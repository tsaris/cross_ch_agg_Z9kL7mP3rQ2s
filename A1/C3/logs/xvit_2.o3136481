
Lmod is automatically replacing "cce/18.0.1" with "gcc-native/13.2".


Lmod is automatically replacing "PrgEnv-cray/8.6.0" with "PrgEnv-gnu/8.6.0".


Due to MODULEPATH changes, the following have been reloaded:
  1) cray-libsci/24.11.0     2) cray-mpich/8.1.31     3) darshan-runtime/3.4.6-mpi


Lmod is automatically replacing "gcc-native/13.2" with "gcc/12.2.0".


Inactive Modules:
  1) darshan-runtime

The following have been reloaded with a version change:
  1) cray-libsci/24.11.0 => cray-libsci/23.09.1.1
  2) cray-mpich/8.1.31 => cray-mpich/8.1.27
  3) libfabric/1.22.0 => libfabric/1.20.1

Lmod has detected the following error: These module(s) or extension(s) exist
but cannot be loaded as requested: "darshan-runtime"
   Try: "module spider darshan-runtime" to see how to load the module(s).



for i in {orbit_hier_token,orbit_hier_token_noagg,orbit_hier_token_noagg_self,orbit_linear}; do for j in {2,}; do for k in {32,64,128,256,512,768,1024}; do python train.py \ configs/ERA5-100million-91variables.yaml \ --max_epochs 1 \ --fa2 \ --fsdp_size 1 \ --simple_ddp_size 1 \ --seq_par_size 1 \ --tensor_par_size 16 \ --batch_size $j \ --arch $i \ --channels $k \ --imagex 128 \ --imagey 256 \ --embed_dim 6144 \ --depth 32 \ --num_heads 32 echo "sleeping..." sleep 5 echo "Done" done done done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,909] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,909] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,909] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,909] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,909] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,909] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,909] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,909] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,910] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,910] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,910] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,910] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,910] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,910] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,910] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:52:38,910] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=32, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 1 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 6 After initialize parallelism groups
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 8 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 10 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 15 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 12 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 6144])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(94790144) params_per_gpu tensor(94790144)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.0234375
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.0234375
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.0234375
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.015625
[2025-03-07 21:53:10,115] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,140] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[2025-03-07 21:53:10,714] [INFO] [profiler.py:80:start_profile] Flops profiler started
MUST: Model 94.790144 M TFLOPS: 44.744481596141334

--> cuda max reserved memory = 2.8262
--> max reserved percentage = 4.42 %

--> cuda max memory allocated = 1.9855
--> max allocated percentage = 3.1 %

--> peak active memory = 1.9855
--> peak active memory 3.1 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=32, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 2.8262 44.744481596141334 tensor(94790144)
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,715] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:10,742] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,742] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,742] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,742] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,742] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,742] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,742] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,742] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,743] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,743] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,743] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,743] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,743] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,743] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:10,744] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:22,975] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=64, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:23,896] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:23,896] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:23,896] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:23,896] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:23,896] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:23,896] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:23,896] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 7 After initialize parallelism groups
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:24,594] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:24,594] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:24,594] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:24,594] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:24,594] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:24,594] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:24,594] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:53:24,594] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 9 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 14 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 13 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 2 After initialize model
rank 1 After initialize model
rank 2 Before the second dist.barrier()
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 8 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 5 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 6144])
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(101475328) params_per_gpu tensor(101475328)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.234375
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.234375
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.234375
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.2265625
[2025-03-07 21:53:46,945] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:46,983] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[2025-03-07 21:53:47,061] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,061] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,061] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,062] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,062] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,062] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,062] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,062] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,063] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,063] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,063] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,063] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,063] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,063] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,064] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:53:47,100] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,100] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,100] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,100] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,101] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,101] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,101] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,101] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,101] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,101] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,101] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,101] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,102] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,102] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:53:47,102] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 101.475328 M TFLOPS: 38.5523976845044

--> cuda max reserved memory = 3.6191
--> max reserved percentage = 5.66 %

--> cuda max memory allocated = 2.292
--> max allocated percentage = 3.58 %

--> peak active memory = 2.292
--> peak active memory 3.58 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=64, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 3.6191 38.5523976845044 tensor(101475328)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,345] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,345] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,345] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,345] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,345] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,345] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,345] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,345] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:00,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=128, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 7 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 14 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 15 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 9 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 1 After initialize model
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 1 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 3 After initialize model
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 3 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 6144])
rank 5 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
rank 4 After the second dist.barrier()
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
rank 7 After the second dist.barrier()
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 6 After the second dist.barrier()
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
rank 3 After the second dist.barrier()
rank 2 After the second dist.barrier()
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(114845696) params_per_gpu tensor(114845696)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  2.515625
epoch-train:  0 batch_idx 1 world_rank 0  loss  2.515625
epoch-train:  0 batch_idx 2 world_rank 0  loss  2.5
epoch-train:  0 batch_idx 3 world_rank 0  loss  2.5
[2025-03-07 21:54:22,605] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:22,662] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 114.845696 M TFLOPS: 30.780412322497543

--> cuda max reserved memory = 4.6582
--> max reserved percentage = 7.28 %

--> cuda max memory allocated = 3.1006
--> max allocated percentage = 4.85 %

--> peak active memory = 3.1006
--> peak active memory 4.85 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=128, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 4.6582 30.780412322497543 tensor(114845696)
[2025-03-07 21:54:23,570] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,570] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,570] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,570] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,572] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,572] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:23,631] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,631] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,631] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,631] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,631] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,631] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,632] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,631] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,632] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,632] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,632] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,632] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,632] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,632] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:23,632] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:35,186] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=256, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:36,822] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:36,822] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:36,822] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:36,822] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:36,822] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:36,822] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:36,822] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:37,246] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:37,246] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:37,246] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:37,246] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:37,246] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:37,246] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:37,246] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:54:37,246] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 3 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 2 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 8 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 10 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 15 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 4 After initialize model
rank 5 Before the second dist.barrier()
rank 4 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 256, 6144])
rank 13 After the second dist.barrier()
rank 12 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
rank 11 After the second dist.barrier()
rank 10 After the second dist.barrier()
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([4096, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([4096])
total_params before FSDP tensor(141586432) params_per_gpu tensor(141586432)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-255): 256 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=4096, bias=True)
    )
  )
)
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.703125
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.703125
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.703125
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.6953125
[2025-03-07 21:54:59,625] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,730] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,743] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,743] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,743] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,744] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,744] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,744] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,744] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,744] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:54:59,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[2025-03-07 21:54:59,853] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,853] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,853] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,854] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,854] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,854] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,854] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,854] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,854] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,854] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,854] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,854] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,854] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,855] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:54:59,855] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 141.586432 M TFLOPS: 21.860024493744852

--> cuda max reserved memory = 5.3984
--> max reserved percentage = 8.44 %

--> cuda max memory allocated = 4.7199
--> max allocated percentage = 7.38 %

--> peak active memory = 4.7199
--> peak active memory 7.38 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=256, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 5.3984 21.860024493744852 tensor(141586432)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,252] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,252] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,252] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,252] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,252] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,252] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,252] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,252] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,619] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,619] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,619] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,619] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,619] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,619] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,619] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:13,619] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=512, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 5 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 5 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 6 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 10 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 10 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 11 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 15 After initialize parallelism groups
rank 14 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 10 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 512, 6144])
rank 11 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 6 After the second dist.barrier()
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 7 After the second dist.barrier()
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
rank 3 After the second dist.barrier()
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 2 After the second dist.barrier()
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([8192, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([8192])
total_params before FSDP tensor(195067904) params_per_gpu tensor(195067904)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-511): 512 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=8192, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  2.890625
epoch-train:  0 batch_idx 1 world_rank 0  loss  2.875
epoch-train:  0 batch_idx 2 world_rank 0  loss  2.875
epoch-train:  0 batch_idx 3 world_rank 0  loss  2.875
[2025-03-07 21:55:37,534] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,741] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,742] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,742] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,742] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,743] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,743] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,743] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,744] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:55:37,867] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[2025-03-07 21:55:38,075] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,075] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:55:38,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 195.067904 M TFLOPS: 13.653142869256627

--> cuda max reserved memory = 8.7188
--> max reserved percentage = 13.63 %

--> cuda max memory allocated = 7.9604
--> max allocated percentage = 12.44 %

--> peak active memory = 7.9604
--> peak active memory 12.44 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=512, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 8.7188 13.653142869256627 tensor(195067904)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,688] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,688] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,688] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,688] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,688] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,688] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,688] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:55:51,688] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=768, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 7 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 8 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 13 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 9 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 3 After initialize model
rank 4 Before the second dist.barrier()
rank 3 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 13 After initialize model
rank 15 After initialize model
rank 13 Before the second dist.barrier()
rank 15 Before the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 768, 6144])
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.512.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.512.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.513.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.513.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.514.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.514.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.515.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.515.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.516.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.516.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.517.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.517.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.518.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.518.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.519.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.519.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.520.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.520.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.521.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.521.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.522.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.522.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.523.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.523.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.524.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.524.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.525.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.525.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.526.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.526.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.527.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.527.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.528.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.528.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.529.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.529.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.530.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.530.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.531.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.531.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.532.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.532.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.533.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.533.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.534.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.534.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.535.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.535.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.536.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.536.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.537.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.537.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.538.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.538.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.539.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.539.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.540.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.540.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.541.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.541.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.542.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.542.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.543.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.543.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.544.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.544.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.545.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.545.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.546.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.546.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.547.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.547.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.548.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.548.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.549.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.549.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.550.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.550.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.551.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.551.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.552.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.552.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.553.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.553.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.554.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.554.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.555.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.555.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.556.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.556.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.557.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.557.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.558.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.558.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.559.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.559.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.560.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.560.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.561.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.561.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.562.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.562.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.563.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.563.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.564.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.564.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.565.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.565.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.566.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.566.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.567.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.567.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.568.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.568.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.569.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.569.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.570.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.570.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.571.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.571.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.572.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.572.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.573.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.573.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.574.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.574.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.575.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.575.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.576.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.576.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.577.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.577.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.578.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.578.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.579.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.579.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.580.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.580.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.581.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.581.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.582.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.582.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.583.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.583.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.584.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.584.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.585.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.585.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.586.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.586.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.587.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.587.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.588.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.588.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.589.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.589.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.590.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.590.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.591.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.591.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.592.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.592.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.593.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.593.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.594.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.594.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.595.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.595.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.596.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.596.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.597.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.597.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.598.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.598.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.599.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.599.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.600.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.600.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.601.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.601.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.602.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.602.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.603.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.603.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.604.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.604.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.605.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.605.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.606.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.606.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.607.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.607.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.608.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.608.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.609.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.609.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.610.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.610.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.611.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.611.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.612.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.612.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.613.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.613.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.614.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.614.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.615.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.615.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.616.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.616.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.617.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.617.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.618.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.618.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.619.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.619.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.620.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.620.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.621.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.621.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.622.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.622.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.623.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.623.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.624.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.624.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.625.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.625.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.626.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.626.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.627.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.627.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.628.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.628.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.629.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.629.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.630.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.630.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.631.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.631.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.632.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.632.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.633.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.633.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.634.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.634.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.635.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.635.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.636.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.636.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.637.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.637.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.638.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.638.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.639.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.639.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.640.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.640.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.641.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.641.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.642.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.642.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.643.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.643.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.644.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.644.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.645.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.645.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.646.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.646.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.647.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.647.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.648.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.648.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.649.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.649.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.650.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.650.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.651.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.651.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.652.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.652.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.653.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.653.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.654.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.654.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.655.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.655.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.656.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.656.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.657.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.657.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.658.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.658.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.659.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.659.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.660.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.660.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.661.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.661.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.662.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.662.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.663.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.663.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.664.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.664.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.665.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.665.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.666.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.666.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.667.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.667.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.668.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.668.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.669.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.669.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.670.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.670.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.671.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.671.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.672.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.672.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.673.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.673.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.674.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.674.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.675.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.675.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.676.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.676.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.677.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.677.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.678.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.678.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.679.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.679.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.680.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.680.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.681.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.681.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.682.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.682.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.683.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.683.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.684.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.684.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.685.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.685.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.686.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.686.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.687.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.687.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.688.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.688.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.689.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.689.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.690.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.690.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.691.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.691.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.692.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.692.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.693.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.693.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.694.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.694.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.695.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.695.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.696.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.696.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.697.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.697.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.698.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.698.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.699.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.699.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.700.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.700.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.701.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.701.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.702.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.702.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.703.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.703.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.704.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.704.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.705.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.705.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.706.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.706.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.707.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.707.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.708.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.708.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.709.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.709.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.710.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.710.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.711.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.711.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.712.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.712.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.713.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.713.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.714.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.714.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.715.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.715.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.716.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.716.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.717.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.717.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.718.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.718.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.719.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.719.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.720.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.720.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.721.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.721.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.722.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.722.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.723.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.723.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.724.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.724.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.725.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.725.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.726.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.726.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.727.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.727.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.728.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.728.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.729.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.729.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.730.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.730.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.731.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.731.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.732.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.732.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.733.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.733.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.734.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.734.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.735.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.735.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.736.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.736.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.737.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.737.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.738.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.738.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.739.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.739.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.740.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.740.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.741.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.741.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.742.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.742.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.743.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.743.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.744.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.744.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.745.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.745.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.746.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.746.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.747.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.747.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.748.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.748.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.749.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.749.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.750.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.750.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.751.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.751.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.752.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.752.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.753.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.753.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.754.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.754.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.755.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.755.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.756.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.756.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.757.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.757.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.758.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.758.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.759.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.759.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.760.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.760.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.761.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.761.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.762.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.762.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.763.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.763.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.764.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.764.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.765.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.765.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.766.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.766.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.767.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.767.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([12288, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([12288])
total_params before FSDP tensor(248549376) params_per_gpu tensor(248549376)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-767): 768 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=12288, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.53125
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.5234375
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.5234375
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.5234375
[2025-03-07 21:56:17,371] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,384] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,385] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,385] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,385] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,386] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,386] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,387] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,388] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,389] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,389] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,389] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,389] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,389] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,389] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,389] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:17,686] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,694] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,694] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,694] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,694] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,694] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,695] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,695] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,695] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,695] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,696] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,696] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,696] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,697] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,697] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:17,698] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 248.549376 M TFLOPS: 13.475062479124809

--> cuda max reserved memory = 12.0508
--> max reserved percentage = 18.83 %

--> cuda max memory allocated = 11.2009
--> max allocated percentage = 17.51 %

--> peak active memory = 11.2009
--> peak active memory 17.51 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=768, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 12.0508 13.475062479124809 tensor(248549376)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,359] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,359] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,359] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,359] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,359] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,359] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,359] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,359] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,364] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,364] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,364] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,364] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,364] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,364] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,364] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:56:31,364] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=1024, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 8 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 4 After initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 5 After initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 11 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 9 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 1 After initialize model
rank 15 After initialize model
rank 1 Before the second dist.barrier()
rank 15 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 1024, 6144])
rank 13 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
rank 12 After the second dist.barrier()
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 14 After the second dist.barrier()
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 15 After the second dist.barrier()
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.512.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.512.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.513.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.513.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.514.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.514.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.515.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.515.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.516.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.516.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.517.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.517.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.518.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.518.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.519.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.519.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.520.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.520.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.521.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.521.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.522.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.522.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.523.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.523.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.524.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.524.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.525.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.525.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.526.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.526.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.527.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.527.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.528.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.528.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.529.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.529.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.530.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.530.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.531.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.531.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.532.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.532.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.533.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.533.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.534.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.534.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.535.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.535.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.536.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.536.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.537.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.537.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.538.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.538.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.539.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.539.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.540.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.540.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.541.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.541.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.542.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.542.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.543.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.543.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.544.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.544.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.545.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.545.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.546.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.546.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.547.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.547.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.548.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.548.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.549.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.549.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.550.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.550.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.551.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.551.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.552.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.552.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.553.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.553.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.554.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.554.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.555.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.555.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.556.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.556.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.557.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.557.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.558.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.558.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.559.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.559.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.560.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.560.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.561.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.561.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.562.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.562.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.563.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.563.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.564.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.564.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.565.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.565.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.566.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.566.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.567.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.567.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.568.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.568.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.569.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.569.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.570.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.570.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.571.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.571.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.572.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.572.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.573.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.573.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.574.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.574.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.575.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.575.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.576.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.576.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.577.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.577.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.578.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.578.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.579.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.579.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.580.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.580.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.581.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.581.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.582.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.582.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.583.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.583.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.584.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.584.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.585.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.585.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.586.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.586.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.587.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.587.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.588.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.588.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.589.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.589.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.590.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.590.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.591.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.591.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.592.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.592.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.593.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.593.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.594.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.594.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.595.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.595.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.596.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.596.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.597.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.597.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.598.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.598.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.599.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.599.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.600.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.600.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.601.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.601.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.602.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.602.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.603.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.603.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.604.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.604.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.605.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.605.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.606.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.606.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.607.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.607.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.608.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.608.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.609.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.609.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.610.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.610.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.611.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.611.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.612.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.612.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.613.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.613.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.614.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.614.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.615.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.615.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.616.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.616.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.617.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.617.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.618.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.618.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.619.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.619.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.620.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.620.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.621.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.621.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.622.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.622.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.623.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.623.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.624.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.624.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.625.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.625.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.626.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.626.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.627.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.627.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.628.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.628.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.629.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.629.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.630.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.630.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.631.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.631.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.632.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.632.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.633.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.633.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.634.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.634.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.635.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.635.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.636.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.636.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.637.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.637.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.638.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.638.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.639.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.639.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.640.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.640.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.641.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.641.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.642.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.642.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.643.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.643.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.644.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.644.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.645.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.645.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.646.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.646.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.647.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.647.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.648.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.648.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.649.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.649.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.650.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.650.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.651.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.651.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.652.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.652.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.653.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.653.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.654.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.654.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.655.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.655.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.656.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.656.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.657.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.657.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.658.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.658.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.659.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.659.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.660.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.660.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.661.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.661.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.662.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.662.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.663.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.663.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.664.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.664.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.665.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.665.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.666.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.666.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.667.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.667.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.668.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.668.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.669.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.669.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.670.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.670.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.671.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.671.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.672.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.672.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.673.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.673.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.674.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.674.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.675.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.675.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.676.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.676.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.677.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.677.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.678.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.678.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.679.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.679.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.680.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.680.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.681.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.681.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.682.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.682.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.683.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.683.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.684.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.684.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.685.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.685.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.686.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.686.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.687.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.687.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.688.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.688.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.689.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.689.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.690.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.690.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.691.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.691.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.692.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.692.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.693.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.693.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.694.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.694.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.695.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.695.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.696.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.696.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.697.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.697.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.698.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.698.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.699.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.699.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.700.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.700.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.701.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.701.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.702.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.702.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.703.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.703.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.704.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.704.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.705.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.705.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.706.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.706.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.707.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.707.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.708.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.708.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.709.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.709.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.710.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.710.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.711.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.711.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.712.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.712.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.713.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.713.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.714.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.714.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.715.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.715.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.716.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.716.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.717.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.717.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.718.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.718.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.719.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.719.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.720.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.720.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.721.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.721.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.722.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.722.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.723.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.723.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.724.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.724.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.725.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.725.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.726.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.726.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.727.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.727.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.728.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.728.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.729.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.729.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.730.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.730.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.731.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.731.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.732.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.732.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.733.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.733.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.734.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.734.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.735.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.735.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.736.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.736.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.737.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.737.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.738.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.738.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.739.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.739.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.740.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.740.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.741.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.741.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.742.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.742.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.743.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.743.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.744.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.744.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.745.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.745.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.746.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.746.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.747.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.747.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.748.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.748.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.749.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.749.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.750.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.750.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.751.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.751.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.752.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.752.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.753.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.753.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.754.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.754.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.755.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.755.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.756.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.756.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.757.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.757.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.758.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.758.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.759.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.759.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.760.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.760.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.761.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.761.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.762.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.762.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.763.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.763.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.764.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.764.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.765.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.765.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.766.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.766.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.767.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.767.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.768.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.768.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.769.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.769.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.770.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.770.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.771.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.771.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.772.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.772.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.773.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.773.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.774.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.774.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.775.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.775.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.776.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.776.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.777.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.777.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.778.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.778.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.779.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.779.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.780.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.780.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.781.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.781.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.782.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.782.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.783.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.783.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.784.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.784.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.785.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.785.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.786.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.786.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.787.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.787.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.788.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.788.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.789.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.789.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.790.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.790.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.791.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.791.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.792.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.792.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.793.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.793.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.794.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.794.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.795.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.795.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.796.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.796.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.797.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.797.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.798.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.798.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.799.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.799.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.800.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.800.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.801.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.801.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.802.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.802.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.803.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.803.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.804.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.804.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.805.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.805.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.806.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.806.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.807.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.807.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.808.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.808.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.809.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.809.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.810.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.810.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.811.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.811.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.812.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.812.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.813.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.813.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.814.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.814.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.815.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.815.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.816.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.816.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.817.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.817.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.818.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.818.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.819.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.819.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.820.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.820.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.821.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.821.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.822.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.822.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.823.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.823.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.824.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.824.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.825.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.825.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.826.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.826.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.827.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.827.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.828.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.828.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.829.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.829.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.830.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.830.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.831.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.831.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.832.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.832.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.833.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.833.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.834.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.834.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.835.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.835.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.836.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.836.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.837.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.837.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.838.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.838.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.839.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.839.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.840.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.840.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.841.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.841.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.842.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.842.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.843.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.843.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.844.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.844.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.845.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.845.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.846.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.846.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.847.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.847.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.848.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.848.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.849.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.849.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.850.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.850.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.851.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.851.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.852.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.852.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.853.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.853.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.854.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.854.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.855.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.855.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.856.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.856.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.857.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.857.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.858.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.858.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.859.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.859.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.860.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.860.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.861.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.861.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.862.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.862.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.863.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.863.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.864.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.864.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.865.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.865.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.866.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.866.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.867.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.867.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.868.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.868.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.869.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.869.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.870.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.870.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.871.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.871.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.872.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.872.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.873.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.873.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.874.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.874.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.875.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.875.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.876.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.876.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.877.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.877.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.878.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.878.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.879.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.879.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.880.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.880.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.881.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.881.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.882.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.882.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.883.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.883.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.884.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.884.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.885.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.885.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.886.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.886.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.887.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.887.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.888.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.888.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.889.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.889.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.890.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.890.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.891.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.891.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.892.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.892.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.893.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.893.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.894.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.894.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.895.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.895.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.896.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.896.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.897.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.897.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.898.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.898.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.899.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.899.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.900.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.900.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.901.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.901.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.902.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.902.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.903.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.903.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.904.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.904.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.905.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.905.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.906.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.906.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.907.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.907.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.908.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.908.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.909.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.909.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.910.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.910.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.911.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.911.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.912.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.912.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.913.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.913.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.914.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.914.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.915.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.915.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.916.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.916.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.917.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.917.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.918.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.918.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.919.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.919.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.920.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.920.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.921.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.921.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.922.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.922.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.923.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.923.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.924.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.924.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.925.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.925.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.926.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.926.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.927.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.927.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.928.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.928.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.929.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.929.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.930.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.930.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.931.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.931.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.932.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.932.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.933.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.933.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.934.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.934.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.935.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.935.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.936.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.936.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.937.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.937.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.938.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.938.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.939.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.939.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.940.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.940.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.941.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.941.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.942.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.942.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.943.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.943.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.944.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.944.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.945.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.945.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.946.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.946.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.947.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.947.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.948.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.948.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.949.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.949.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.950.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.950.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.951.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.951.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.952.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.952.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.953.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.953.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.954.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.954.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.955.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.955.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.956.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.956.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.957.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.957.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.958.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.958.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.959.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.959.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.960.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.960.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.961.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.961.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.962.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.962.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.963.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.963.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.964.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.964.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.965.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.965.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.966.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.966.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.967.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.967.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.968.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.968.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.969.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.969.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.970.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.970.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.971.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.971.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.972.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.972.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.973.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.973.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.974.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.974.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.975.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.975.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.976.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.976.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.977.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.977.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.978.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.978.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.979.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.979.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.980.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.980.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.981.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.981.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.982.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.982.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.983.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.983.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.984.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.984.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.985.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.985.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.986.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.986.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.987.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.987.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.988.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.988.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.989.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.989.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.990.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.990.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.991.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.991.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.992.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.992.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.993.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.993.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.994.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.994.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.995.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.995.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.996.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.996.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.997.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.997.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.998.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.998.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.999.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.999.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1000.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1000.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1001.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1001.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1002.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1002.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1003.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1003.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1004.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1004.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1005.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1005.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1006.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1006.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1007.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1007.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1008.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1008.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1009.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1009.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1010.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1010.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1011.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1011.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1012.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1012.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1013.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1013.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1014.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1014.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1015.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1015.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1016.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1016.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1017.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1017.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1018.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1018.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1019.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1019.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1020.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1020.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1021.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1021.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1022.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1022.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1023.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1023.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([16384, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([16384])
total_params before FSDP tensor(302030848) params_per_gpu tensor(302030848)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-1023): 1024 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=16384, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.5859375
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.578125
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.578125
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.578125
[2025-03-07 21:56:58,152] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,161] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,162] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,162] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,163] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,163] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,163] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,163] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,166] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,166] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,167] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,167] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,167] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,167] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,168] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,168] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:56:58,563] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,569] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,569] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,570] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,571] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,571] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,572] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,572] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,572] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,573] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,573] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,572] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,573] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,573] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,573] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:56:58,574] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 302.030848 M TFLOPS: 11.83416075449107

--> cuda max reserved memory = 15.5625
--> max reserved percentage = 24.32 %

--> cuda max memory allocated = 14.4414
--> max allocated percentage = 22.57 %

--> peak active memory = 14.4414
--> peak active memory 22.57 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=1024, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 15.5625 11.83416075449107 tensor(302030848)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,058] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,058] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,058] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,058] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,058] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,058] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,058] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,058] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,145] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,145] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,145] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,145] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,145] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,145] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,145] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:12,145] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=32, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
rank 1 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 2 After initialize parallelism groups
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 14 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 8 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 10 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 9 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 6144])
rank 5 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 6144])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
rank 4 After the second dist.barrier()
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 6 After the second dist.barrier()
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 7 After the second dist.barrier()
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
rank 2 After the second dist.barrier()
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 3 After the second dist.barrier()
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([384, 6144])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([768, 6144])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(245889536) params_per_gpu tensor(104239616)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=6144, out_features=384, bias=False)
          (kv): Linear(in_features=6144, out_features=768, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=6144, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  12.4375
epoch-train:  0 batch_idx 1 world_rank 0  loss  12.375
epoch-train:  0 batch_idx 2 world_rank 0  loss  12.3125
epoch-train:  0 batch_idx 3 world_rank 0  loss  12.3125
[2025-03-07 21:57:37,005] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,005] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,005] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,005] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,005] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,006] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,005] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,006] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,006] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,006] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,006] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,006] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,006] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,006] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,006] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,006] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:57:37,129] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,129] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,129] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,129] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,129] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,129] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,129] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,129] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,129] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,129] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,129] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,129] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,130] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,130] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,130] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:57:37,130] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 104.239616 M TFLOPS: 20.641152538577156

--> cuda max reserved memory = 8.7598
--> max reserved percentage = 13.69 %

--> cuda max memory allocated = 6.6917
--> max allocated percentage = 10.46 %

--> peak active memory = 8.2854
--> peak active memory 12.95 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=32, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 8.7598 20.641152538577156 tensor(245889536)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:57:50,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=64, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 3 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 13 After initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 7 After initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 9 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 4 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 2 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 2 After initialize model
rank 0 After initialize model
rank 2 Before the second dist.barrier()
rank 0 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 6144])
rank 13 After the second dist.barrier()
rank 12 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 6144])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 11 After the second dist.barrier()
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 10 After the second dist.barrier()
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([384, 6144])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([768, 6144])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(252574720) params_per_gpu tensor(110924800)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=6144, out_features=384, bias=False)
          (kv): Linear(in_features=6144, out_features=768, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=6144, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  15.1875
epoch-train:  0 batch_idx 1 world_rank 0  loss  15.125
epoch-train:  0 batch_idx 2 world_rank 0  loss  15.125
epoch-train:  0 batch_idx 3 world_rank 0  loss  15.0625
[2025-03-07 21:58:15,614] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,614] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,614] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,614] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,614] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,614] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,615] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,615] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,615] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,615] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,615] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,615] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,615] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,615] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,615] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,615] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:15,852] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 110.9248 M TFLOPS: 18.117904216448732

--> cuda max reserved memory = 15.5449
--> max reserved percentage = 24.29 %

--> cuda max memory allocated = 11.6933
--> max allocated percentage = 18.28 %

--> peak active memory = 14.8808
--> peak active memory 23.26 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=64, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 15.5449 18.117904216448732 tensor(252574720)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,464] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,464] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,464] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,464] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,464] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,464] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,464] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,464] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,465] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,465] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,465] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,465] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,465] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,465] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,465] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:58:29,465] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=128, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 9 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 13 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 5 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 2 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 14 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 8 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 6 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 6144])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 6144])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([384, 6144])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([768, 6144])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(265945088) params_per_gpu tensor(124295168)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=6144, out_features=384, bias=False)
          (kv): Linear(in_features=6144, out_features=768, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=6144, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  8.1875
epoch-train:  0 batch_idx 1 world_rank 0  loss  8.125
epoch-train:  0 batch_idx 2 world_rank 0  loss  8.125
epoch-train:  0 batch_idx 3 world_rank 0  loss  8.0625
[2025-03-07 21:58:55,970] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,971] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,971] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,971] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,972] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,972] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,972] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,972] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,972] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,972] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,972] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,972] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,972] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,973] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,973] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:55,973] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:58:56,434] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,434] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,434] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:58:56,435] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 124.295168 M TFLOPS: 16.93020798122808

--> cuda max reserved memory = 28.9785
--> max reserved percentage = 45.29 %

--> cuda max memory allocated = 21.6887
--> max allocated percentage = 33.9 %

--> peak active memory = 28.0637
--> peak active memory 43.86 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=128, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 28.9785 16.93020798122808 tensor(265945088)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,790] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,790] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,790] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,790] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,790] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,790] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,790] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,790] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,900] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,900] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,900] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,900] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,900] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,900] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,900] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:09,900] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=256, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 13 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 14 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 13 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 9 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 256, 6144])
rank 2 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 12 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 6144])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 14 After the second dist.barrier()
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 15 After the second dist.barrier()
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
rank 11 After the second dist.barrier()
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 10 After the second dist.barrier()
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([384, 6144])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([768, 6144])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([4096, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([4096])
total_params before FSDP tensor(292685824) params_per_gpu tensor(151035904)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-255): 256 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=6144, out_features=384, bias=False)
          (kv): Linear(in_features=6144, out_features=768, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=6144, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=4096, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  19.5
epoch-train:  0 batch_idx 1 world_rank 0  loss  19.5
epoch-train:  0 batch_idx 2 world_rank 0  loss  19.5
epoch-train:  0 batch_idx 3 world_rank 0  loss  19.375
[2025-03-07 21:59:40,960] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,960] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,960] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,960] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,960] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,960] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,960] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,960] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,961] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,961] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,961] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,961] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,961] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,961] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,961] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:40,961] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 21:59:41,873] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,873] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,873] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,873] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,873] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,874] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,874] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,876] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,877] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,878] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,880] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,881] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,881] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,881] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,882] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 21:59:41,889] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 151.035904 M TFLOPS: 16.319040579438497

--> cuda max reserved memory = 55.6523
--> max reserved percentage = 86.98 %

--> cuda max memory allocated = 41.685
--> max allocated percentage = 65.15 %

--> peak active memory = 54.435
--> peak active memory 85.08 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=256, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 55.6523 16.319040579438497 tensor(292685824)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,394] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,394] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,394] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,394] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,394] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,394] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,394] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,394] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,395] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,395] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,395] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,395] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,395] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,395] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,395] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 21:59:55,395] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=512, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 9 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 9 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 11 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 10 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 5 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 11 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 6 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 512, 6144])
rank 13 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 2 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 6144])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
rank 14 After the second dist.barrier()
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 15 After the second dist.barrier()
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 10 After the second dist.barrier()
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
rank 11 After the second dist.barrier()
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([384, 6144])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([768, 6144])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([8192, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([8192])
total_params before FSDP tensor(346167296) params_per_gpu tensor(204517376)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-511): 512 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=6144, out_features=384, bias=False)
          (kv): Linear(in_features=6144, out_features=768, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=6144, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=8192, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank10]: Traceback (most recent call last):
[rank10]:   File "train.py", line 986, in <module>
[rank10]:     main(args, device, world_size, world_rank, local_rank)
[rank10]:   File "train.py", line 890, in main
[rank10]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank10]:   File "train.py", line 372, in training_step
[rank10]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank10]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank10]:     return forward_call(*args, **kwargs)
[rank10]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank10]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank10]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank10]:     x = self.aggregate_variables(x)        
[rank10]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank10]:     x = x.flatten(0, 1)  # BxL, V, D
[rank10]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 2 has a total capacity of 63.98 GiB of which 12.10 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank13]: Traceback (most recent call last):
[rank13]:   File "train.py", line 986, in <module>
[rank13]:     main(args, device, world_size, world_rank, local_rank)
[rank13]:   File "train.py", line 890, in main
[rank13]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank13]:   File "train.py", line 372, in training_step
[rank13]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank13]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank13]:     return forward_call(*args, **kwargs)
[rank13]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank13]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank13]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank13]:     x = self.aggregate_variables(x)        
[rank13]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank13]:     x = x.flatten(0, 1)  # BxL, V, D
[rank13]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 5 has a total capacity of 63.98 GiB of which 12.10 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 890, in main
[rank8]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank8]:   File "train.py", line 372, in training_step
[rank8]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank8]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank8]:     return forward_call(*args, **kwargs)
[rank8]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank8]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank8]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank8]:     x = self.aggregate_variables(x)        
[rank8]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank8]:     x = x.flatten(0, 1)  # BxL, V, D
[rank8]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 63.98 GiB of which 12.10 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank5]: Traceback (most recent call last):
[rank5]:   File "train.py", line 986, in <module>
[rank5]:     main(args, device, world_size, world_rank, local_rank)
[rank5]:   File "train.py", line 890, in main
[rank5]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank5]:   File "train.py", line 372, in training_step
[rank5]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank5]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank5]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank5]:     x = self.aggregate_variables(x)        
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank5]:     x = x.flatten(0, 1)  # BxL, V, D
[rank5]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 5 has a total capacity of 63.98 GiB of which 12.10 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank7]: Traceback (most recent call last):
[rank7]:   File "train.py", line 986, in <module>
[rank7]:     main(args, device, world_size, world_rank, local_rank)
[rank7]:   File "train.py", line 890, in main
[rank7]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank7]:   File "train.py", line 372, in training_step
[rank7]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank7]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank7]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank7]:     x = self.aggregate_variables(x)        
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank7]:     x = x.flatten(0, 1)  # BxL, V, D
[rank7]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 7 has a total capacity of 63.98 GiB of which 12.10 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 986, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 890, in main
[rank3]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank3]:   File "train.py", line 372, in training_step
[rank3]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank3]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank3]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank3]:     x = self.aggregate_variables(x)        
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank3]:     x = x.flatten(0, 1)  # BxL, V, D
[rank3]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 11.91 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 890, in main
[rank15]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank15]:   File "train.py", line 372, in training_step
[rank15]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank15]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank15]:     return forward_call(*args, **kwargs)
[rank15]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank15]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank15]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank15]:     x = self.aggregate_variables(x)        
[rank15]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank15]:     x = x.flatten(0, 1)  # BxL, V, D
[rank15]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 7 has a total capacity of 63.98 GiB of which 12.10 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 890, in main
[rank1]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank1]:   File "train.py", line 372, in training_step
[rank1]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank1]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank1]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank1]:     x = self.aggregate_variables(x)        
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank1]:     x = x.flatten(0, 1)  # BxL, V, D
[rank1]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 11.91 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 890, in main
[rank14]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank14]:   File "train.py", line 372, in training_step
[rank14]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank14]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank14]:     return forward_call(*args, **kwargs)
[rank14]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank14]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank14]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank14]:     x = self.aggregate_variables(x)        
[rank14]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank14]:     x = x.flatten(0, 1)  # BxL, V, D
[rank14]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 6 has a total capacity of 63.98 GiB of which 11.91 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 890, in main
[rank9]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank9]:   File "train.py", line 372, in training_step
[rank9]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank9]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank9]:     return forward_call(*args, **kwargs)
[rank9]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank9]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank9]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank9]:     x = self.aggregate_variables(x)        
[rank9]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank9]:     x = x.flatten(0, 1)  # BxL, V, D
[rank9]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 11.91 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 890, in main
[rank11]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank11]:   File "train.py", line 372, in training_step
[rank11]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank11]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank11]:     return forward_call(*args, **kwargs)
[rank11]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank11]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank11]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank11]:     x = self.aggregate_variables(x)        
[rank11]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank11]:     x = x.flatten(0, 1)  # BxL, V, D
[rank11]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 11.91 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 890, in main
[rank12]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank12]:   File "train.py", line 372, in training_step
[rank12]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank12]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank12]:     return forward_call(*args, **kwargs)
[rank12]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank12]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank12]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank12]:     x = self.aggregate_variables(x)        
[rank12]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank12]:     x = x.flatten(0, 1)  # BxL, V, D
[rank12]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 4 has a total capacity of 63.98 GiB of which 11.91 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "train.py", line 986, in <module>
[rank0]:     main(args, device, world_size, world_rank, local_rank)
[rank0]:   File "train.py", line 890, in main
[rank0]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank0]:   File "train.py", line 372, in training_step
[rank0]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank0]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank0]:     x = self.aggregate_variables(x)        
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank0]:     x = x.flatten(0, 1)  # BxL, V, D
[rank0]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 63.98 GiB of which 12.10 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 54.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank2]: Traceback (most recent call last):
[rank2]:   File "train.py", line 986, in <module>
[rank2]:     main(args, device, world_size, world_rank, local_rank)
[rank2]:   File "train.py", line 890, in main
[rank2]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank2]:   File "train.py", line 372, in training_step
[rank2]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank2]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank2]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank2]:     x = self.aggregate_variables(x)        
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank2]:     x = x.flatten(0, 1)  # BxL, V, D
[rank2]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 2 has a total capacity of 63.98 GiB of which 12.10 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank4]: Traceback (most recent call last):
[rank4]:   File "train.py", line 986, in <module>
[rank4]:     main(args, device, world_size, world_rank, local_rank)
[rank4]:   File "train.py", line 890, in main
[rank4]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank4]:   File "train.py", line 372, in training_step
[rank4]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank4]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank4]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank4]:     x = self.aggregate_variables(x)        
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank4]:     x = x.flatten(0, 1)  # BxL, V, D
[rank4]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 4 has a total capacity of 63.98 GiB of which 11.91 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank6]: Traceback (most recent call last):
[rank6]:   File "train.py", line 986, in <module>
[rank6]:     main(args, device, world_size, world_rank, local_rank)
[rank6]:   File "train.py", line 890, in main
[rank6]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank6]:   File "train.py", line 372, in training_step
[rank6]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank6]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank6]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank6]:     x = self.aggregate_variables(x)        
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank6]:     x = x.flatten(0, 1)  # BxL, V, D
[rank6]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 6 has a total capacity of 63.98 GiB of which 11.91 GiB is free. Of the allocated memory 50.82 GiB is allocated by PyTorch, and 52.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,951] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,951] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,951] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,951] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,951] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,951] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,951] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,951] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,956] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,956] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,956] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,956] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,956] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,956] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,956] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:00:31,956] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=768, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 5 After initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 1 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'sperank 14 After initialize parallelism groups
cific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'vrank 12 After initialize parallelism groups
_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'gerank 8 After initialize parallelism groups
opotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_wrank 11 After initialize parallelism groups
orkers': 1, 'pin_memory': False}}
rank 6 Before initialize parallelism groups
rank 9 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 13 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 768, 6144])
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 6144])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
rank 14 After the second dist.barrier()
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 15 After the second dist.barrier()
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 10 After the second dist.barrier()
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
rank 11 After the second dist.barrier()
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.512.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.512.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.513.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.513.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.514.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.514.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.515.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.515.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.516.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.516.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.517.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.517.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.518.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.518.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.519.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.519.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.520.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.520.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.521.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.521.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.522.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.522.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.523.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.523.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.524.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.524.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.525.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.525.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.526.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.526.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.527.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.527.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.528.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.528.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.529.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.529.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.530.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.530.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.531.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.531.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.532.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.532.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.533.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.533.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.534.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.534.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.535.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.535.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.536.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.536.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.537.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.537.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.538.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.538.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.539.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.539.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.540.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.540.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.541.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.541.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.542.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.542.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.543.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.543.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.544.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.544.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.545.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.545.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.546.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.546.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.547.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.547.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.548.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.548.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.549.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.549.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.550.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.550.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.551.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.551.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.552.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.552.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.553.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.553.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.554.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.554.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.555.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.555.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.556.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.556.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.557.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.557.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.558.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.558.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.559.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.559.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.560.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.560.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.561.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.561.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.562.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.562.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.563.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.563.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.564.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.564.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.565.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.565.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.566.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.566.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.567.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.567.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.568.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.568.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.569.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.569.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.570.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.570.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.571.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.571.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.572.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.572.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.573.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.573.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.574.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.574.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.575.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.575.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.576.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.576.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.577.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.577.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.578.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.578.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.579.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.579.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.580.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.580.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.581.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.581.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.582.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.582.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.583.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.583.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.584.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.584.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.585.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.585.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.586.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.586.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.587.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.587.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.588.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.588.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.589.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.589.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.590.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.590.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.591.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.591.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.592.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.592.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.593.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.593.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.594.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.594.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.595.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.595.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.596.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.596.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.597.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.597.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.598.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.598.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.599.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.599.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.600.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.600.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.601.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.601.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.602.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.602.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.603.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.603.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.604.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.604.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.605.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.605.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.606.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.606.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.607.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.607.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.608.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.608.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.609.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.609.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.610.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.610.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.611.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.611.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.612.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.612.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.613.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.613.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.614.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.614.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.615.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.615.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.616.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.616.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.617.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.617.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.618.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.618.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.619.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.619.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.620.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.620.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.621.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.621.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.622.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.622.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.623.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.623.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.624.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.624.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.625.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.625.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.626.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.626.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.627.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.627.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.628.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.628.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.629.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.629.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.630.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.630.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.631.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.631.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.632.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.632.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.633.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.633.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.634.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.634.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.635.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.635.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.636.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.636.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.637.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.637.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.638.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.638.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.639.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.639.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.640.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.640.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.641.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.641.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.642.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.642.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.643.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.643.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.644.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.644.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.645.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.645.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.646.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.646.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.647.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.647.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.648.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.648.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.649.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.649.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.650.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.650.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.651.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.651.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.652.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.652.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.653.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.653.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.654.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.654.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.655.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.655.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.656.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.656.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.657.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.657.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.658.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.658.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.659.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.659.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.660.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.660.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.661.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.661.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.662.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.662.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.663.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.663.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.664.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.664.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.665.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.665.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.666.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.666.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.667.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.667.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.668.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.668.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.669.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.669.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.670.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.670.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.671.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.671.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.672.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.672.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.673.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.673.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.674.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.674.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.675.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.675.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.676.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.676.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.677.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.677.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.678.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.678.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.679.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.679.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.680.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.680.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.681.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.681.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.682.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.682.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.683.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.683.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.684.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.684.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.685.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.685.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.686.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.686.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.687.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.687.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.688.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.688.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.689.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.689.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.690.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.690.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.691.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.691.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.692.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.692.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.693.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.693.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.694.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.694.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.695.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.695.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.696.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.696.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.697.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.697.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.698.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.698.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.699.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.699.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.700.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.700.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.701.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.701.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.702.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.702.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.703.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.703.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.704.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.704.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.705.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.705.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.706.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.706.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.707.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.707.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.708.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.708.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.709.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.709.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.710.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.710.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.711.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.711.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.712.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.712.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.713.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.713.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.714.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.714.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.715.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.715.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.716.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.716.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.717.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.717.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.718.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.718.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.719.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.719.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.720.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.720.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.721.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.721.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.722.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.722.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.723.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.723.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.724.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.724.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.725.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.725.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.726.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.726.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.727.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.727.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.728.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.728.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.729.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.729.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.730.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.730.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.731.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.731.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.732.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.732.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.733.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.733.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.734.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.734.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.735.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.735.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.736.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.736.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.737.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.737.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.738.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.738.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.739.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.739.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.740.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.740.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.741.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.741.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.742.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.742.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.743.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.743.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.744.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.744.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.745.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.745.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.746.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.746.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.747.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.747.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.748.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.748.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.749.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.749.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.750.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.750.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.751.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.751.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.752.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.752.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.753.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.753.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.754.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.754.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.755.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.755.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.756.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.756.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.757.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.757.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.758.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.758.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.759.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.759.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.760.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.760.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.761.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.761.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.762.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.762.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.763.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.763.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.764.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.764.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.765.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.765.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.766.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.766.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.767.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.767.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([384, 6144])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([768, 6144])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([12288, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([12288])
total_params before FSDP tensor(399648768) params_per_gpu tensor(257998848)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-767): 768 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=6144, out_features=384, bias=False)
          (kv): Linear(in_features=6144, out_features=768, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=6144, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=12288, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 890, in main
[rank1]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank1]:   File "train.py", line 372, in training_step
[rank1]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank1]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank1]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank1]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank1]:     return _AllGather.apply(group, tensor)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank1]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank1]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank1]:     work = group.allgather([tensor_list], [tensor])
[rank1]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 20.46 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank5]: Traceback (most recent call last):
[rank5]:   File "train.py", line 986, in <module>
[rank5]:     main(args, device, world_size, world_rank, local_rank)
[rank5]:   File "train.py", line 890, in main
[rank5]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank5]:   File "train.py", line 372, in training_step
[rank5]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank5]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank5]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank5]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank5]:     return _AllGather.apply(group, tensor)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank5]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank5]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank5]:     return func(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank5]:     work = group.allgather([tensor_list], [tensor])
[rank5]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 5 has a total capacity of 63.98 GiB of which 20.65 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 986, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 890, in main
[rank3]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank3]:   File "train.py", line 372, in training_step
[rank3]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank3]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank3]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank3]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank3]:     return _AllGather.apply(group, tensor)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank3]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank3]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank3]:     work = group.allgather([tensor_list], [tensor])
[rank3]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 20.46 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank6]: Traceback (most recent call last):
[rank6]:   File "train.py", line 986, in <module>
[rank6]:     main(args, device, world_size, world_rank, local_rank)
[rank6]:   File "train.py", line 890, in main
[rank6]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank6]:   File "train.py", line 372, in training_step
[rank6]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank6]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank6]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank6]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank6]:     return _AllGather.apply(group, tensor)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank6]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank6]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank6]:     return func(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank6]:     work = group.allgather([tensor_list], [tensor])
[rank6]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 6 has a total capacity of 63.98 GiB of which 20.46 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 890, in main
[rank8]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank8]:   File "train.py", line 372, in training_step
[rank8]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank8]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank8]:     return forward_call(*args, **kwargs)
[rank8]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank8]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank8]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank8]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank8]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank8]:     return _AllGather.apply(group, tensor)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank8]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank8]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank8]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank8]:     work = group.allgather([tensor_list], [tensor])
[rank8]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 0 has a total capacity of 63.98 GiB of which 20.65 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank10]: Traceback (most recent call last):
[rank10]:   File "train.py", line 986, in <module>
[rank10]:     main(args, device, world_size, world_rank, local_rank)
[rank10]:   File "train.py", line 890, in main
[rank10]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank10]:   File "train.py", line 372, in training_step
[rank10]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank10]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank10]:     return forward_call(*args, **kwargs)
[rank10]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank10]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank10]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank10]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank10]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank10]:     return _AllGather.apply(group, tensor)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank10]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank10]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank10]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank10]:     return func(*args, **kwargs)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank10]:     work = group.allgather([tensor_list], [tensor])
[rank10]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 2 has a total capacity of 63.98 GiB of which 20.65 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 890, in main
[rank15]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank15]:   File "train.py", line 372, in training_step
[rank15]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank15]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank15]:     return forward_call(*args, **kwargs)
[rank15]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank15]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank15]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank15]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank15]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank15]:     return _AllGather.apply(group, tensor)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank15]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank15]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank15]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank15]:     work = group.allgather([tensor_list], [tensor])
[rank15]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 7 has a total capacity of 63.98 GiB of which 20.65 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 890, in main
[rank12]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank12]:   File "train.py", line 372, in training_step
[rank12]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank12]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank12]:     return forward_call(*args, **kwargs)
[rank12]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank12]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank12]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank12]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank12]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank12]:     return _AllGather.apply(group, tensor)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank12]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank12]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank12]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank12]:     work = group.allgather([tensor_list], [tensor])
[rank12]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 4 has a total capacity of 63.98 GiB of which 20.46 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 890, in main
[rank9]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank9]:   File "train.py", line 372, in training_step
[rank9]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank9]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank9]:     return forward_call(*args, **kwargs)
[rank9]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank9]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank9]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank9]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank9]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank9]:     return _AllGather.apply(group, tensor)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank9]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank9]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank9]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank9]:     work = group.allgather([tensor_list], [tensor])
[rank9]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 20.46 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank13]: Traceback (most recent call last):
[rank13]:   File "train.py", line 986, in <module>
[rank13]:     main(args, device, world_size, world_rank, local_rank)
[rank13]:   File "train.py", line 890, in main
[rank13]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank13]:   File "train.py", line 372, in training_step
[rank13]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank13]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank13]:     return forward_call(*args, **kwargs)
[rank13]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank13]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank13]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank13]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank13]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank13]:     return _AllGather.apply(group, tensor)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank13]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank13]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank13]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank13]:     return func(*args, **kwargs)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank13]:     work = group.allgather([tensor_list], [tensor])
[rank13]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 5 has a total capacity of 63.98 GiB of which 20.65 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 890, in main
[rank11]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank11]:   File "train.py", line 372, in training_step
[rank11]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank11]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank11]:     return forward_call(*args, **kwargs)
[rank11]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank11]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank11]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank11]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank11]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank11]:     return _AllGather.apply(group, tensor)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank11]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank11]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank11]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank11]:     work = group.allgather([tensor_list], [tensor])
[rank11]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 20.46 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 890, in main
[rank14]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank14]:   File "train.py", line 372, in training_step
[rank14]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank14]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank14]:     return forward_call(*args, **kwargs)
[rank14]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank14]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank14]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank14]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank14]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank14]:     return _AllGather.apply(group, tensor)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank14]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank14]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank14]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank14]:     work = group.allgather([tensor_list], [tensor])
[rank14]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 6 has a total capacity of 63.98 GiB of which 20.46 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank4]: Traceback (most recent call last):
[rank4]:   File "train.py", line 986, in <module>
[rank4]:     main(args, device, world_size, world_rank, local_rank)
[rank4]:   File "train.py", line 890, in main
[rank4]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank4]:   File "train.py", line 372, in training_step
[rank4]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank4]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank4]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank4]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank4]:     return _AllGather.apply(group, tensor)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank4]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank4]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank4]:     return func(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank4]:     work = group.allgather([tensor_list], [tensor])
[rank4]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 4 has a total capacity of 63.98 GiB of which 20.46 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank7]: Traceback (most recent call last):
[rank7]:   File "train.py", line 986, in <module>
[rank7]:     main(args, device, world_size, world_rank, local_rank)
[rank7]:   File "train.py", line 890, in main
[rank7]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank7]:   File "train.py", line 372, in training_step
[rank7]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank7]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank7]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank7]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank7]:     return _AllGather.apply(group, tensor)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank7]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank7]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank7]:     return func(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank7]:     work = group.allgather([tensor_list], [tensor])
[rank7]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 7 has a total capacity of 63.98 GiB of which 20.65 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "train.py", line 986, in <module>
[rank0]:     main(args, device, world_size, world_rank, local_rank)
[rank0]:   File "train.py", line 890, in main
[rank0]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank0]:   File "train.py", line 372, in training_step
[rank0]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank0]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank0]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank0]:     return _AllGather.apply(group, tensor)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank0]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank0]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank0]:     work = group.allgather([tensor_list], [tensor])
[rank0]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 0 has a total capacity of 63.98 GiB of which 20.65 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 114.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank2]: Traceback (most recent call last):
[rank2]:   File "train.py", line 986, in <module>
[rank2]:     main(args, device, world_size, world_rank, local_rank)
[rank2]:   File "train.py", line 890, in main
[rank2]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank2]:   File "train.py", line 372, in training_step
[rank2]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank2]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank2]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank2]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank2]:     return _AllGather.apply(group, tensor)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank2]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank2]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank2]:     work = group.allgather([tensor_list], [tensor])
[rank2]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 36.00 GiB. GPU 2 has a total capacity of 63.98 GiB of which 20.65 GiB is free. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 112.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:07,407] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:07,407] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:07,407] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:07,407] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:07,998] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:07,998] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:07,998] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:07,998] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:08,301] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:08,301] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:08,301] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:08,301] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:08,301] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:08,301] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:08,301] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:08,301] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=1024, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 7 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 7 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 2 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 9 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 11 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 15 After initialize parallelism groups
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 5 Before initialize parallelism groups
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 5 After initialize parallelism groups
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 6 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 3 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 6 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 11 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 1024, 6144])
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 6144])
rank 2 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
rank 3 After the second dist.barrier()
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.512.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.512.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.513.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.513.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.514.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.514.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.515.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.515.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.516.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.516.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.517.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.517.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.518.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.518.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.519.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.519.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.520.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.520.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.521.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.521.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.522.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.522.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.523.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.523.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.524.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.524.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.525.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.525.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.526.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.526.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.527.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.527.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.528.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.528.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.529.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.529.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.530.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.530.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.531.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.531.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.532.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.532.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.533.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.533.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.534.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.534.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.535.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.535.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.536.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.536.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.537.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.537.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.538.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.538.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.539.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.539.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.540.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.540.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.541.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.541.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.542.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.542.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.543.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.543.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.544.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.544.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.545.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.545.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.546.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.546.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.547.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.547.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.548.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.548.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.549.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.549.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.550.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.550.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.551.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.551.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.552.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.552.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.553.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.553.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.554.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.554.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.555.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.555.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.556.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.556.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.557.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.557.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.558.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.558.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.559.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.559.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.560.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.560.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.561.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.561.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.562.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.562.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.563.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.563.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.564.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.564.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.565.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.565.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.566.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.566.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.567.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.567.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.568.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.568.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.569.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.569.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.570.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.570.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.571.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.571.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.572.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.572.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.573.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.573.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.574.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.574.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.575.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.575.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.576.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.576.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.577.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.577.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.578.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.578.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.579.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.579.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.580.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.580.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.581.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.581.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.582.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.582.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.583.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.583.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.584.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.584.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.585.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.585.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.586.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.586.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.587.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.587.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.588.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.588.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.589.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.589.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.590.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.590.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.591.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.591.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.592.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.592.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.593.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.593.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.594.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.594.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.595.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.595.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.596.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.596.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.597.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.597.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.598.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.598.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.599.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.599.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.600.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.600.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.601.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.601.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.602.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.602.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.603.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.603.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.604.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.604.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.605.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.605.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.606.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.606.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.607.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.607.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.608.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.608.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.609.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.609.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.610.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.610.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.611.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.611.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.612.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.612.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.613.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.613.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.614.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.614.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.615.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.615.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.616.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.616.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.617.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.617.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.618.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.618.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.619.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.619.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.620.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.620.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.621.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.621.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.622.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.622.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.623.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.623.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.624.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.624.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.625.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.625.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.626.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.626.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.627.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.627.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.628.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.628.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.629.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.629.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.630.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.630.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.631.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.631.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.632.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.632.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.633.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.633.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.634.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.634.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.635.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.635.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.636.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.636.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.637.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.637.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.638.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.638.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.639.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.639.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.640.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.640.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.641.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.641.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.642.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.642.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.643.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.643.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.644.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.644.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.645.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.645.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.646.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.646.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.647.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.647.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.648.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.648.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.649.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.649.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.650.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.650.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.651.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.651.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.652.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.652.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.653.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.653.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.654.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.654.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.655.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.655.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.656.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.656.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.657.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.657.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.658.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.658.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.659.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.659.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.660.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.660.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.661.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.661.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.662.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.662.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.663.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.663.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.664.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.664.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.665.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.665.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.666.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.666.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.667.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.667.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.668.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.668.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.669.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.669.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.670.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.670.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.671.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.671.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.672.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.672.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.673.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.673.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.674.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.674.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.675.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.675.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.676.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.676.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.677.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.677.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.678.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.678.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.679.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.679.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.680.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.680.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.681.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.681.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.682.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.682.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.683.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.683.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.684.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.684.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.685.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.685.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.686.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.686.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.687.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.687.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.688.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.688.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.689.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.689.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.690.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.690.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.691.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.691.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.692.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.692.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.693.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.693.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.694.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.694.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.695.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.695.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.696.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.696.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.697.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.697.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.698.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.698.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.699.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.699.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.700.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.700.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.701.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.701.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.702.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.702.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.703.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.703.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.704.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.704.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.705.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.705.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.706.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.706.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.707.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.707.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.708.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.708.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.709.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.709.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.710.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.710.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.711.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.711.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.712.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.712.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.713.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.713.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.714.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.714.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.715.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.715.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.716.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.716.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.717.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.717.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.718.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.718.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.719.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.719.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.720.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.720.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.721.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.721.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.722.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.722.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.723.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.723.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.724.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.724.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.725.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.725.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.726.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.726.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.727.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.727.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.728.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.728.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.729.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.729.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.730.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.730.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.731.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.731.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.732.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.732.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.733.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.733.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.734.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.734.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.735.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.735.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.736.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.736.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.737.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.737.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.738.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.738.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.739.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.739.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.740.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.740.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.741.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.741.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.742.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.742.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.743.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.743.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.744.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.744.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.745.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.745.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.746.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.746.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.747.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.747.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.748.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.748.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.749.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.749.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.750.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.750.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.751.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.751.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.752.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.752.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.753.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.753.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.754.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.754.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.755.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.755.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.756.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.756.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.757.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.757.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.758.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.758.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.759.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.759.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.760.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.760.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.761.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.761.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.762.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.762.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.763.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.763.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.764.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.764.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.765.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.765.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.766.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.766.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.767.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.767.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.768.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.768.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.769.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.769.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.770.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.770.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.771.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.771.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.772.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.772.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.773.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.773.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.774.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.774.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.775.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.775.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.776.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.776.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.777.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.777.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.778.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.778.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.779.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.779.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.780.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.780.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.781.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.781.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.782.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.782.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.783.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.783.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.784.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.784.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.785.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.785.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.786.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.786.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.787.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.787.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.788.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.788.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.789.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.789.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.790.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.790.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.791.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.791.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.792.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.792.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.793.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.793.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.794.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.794.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.795.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.795.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.796.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.796.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.797.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.797.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.798.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.798.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.799.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.799.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.800.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.800.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.801.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.801.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.802.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.802.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.803.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.803.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.804.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.804.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.805.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.805.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.806.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.806.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.807.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.807.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.808.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.808.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.809.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.809.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.810.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.810.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.811.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.811.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.812.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.812.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.813.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.813.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.814.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.814.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.815.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.815.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.816.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.816.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.817.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.817.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.818.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.818.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.819.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.819.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.820.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.820.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.821.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.821.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.822.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.822.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.823.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.823.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.824.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.824.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.825.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.825.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.826.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.826.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.827.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.827.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.828.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.828.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.829.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.829.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.830.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.830.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.831.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.831.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.832.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.832.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.833.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.833.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.834.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.834.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.835.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.835.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.836.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.836.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.837.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.837.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.838.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.838.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.839.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.839.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.840.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.840.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.841.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.841.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.842.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.842.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.843.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.843.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.844.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.844.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.845.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.845.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.846.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.846.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.847.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.847.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.848.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.848.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.849.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.849.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.850.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.850.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.851.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.851.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.852.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.852.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.853.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.853.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.854.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.854.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.855.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.855.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.856.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.856.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.857.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.857.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.858.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.858.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.859.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.859.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.860.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.860.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.861.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.861.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.862.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.862.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.863.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.863.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.864.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.864.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.865.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.865.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.866.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.866.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.867.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.867.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.868.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.868.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.869.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.869.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.870.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.870.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.871.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.871.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.872.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.872.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.873.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.873.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.874.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.874.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.875.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.875.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.876.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.876.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.877.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.877.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.878.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.878.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.879.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.879.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.880.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.880.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.881.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.881.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.882.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.882.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.883.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.883.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.884.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.884.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.885.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.885.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.886.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.886.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.887.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.887.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.888.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.888.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.889.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.889.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.890.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.890.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.891.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.891.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.892.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.892.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.893.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.893.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.894.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.894.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.895.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.895.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.896.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.896.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.897.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.897.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.898.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.898.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.899.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.899.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.900.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.900.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.901.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.901.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.902.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.902.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.903.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.903.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.904.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.904.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.905.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.905.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.906.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.906.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.907.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.907.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.908.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.908.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.909.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.909.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.910.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.910.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.911.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.911.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.912.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.912.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.913.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.913.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.914.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.914.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.915.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.915.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.916.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.916.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.917.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.917.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.918.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.918.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.919.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.919.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.920.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.920.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.921.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.921.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.922.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.922.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.923.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.923.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.924.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.924.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.925.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.925.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.926.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.926.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.927.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.927.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.928.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.928.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.929.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.929.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.930.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.930.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.931.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.931.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.932.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.932.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.933.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.933.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.934.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.934.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.935.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.935.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.936.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.936.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.937.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.937.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.938.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.938.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.939.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.939.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.940.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.940.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.941.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.941.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.942.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.942.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.943.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.943.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.944.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.944.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.945.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.945.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.946.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.946.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.947.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.947.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.948.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.948.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.949.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.949.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.950.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.950.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.951.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.951.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.952.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.952.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.953.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.953.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.954.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.954.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.955.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.955.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.956.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.956.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.957.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.957.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.958.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.958.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.959.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.959.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.960.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.960.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.961.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.961.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.962.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.962.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.963.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.963.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.964.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.964.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.965.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.965.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.966.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.966.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.967.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.967.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.968.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.968.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.969.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.969.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.970.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.970.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.971.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.971.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.972.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.972.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.973.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.973.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.974.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.974.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.975.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.975.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.976.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.976.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.977.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.977.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.978.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.978.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.979.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.979.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.980.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.980.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.981.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.981.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.982.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.982.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.983.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.983.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.984.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.984.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.985.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.985.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.986.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.986.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.987.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.987.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.988.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.988.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.989.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.989.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.990.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.990.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.991.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.991.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.992.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.992.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.993.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.993.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.994.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.994.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.995.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.995.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.996.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.996.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.997.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.997.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.998.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.998.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.999.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.999.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1000.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1000.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1001.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1001.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1002.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1002.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1003.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1003.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1004.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1004.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1005.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1005.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1006.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1006.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1007.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1007.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1008.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1008.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1009.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1009.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1010.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1010.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1011.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1011.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1012.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1012.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1013.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1013.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1014.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1014.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1015.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1015.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1016.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1016.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1017.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1017.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1018.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1018.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1019.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1019.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1020.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1020.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1021.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1021.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1022.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1022.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1023.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1023.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([384, 6144])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([768, 6144])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([16384, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([16384])
total_params before FSDP tensor(453130240) params_per_gpu tensor(311480320)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-1023): 1024 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=6144, out_features=384, bias=False)
          (kv): Linear(in_features=6144, out_features=768, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=6144, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=16384, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank5]: Traceback (most recent call last):
[rank5]:   File "train.py", line 986, in <module>
[rank5]:     main(args, device, world_size, world_rank, local_rank)
[rank5]:   File "train.py", line 890, in main
[rank5]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank5]:   File "train.py", line 372, in training_step
[rank5]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank5]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank5]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank5]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank5]:     return _AllGather.apply(group, tensor)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank5]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank5]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank5]:     return func(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank5]:     work = group.allgather([tensor_list], [tensor])
[rank5]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 5 has a total capacity of 63.98 GiB of which 6.73 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank2]: Traceback (most recent call last):
[rank2]:   File "train.py", line 986, in <module>
[rank2]:     main(args, device, world_size, world_rank, local_rank)
[rank2]:   File "train.py", line 890, in main
[rank2]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank2]:   File "train.py", line 372, in training_step
[rank2]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank2]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank2]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank2]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank2]:     return _AllGather.apply(group, tensor)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank2]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank2]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank2]:     work = group.allgather([tensor_list], [tensor])
[rank2]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 2 has a total capacity of 63.98 GiB of which 6.73 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank6]: Traceback (most recent call last):
[rank6]:   File "train.py", line 986, in <module>
[rank6]:     main(args, device, world_size, world_rank, local_rank)
[rank6]:   File "train.py", line 890, in main
[rank6]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank6]:   File "train.py", line 372, in training_step
[rank6]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank6]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank6]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank6]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank6]:     return _AllGather.apply(group, tensor)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank6]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank6]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank6]:     return func(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank6]:     work = group.allgather([tensor_list], [tensor])
[rank6]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 6 has a total capacity of 63.98 GiB of which 6.54 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 890, in main
[rank1]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank1]:   File "train.py", line 372, in training_step
[rank1]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank1]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank1]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank1]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank1]:     return _AllGather.apply(group, tensor)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank1]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank1]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank1]:     work = group.allgather([tensor_list], [tensor])
[rank1]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 6.54 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank7]: Traceback (most recent call last):
[rank7]:   File "train.py", line 986, in <module>
[rank7]:     main(args, device, world_size, world_rank, local_rank)
[rank7]:   File "train.py", line 890, in main
[rank7]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank7]:   File "train.py", line 372, in training_step
[rank7]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank7]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank7]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank7]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank7]:     return _AllGather.apply(group, tensor)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank7]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank7]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank7]:     return func(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank7]:     work = group.allgather([tensor_list], [tensor])
[rank7]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 7 has a total capacity of 63.98 GiB of which 6.73 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "train.py", line 986, in <module>
[rank0]:     main(args, device, world_size, world_rank, local_rank)
[rank0]:   File "train.py", line 890, in main
[rank0]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank0]:   File "train.py", line 372, in training_step
[rank0]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank0]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank0]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank0]:     return _AllGather.apply(group, tensor)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank0]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank0]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank0]:     work = group.allgather([tensor_list], [tensor])
[rank0]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 63.98 GiB of which 6.73 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 140.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 986, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 890, in main
[rank3]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank3]:   File "train.py", line 372, in training_step
[rank3]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank3]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank3]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank3]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank3]:     return _AllGather.apply(group, tensor)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank3]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank3]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank3]:     work = group.allgather([tensor_list], [tensor])
[rank3]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 6.54 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank13]: Traceback (most recent call last):
[rank13]:   File "train.py", line 986, in <module>
[rank13]:     main(args, device, world_size, world_rank, local_rank)
[rank13]:   File "train.py", line 890, in main
[rank13]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank13]:   File "train.py", line 372, in training_step
[rank13]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank13]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank13]:     return self._call_impl(*args, **kwargs)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank13]:     return forward_call(*args, **kwargs)
[rank13]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank13]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank13]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank13]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank13]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank13]:     return _AllGather.apply(group, tensor)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank13]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank13]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank13]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank13]:     return func(*args, **kwargs)
[rank13]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank13]:     work = group.allgather([tensor_list], [tensor])
[rank13]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 5 has a total capacity of 63.98 GiB of which 6.73 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 890, in main
[rank9]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank9]:   File "train.py", line 372, in training_step
[rank9]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank9]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank9]:     return self._call_impl(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank9]:     return forward_call(*args, **kwargs)
[rank9]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank9]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank9]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank9]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank9]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank9]:     return _AllGather.apply(group, tensor)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank9]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank9]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank9]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank9]:     work = group.allgather([tensor_list], [tensor])
[rank9]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 6.54 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 890, in main
[rank15]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank15]:   File "train.py", line 372, in training_step
[rank15]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank15]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank15]:     return self._call_impl(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank15]:     return forward_call(*args, **kwargs)
[rank15]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank15]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank15]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank15]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank15]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank15]:     return _AllGather.apply(group, tensor)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank15]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank15]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank15]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank15]:     work = group.allgather([tensor_list], [tensor])
[rank15]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 7 has a total capacity of 63.98 GiB of which 6.73 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank10]: Traceback (most recent call last):
[rank10]:   File "train.py", line 986, in <module>
[rank10]:     main(args, device, world_size, world_rank, local_rank)
[rank10]:   File "train.py", line 890, in main
[rank10]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank10]:   File "train.py", line 372, in training_step
[rank10]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank10]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank10]:     return self._call_impl(*args, **kwargs)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank10]:     return forward_call(*args, **kwargs)
[rank10]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank10]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank10]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank10]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank10]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank10]:     return _AllGather.apply(group, tensor)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank10]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank10]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank10]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank10]:     return func(*args, **kwargs)
[rank10]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank10]:     work = group.allgather([tensor_list], [tensor])
[rank10]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 2 has a total capacity of 63.98 GiB of which 6.73 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 890, in main
[rank14]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank14]:   File "train.py", line 372, in training_step
[rank14]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank14]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank14]:     return self._call_impl(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank14]:     return forward_call(*args, **kwargs)
[rank14]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank14]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank14]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank14]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank14]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank14]:     return _AllGather.apply(group, tensor)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank14]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank14]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank14]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank14]:     work = group.allgather([tensor_list], [tensor])
[rank14]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 6 has a total capacity of 63.98 GiB of which 6.54 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank4]: Traceback (most recent call last):
[rank4]:   File "train.py", line 986, in <module>
[rank4]:     main(args, device, world_size, world_rank, local_rank)
[rank4]:   File "train.py", line 890, in main
[rank4]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank4]:   File "train.py", line 372, in training_step
[rank4]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank4]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank4]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank4]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank4]:     return _AllGather.apply(group, tensor)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank4]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank4]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank4]:     return func(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank4]:     work = group.allgather([tensor_list], [tensor])
[rank4]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 4 has a total capacity of 63.98 GiB of which 6.54 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 890, in main
[rank12]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank12]:   File "train.py", line 372, in training_step
[rank12]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank12]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank12]:     return self._call_impl(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank12]:     return forward_call(*args, **kwargs)
[rank12]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank12]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank12]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank12]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank12]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank12]:     return _AllGather.apply(group, tensor)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank12]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank12]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank12]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank12]:     work = group.allgather([tensor_list], [tensor])
[rank12]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 4 has a total capacity of 63.98 GiB of which 6.54 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 890, in main
[rank8]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank8]:   File "train.py", line 372, in training_step
[rank8]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank8]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank8]:     return self._call_impl(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank8]:     return forward_call(*args, **kwargs)
[rank8]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank8]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank8]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank8]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank8]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank8]:     return _AllGather.apply(group, tensor)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank8]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank8]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank8]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank8]:     work = group.allgather([tensor_list], [tensor])
[rank8]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 63.98 GiB of which 6.73 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 890, in main
[rank11]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank11]:   File "train.py", line 372, in training_step
[rank11]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank11]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank11]:     return self._call_impl(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank11]:     return forward_call(*args, **kwargs)
[rank11]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank11]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank11]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank11]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank11]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank11]:     return _AllGather.apply(group, tensor)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank11]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank11]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank11]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank11]:     work = group.allgather([tensor_list], [tensor])
[rank11]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 48.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 6.54 GiB is free. Of the allocated memory 56.10 GiB is allocated by PyTorch, and 138.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,888] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,888] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,888] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,888] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,888] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,888] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,888] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,888] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,960] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,960] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,960] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,960] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,960] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,960] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,960] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:01:44,960] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=32, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 4 After initialize parallelism groups
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 10 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 10 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 14 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 13 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 15 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 0 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 6144])
rank 1 After the second dist.barrier()
rank 5 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 6144])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 4 After the second dist.barrier()
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 6 After the second dist.barrier()
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 7 After the second dist.barrier()
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
rank 3 After the second dist.barrier()
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 2 After the second dist.barrier()
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([384, 6144])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([768, 6144])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  norm.weight  requires_gradient  True size torch.Size([6144])
parameter name  norm.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(14749870592) params_per_gpu tensor(1011487232)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=6144, out_features=384, bias=False)
          (kv): Linear(in_features=6144, out_features=768, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=6144, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=6144, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=6144, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=6144, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=1536, out_features=6144, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 0 world_rank 0  loss  3.1875
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 1 world_rank 0  loss  nan
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 2 world_rank 0  loss  nan
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 3 world_rank 0  loss  nan
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,097] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,098] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:02:24,098] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,099] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,099] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,100] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,101] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,101] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,104] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,106] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,107] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,107] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,108] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,109] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,109] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,109] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,807] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,807] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,807] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,807] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,807] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,807] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,807] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,807] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,808] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,808] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,808] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,808] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,808] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,808] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,808] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 2, 2048, 6144])
2 torch.Size([2, 32, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:02:24,808] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 1011.487232 M TFLOPS: 24.090320672599493

--> cuda max reserved memory = 27.2402
--> max reserved percentage = 42.57 %

--> cuda max memory allocated = 20.2633
--> max allocated percentage = 31.67 %

--> peak active memory = 24.8775
--> peak active memory 38.88 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=32, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 27.2402 24.090320672599493 tensor(14749870592)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,213] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,213] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,213] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,213] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,213] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,213] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,213] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,213] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,333] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,333] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,333] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,333] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,333] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,333] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,333] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:02:38,333] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=64, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 9 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 13 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 11 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 10 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 11 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 9 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 6144])
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 6144])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 3 After the second dist.barrier()
rank 2 After the second dist.barrier()
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([384, 6144])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([768, 6144])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  norm.weight  requires_gradient  True size torch.Size([6144])
parameter name  norm.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(14756555776) params_per_gpu tensor(1018172416)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=6144, out_features=384, bias=False)
          (kv): Linear(in_features=6144, out_features=768, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=6144, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=6144, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=6144, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=6144, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=1536, out_features=6144, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 0 world_rank 0  loss  nan
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 1 world_rank 0  loss  nan
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 2 world_rank 0  loss  nan
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,560] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 3 world_rank 0  loss  nan
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,563] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,564] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,564] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,564] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:03:17,565] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,566] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,568] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,570] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,572] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,572] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,572] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:17,572] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,391] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,391] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,391] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,391] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,391] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,391] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,391] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,391] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,392] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,392] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,392] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,392] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,392] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,392] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,392] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 6144])
2 torch.Size([2, 64, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:03:18,392] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 1018.172416 M TFLOPS: 22.77941958183209

--> cuda max reserved memory = 34.8906
--> max reserved percentage = 54.53 %

--> cuda max memory allocated = 25.264
--> max allocated percentage = 39.48 %

--> peak active memory = 31.2292
--> peak active memory 48.81 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=64, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 34.8906 22.77941958183209 tensor(14756555776)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,847] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,847] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,847] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,847] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,847] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,847] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,847] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,847] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,938] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,938] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,938] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,938] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,938] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,938] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,938] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:03:31,938] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=128, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 6 After initialize parallelism groups
rank 2 After initialize parallelism groups
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 8 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 15 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 9 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 6144])
rank 12 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 6144])
rank 13 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
rank 14 After the second dist.barrier()
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 15 After the second dist.barrier()
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([384, 6144])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([768, 6144])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  norm.weight  requires_gradient  True size torch.Size([6144])
parameter name  norm.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(14769926144) params_per_gpu tensor(1031542784)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=6144, out_features=384, bias=False)
          (kv): Linear(in_features=6144, out_features=768, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=6144, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=6144, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=6144, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=6144, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=1536, out_features=6144, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 0 world_rank 0  loss  3.6875
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 1 world_rank 0  loss  nan
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 2 world_rank 0  loss  nan
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 3 world_rank 0  loss  nan
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,987] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,988] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,988] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:04:13,988] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,989] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,992] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,992] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,992] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,992] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,993] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,993] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,993] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,994] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,994] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,996] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:13,998] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,017] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,017] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,017] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,017] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,017] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,017] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,017] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,018] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,017] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,018] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,018] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,018] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,018] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,018] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,018] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 6144])
2 torch.Size([2, 128, 2048, 6144])
3 torch.Size([2, 2048, 6144])
[2025-03-07 22:04:15,018] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 1031.542784 M TFLOPS: 21.12128389072289

--> cuda max reserved memory = 45.0312
--> max reserved percentage = 70.38 %

--> cuda max memory allocated = 35.2614
--> max allocated percentage = 55.11 %

--> peak active memory = 41.6364
--> peak active memory 65.07 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=128, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 45.0312 21.12128389072289 tensor(14769926144)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,390] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,390] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,390] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,390] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,390] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,390] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,390] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,390] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,556] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,556] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,556] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,556] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,556] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,556] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,556] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:04:28,556] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=256, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 4 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 9 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 6144 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 9 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 256, 6144])
rank 9 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 6144])
rank 12 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 6144])
rank 13 After the second dist.barrier()
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 14 After the second dist.barrier()
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([6144])
rank 15 After the second dist.barrier()
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([6144, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([384, 6144])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([768, 6144])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([6144, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1152, 6144])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1152])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([6144, 384])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([6144])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([1536, 6144])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([6144, 1536])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([6144])
parameter name  norm.weight  requires_gradient  True size torch.Size([6144])
parameter name  norm.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.0.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.0.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.2.weight  requires_gradient  True size torch.Size([6144, 6144])
parameter name  head.2.bias  requires_gradient  True size torch.Size([6144])
parameter name  head.5.weight  requires_gradient  True size torch.Size([4096, 6144])
parameter name  head.5.bias  requires_gradient  True size torch.Size([4096])
total_params before FSDP tensor(14796666880) params_per_gpu tensor(1058283520)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-255): 256 x PatchEmbed(
        (proj): Conv2d(1, 6144, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=6144, out_features=384, bias=False)
          (kv): Linear(in_features=6144, out_features=768, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=6144, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=6144, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=6144, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=6144, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=6144, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=1536, out_features=6144, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=6144, out_features=6144, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=6144, out_features=6144, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=6144, out_features=4096, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
epoch-train:  0 batch_idx 0 world_rank 0  loss  3.75
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 892, in main
[rank12]:     loss.backward()
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/_tensor.py", line 524, in backward
[rank12]:     torch.autograd.backward(
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank12]:     _engine_run_backward(
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank12]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank12]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 12.00 GiB. GPU 4 has a total capacity of 63.98 GiB of which 5.99 GiB is free. Of the allocated memory 29.29 GiB is allocated by PyTorch, and 27.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 892, in main
[rank9]:     loss.backward()
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/_tensor.py", line 524, in backward
[rank9]:     torch.autograd.backward(
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank9]:     _engine_run_backward(
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank9]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank9]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 12.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 5.85 GiB is free. Of the allocated memory 29.29 GiB is allocated by PyTorch, and 27.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 892, in main
[rank11]:     loss.backward()
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/_tensor.py", line 524, in backward
[rank11]:     torch.autograd.backward(
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank11]:     _engine_run_backward(
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank11]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank11]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 12.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 6.04 GiB is free. Of the allocated memory 29.29 GiB is allocated by PyTorch, and 27.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 892, in main
[rank14]:     loss.backward()
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/_tensor.py", line 524, in backward
[rank14]:     torch.autograd.backward(
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank14]:     _engine_run_backward(
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank14]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank14]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 12.00 GiB. GPU 6 has a total capacity of 63.98 GiB of which 6.74 GiB is free. Of the allocated memory 29.29 GiB is allocated by PyTorch, and 26.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 892, in main
[rank15]:     loss.backward()
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/_tensor.py", line 524, in backward
[rank15]:     torch.autograd.backward(
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank15]:     _engine_run_backward(
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank15]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank15]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 12.00 GiB. GPU 7 has a total capacity of 63.98 GiB of which 6.93 GiB is free. Of the allocated memory 29.29 GiB is allocated by PyTorch, and 26.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 892, in main
[rank1]:     loss.backward()
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/_tensor.py", line 524, in backward
[rank1]:     torch.autograd.backward(
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank1]:     _engine_run_backward(
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank1]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank1]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 12.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 6.09 GiB is free. Of the allocated memory 29.29 GiB is allocated by PyTorch, and 27.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
torch.Size([2, 16, 2048, 6144])
2 torch.Size([2, 256, 2048, 6144])
3 torch.Size([2, 2048, 6144])
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 892, in main
[rank8]:     loss.backward()
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/_tensor.py", line 524, in backward
[rank8]:     torch.autograd.backward(
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank8]:     _engine_run_backward(
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank8]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank8]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacity of 63.98 GiB of which 6.18 GiB is free. Of the allocated memory 29.29 GiB is allocated by PyTorch, and 27.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:21,661] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:21,899] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:21,899] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:21,899] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:21,899] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:21,899] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:21,899] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 1 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 12 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
rank 9 After initialize model
rank 9 Before the second dist.barrier()
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 663, in main
[rank1]:     dist.barrier()
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank1]:     work = default_pg.barrier(opts=opts)
[rank1]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank1]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank1]: Last error:
[rank1]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 8 After initialize model
rank 8 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 663, in main
[rank11]:     dist.barrier()
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank11]:     work = default_pg.barrier(opts=opts)
[rank11]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank11]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank11]: Last error:
[rank11]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 663, in main
[rank9]:     dist.barrier()
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank9]:     work = default_pg.barrier(opts=opts)
[rank9]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank9]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank9]: Last error:
[rank9]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 663, in main
[rank8]:     dist.barrier()
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank8]:     work = default_pg.barrier(opts=opts)
[rank8]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank8]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank8]: Last error:
[rank8]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 663, in main
[rank14]:     dist.barrier()
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank14]:     work = default_pg.barrier(opts=opts)
[rank14]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank14]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank14]: Last error:
[rank14]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 663, in main
[rank15]:     dist.barrier()
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank15]:     work = default_pg.barrier(opts=opts)
[rank15]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank15]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank15]: Last error:
[rank15]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:48,922] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:49,111] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:49,111] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:49,111] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:49,111] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:05:49,111] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 1 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 15 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 9 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 11 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 12 After initialize model
rank 12 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 663, in main
[rank12]:     dist.barrier()
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank12]:     work = default_pg.barrier(opts=opts)
[rank12]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank12]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank12]: Last error:
[rank12]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 663, in main
[rank1]:     dist.barrier()
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank1]:     work = default_pg.barrier(opts=opts)
[rank1]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank1]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank1]: Last error:
[rank1]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 663, in main
[rank8]:     dist.barrier()
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank8]:     work = default_pg.barrier(opts=opts)
[rank8]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank8]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank8]: Last error:
[rank8]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 15 After initialize model
rank 15 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 663, in main
[rank11]:     dist.barrier()
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank11]:     work = default_pg.barrier(opts=opts)
[rank11]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank11]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank11]: Last error:
[rank11]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 663, in main
[rank15]:     dist.barrier()
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank15]:     work = default_pg.barrier(opts=opts)
[rank15]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank15]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank15]: Last error:
[rank15]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 14 After initialize model
rank 14 Before the second dist.barrier()
sleeping...
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 663, in main
[rank14]:     dist.barrier()
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank14]:     work = default_pg.barrier(opts=opts)
[rank14]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank14]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank14]: Last error:
[rank14]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
sleeping...
sleeping...
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:06,214] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
sleeping...
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 12 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 9 After initialize model
rank 9 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 663, in main
[rank9]:     dist.barrier()
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank9]:     work = default_pg.barrier(opts=opts)
[rank9]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank9]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank9]: Last error:
[rank9]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
Done
sleeping...
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:16,695] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:16,695] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:16,695] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:16,717] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 15 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 8 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 1 After initialize parallelism groups
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:17,430] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 14 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 12 After initialize model
rank 12 Before the second dist.barrier()
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:21,670] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 663, in main
[rank12]:     dist.barrier()
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank12]:     work = default_pg.barrier(opts=opts)
[rank12]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank12]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank12]: Last error:
[rank12]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 9 Before initialize parallelism groups
rank 9 After initialize parallelism groups
sleeping...
Done
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 663, in main
[rank8]:     dist.barrier()
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank8]:     work = default_pg.barrier(opts=opts)
[rank8]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank8]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank8]: Last error:
[rank8]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 15 After initialize model
rank 15 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 663, in main
[rank11]:     dist.barrier()
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank11]:     work = default_pg.barrier(opts=opts)
[rank11]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank11]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank11]: Last error:
[rank11]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 663, in main
[rank1]:     dist.barrier()
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank1]:     work = default_pg.barrier(opts=opts)
[rank1]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank1]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank1]: Last error:
[rank1]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 663, in main
[rank15]:     dist.barrier()
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank15]:     work = default_pg.barrier(opts=opts)
[rank15]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank15]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank15]: Last error:
[rank15]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
sleeping...
sleeping...
sleeping...
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:34,266] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 12 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 9 After initialize model
rank 9 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 663, in main
[rank9]:     dist.barrier()
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank9]:     work = default_pg.barrier(opts=opts)
[rank9]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank9]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank9]: Last error:
[rank9]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
Done
Done
Done
rank 14 After initialize model
rank 14 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 663, in main
[rank14]:     dist.barrier()
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank14]:     work = default_pg.barrier(opts=opts)
[rank14]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank14]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank14]: Last error:
[rank14]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:45,135] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:45,135] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:45,135] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:45,186] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 11 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 15 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 1 After initialize parallelism groups
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:49,535] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 9 Before initialize parallelism groups
rank 9 After initialize parallelism groups
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:06:52,471] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 14 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 663, in main
[rank8]:     dist.barrier()
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank8]:     work = default_pg.barrier(opts=opts)
[rank8]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank8]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank8]: Last error:
[rank8]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 15 After initialize model
rank 15 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 663, in main
[rank11]:     dist.barrier()
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank11]:     work = default_pg.barrier(opts=opts)
[rank11]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank11]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank11]: Last error:
[rank11]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 663, in main
[rank1]:     dist.barrier()
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank1]:     work = default_pg.barrier(opts=opts)
[rank1]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank1]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank1]: Last error:
[rank1]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 663, in main
[rank15]:     dist.barrier()
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank15]:     work = default_pg.barrier(opts=opts)
[rank15]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank15]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank15]: Last error:
[rank15]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
sleeping...
sleeping...
sleeping...
rank 9 After initialize model
rank 9 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 663, in main
[rank9]:     dist.barrier()
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank9]:     work = default_pg.barrier(opts=opts)
[rank9]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank9]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank9]: Last error:
[rank9]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
Done
Done
Done
rank 14 After initialize model
rank 14 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 663, in main
[rank14]:     dist.barrier()
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank14]:     work = default_pg.barrier(opts=opts)
[rank14]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank14]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank14]: Last error:
[rank14]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:10,808] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:10,808] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:10,808] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:10,882] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 8 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 8 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 1 After initialize parallelism groups
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:14,700] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 9 Before initialize parallelism groups
rank 9 After initialize parallelism groups
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:18,482] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 14 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 663, in main
[rank8]:     dist.barrier()
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank8]:     work = default_pg.barrier(opts=opts)
[rank8]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank8]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank8]: Last error:
[rank8]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 663, in main
[rank11]:     dist.barrier()
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank11]:     work = default_pg.barrier(opts=opts)
[rank11]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank11]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank11]: Last error:
[rank11]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 663, in main
[rank15]:     dist.barrier()
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank15]:     work = default_pg.barrier(opts=opts)
[rank15]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank15]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank15]: Last error:
[rank15]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 663, in main
[rank1]:     dist.barrier()
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank1]:     work = default_pg.barrier(opts=opts)
[rank1]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank1]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank1]: Last error:
[rank1]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
sleeping...
sleeping...
sleeping...
rank 9 After initialize model
rank 9 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 663, in main
[rank9]:     dist.barrier()
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank9]:     work = default_pg.barrier(opts=opts)
[rank9]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank9]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank9]: Last error:
[rank9]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
Done
Done
Done
rank 14 After initialize model
rank 14 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 663, in main
[rank14]:     dist.barrier()
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank14]:     work = default_pg.barrier(opts=opts)
[rank14]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank14]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank14]: Last error:
[rank14]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:36,738] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:36,738] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:36,738] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:36,941] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 15 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 8 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 12 After initialize model
rank 12 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 663, in main
[rank12]:     dist.barrier()
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank12]:     work = default_pg.barrier(opts=opts)
[rank12]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank12]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank12]: Last error:
[rank12]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
Done
sleeping...
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:39,915] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 9 Before initialize parallelism groups
rank 9 After initialize parallelism groups
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:44,837] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 14 Before initialize parallelism groups
rank 14 After initialize parallelism groups
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:50,149] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 663, in main
[rank8]:     dist.barrier()
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank8]:     work = default_pg.barrier(opts=opts)
[rank8]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank8]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank8]: Last error:
[rank8]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 15 After initialize model
rank 15 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 663, in main
[rank11]:     dist.barrier()
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank11]:     work = default_pg.barrier(opts=opts)
[rank11]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank11]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank11]: Last error:
[rank11]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 12 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 663, in main
[rank15]:     dist.barrier()
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank15]:     work = default_pg.barrier(opts=opts)
[rank15]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank15]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank15]: Last error:
[rank15]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 663, in main
[rank1]:     dist.barrier()
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank1]:     work = default_pg.barrier(opts=opts)
[rank1]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank1]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank1]: Last error:
[rank1]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
sleeping...
sleeping...
sleeping...
rank 9 After initialize model
rank 9 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 663, in main
[rank9]:     dist.barrier()
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank9]:     work = default_pg.barrier(opts=opts)
[rank9]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank9]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank9]: Last error:
[rank9]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:02,800] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:02,800] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:02,800] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:03,009] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 11 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 15 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 12 After initialize model
rank 12 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 663, in main
[rank12]:     dist.barrier()
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank12]:     work = default_pg.barrier(opts=opts)
[rank12]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank12]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank12]: Last error:
[rank12]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:05,494] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 9 Before initialize parallelism groups
rank 9 After initialize parallelism groups
Done
rank 14 After initialize model
rank 14 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 663, in main
[rank14]:     dist.barrier()
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank14]:     work = default_pg.barrier(opts=opts)
[rank14]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank14]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank14]: Last error:
[rank14]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:16,323] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 12 Before initialize parallelism groups
rank 12 After initialize parallelism groups
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 663, in main
[rank8]:     dist.barrier()
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank8]:     work = default_pg.barrier(opts=opts)
[rank8]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank8]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank8]: Last error:
[rank8]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 663, in main
[rank11]:     dist.barrier()
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank11]:     work = default_pg.barrier(opts=opts)
[rank11]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank11]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank11]: Last error:
[rank11]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 663, in main
[rank15]:     dist.barrier()
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank15]:     work = default_pg.barrier(opts=opts)
[rank15]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank15]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank15]: Last error:
[rank15]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 663, in main
[rank1]:     dist.barrier()
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank1]:     work = default_pg.barrier(opts=opts)
[rank1]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank1]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank1]: Last error:
[rank1]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
Done
sleeping...
sleeping...
sleeping...
sleeping...
rank 9 After initialize model
rank 9 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 663, in main
[rank9]:     dist.barrier()
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank9]:     work = default_pg.barrier(opts=opts)
[rank9]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank9]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank9]: Last error:
[rank9]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:24,121] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 14 Before initialize parallelism groups
rank 14 After initialize parallelism groups
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:29,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:29,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:29,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:29,464] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 11 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 15 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 12 After initialize model
rank 12 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 663, in main
[rank12]:     dist.barrier()
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank12]:     work = default_pg.barrier(opts=opts)
[rank12]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank12]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank12]: Last error:
[rank12]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:31,572] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 9 Before initialize parallelism groups
rank 9 After initialize parallelism groups
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:42,737] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 12 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 663, in main
[rank8]:     dist.barrier()
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank8]:     work = default_pg.barrier(opts=opts)
[rank8]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank8]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank8]: Last error:
[rank8]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 663, in main
[rank11]:     dist.barrier()
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank11]:     work = default_pg.barrier(opts=opts)
[rank11]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank11]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank11]: Last error:
[rank11]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 1 After initialize model
rank 1 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 663, in main
[rank15]:     dist.barrier()
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank15]:     work = default_pg.barrier(opts=opts)
[rank15]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank15]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank15]: Last error:
[rank15]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 663, in main
[rank1]:     dist.barrier()
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank1]:     work = default_pg.barrier(opts=opts)
[rank1]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank1]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank1]: Last error:
[rank1]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
sleeping...
sleeping...
sleeping...
rank 9 After initialize model
rank 9 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 663, in main
[rank9]:     dist.barrier()
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank9]:     work = default_pg.barrier(opts=opts)
[rank9]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank9]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank9]: Last error:
[rank9]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:56,252] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:56,252] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:56,252] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:56,537] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
rank 12 After initialize model
rank 12 Before the second dist.barrier()
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 8 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 15 After initialize parallelism groups
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 663, in main
[rank12]:     dist.barrier()
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank12]:     work = default_pg.barrier(opts=opts)
[rank12]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank12]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank12]: Last error:
[rank12]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 1 After initialize parallelism groups
sleeping...
rank 14 After initialize model
rank 14 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 663, in main
[rank14]:     dist.barrier()
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank14]:     work = default_pg.barrier(opts=opts)
[rank14]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank14]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank14]: Last error:
[rank14]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:58,258] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
sleeping...
rank 9 Before initialize parallelism groups
rank 9 After initialize parallelism groups
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:08,892] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 12 Before initialize parallelism groups
rank 12 After initialize parallelism groups
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:09,874] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 14 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 663, in main
[rank8]:     dist.barrier()
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank8]:     work = default_pg.barrier(opts=opts)
[rank8]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank8]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank8]: Last error:
[rank8]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 663, in main
[rank11]:     dist.barrier()
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank11]:     work = default_pg.barrier(opts=opts)
[rank11]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank11]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank11]: Last error:
[rank11]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 1 After initialize model
rank 1 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 663, in main
[rank15]:     dist.barrier()
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank15]:     work = default_pg.barrier(opts=opts)
[rank15]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank15]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank15]: Last error:
[rank15]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 663, in main
[rank1]:     dist.barrier()
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank1]:     work = default_pg.barrier(opts=opts)
[rank1]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank1]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank1]: Last error:
[rank1]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
sleeping...
sleeping...
sleeping...
rank 9 After initialize model
rank 9 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 663, in main
[rank9]:     dist.barrier()
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank9]:     work = default_pg.barrier(opts=opts)
[rank9]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank9]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank9]: Last error:
[rank9]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
Done
Done
Done
Done
rank 12 After initialize model
rank 12 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 663, in main
[rank12]:     dist.barrier()
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank12]:     work = default_pg.barrier(opts=opts)
[rank12]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank12]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank12]: Last error:
[rank12]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:23,860] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:23,860] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:23,860] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
sleeping...
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:24,258] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 11 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 11 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 15 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 1 After initialize parallelism groups
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:25,709] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 9 Before initialize parallelism groups
rank 9 After initialize parallelism groups
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:35,588] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 12 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank8]: Traceback (most recent call last):
[rank8]:   File "train.py", line 986, in <module>
[rank8]:     main(args, device, world_size, world_rank, local_rank)
[rank8]:   File "train.py", line 663, in main
[rank8]:     dist.barrier()
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank8]:     return func(*args, **kwargs)
[rank8]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank8]:     work = default_pg.barrier(opts=opts)
[rank8]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank8]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank8]: Last error:
[rank8]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 15 After initialize model
rank 15 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank11]: Traceback (most recent call last):
[rank11]:   File "train.py", line 986, in <module>
[rank11]:     main(args, device, world_size, world_rank, local_rank)
[rank11]:   File "train.py", line 663, in main
[rank11]:     dist.barrier()
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank11]:     return func(*args, **kwargs)
[rank11]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank11]:     work = default_pg.barrier(opts=opts)
[rank11]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank11]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank11]: Last error:
[rank11]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank15]: Traceback (most recent call last):
[rank15]:   File "train.py", line 986, in <module>
[rank15]:     main(args, device, world_size, world_rank, local_rank)
[rank15]:   File "train.py", line 663, in main
[rank15]:     dist.barrier()
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank15]:     return func(*args, **kwargs)
[rank15]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank15]:     work = default_pg.barrier(opts=opts)
[rank15]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank15]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank15]: Last error:
[rank15]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
rank 1 After initialize model
rank 1 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 663, in main
[rank1]:     dist.barrier()
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank1]:     work = default_pg.barrier(opts=opts)
[rank1]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank1]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank1]: Last error:
[rank1]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
sleeping...
sleeping...
sleeping...
rank 9 After initialize model
rank 9 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank9]: Traceback (most recent call last):
[rank9]:   File "train.py", line 986, in <module>
[rank9]:     main(args, device, world_size, world_rank, local_rank)
[rank9]:   File "train.py", line 663, in main
[rank9]:     dist.barrier()
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank9]:     return func(*args, **kwargs)
[rank9]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank9]:     work = default_pg.barrier(opts=opts)
[rank9]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank9]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank9]: Last error:
[rank9]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
Done
Done
Done
Done
rank 12 After initialize model
rank 12 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 663, in main
[rank12]:     dist.barrier()
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank12]:     work = default_pg.barrier(opts=opts)
[rank12]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank12]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank12]: Last error:
[rank12]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
rank 14 After initialize model
rank 14 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 663, in main
[rank14]:     dist.barrier()
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank14]:     work = default_pg.barrier(opts=opts)
[rank14]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank14]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank14]: Last error:
[rank14]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:02,478] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Done
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 12 Before initialize parallelism groups
rank 12 After initialize parallelism groups
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:09,217] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 14 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 12 After initialize model
rank 12 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 663, in main
[rank12]:     dist.barrier()
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank12]:     work = default_pg.barrier(opts=opts)
[rank12]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank12]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank12]: Last error:
[rank12]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:30,190] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 12 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 12 After initialize model
rank 12 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank12]: Traceback (most recent call last):
[rank12]:   File "train.py", line 986, in <module>
[rank12]:     main(args, device, world_size, world_rank, local_rank)
[rank12]:   File "train.py", line 663, in main
[rank12]:     dist.barrier()
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank12]:     return func(*args, **kwargs)
[rank12]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank12]:     work = default_pg.barrier(opts=opts)
[rank12]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank12]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank12]: Last error:
[rank12]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
rank 14 After initialize model
rank 14 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 663, in main
[rank14]:     dist.barrier()
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank14]:     work = default_pg.barrier(opts=opts)
[rank14]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank14]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank14]: Last error:
[rank14]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:21,221] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 14 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 14 After initialize model
rank 14 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank14]: Traceback (most recent call last):
[rank14]:   File "train.py", line 986, in <module>
[rank14]:     main(args, device, world_size, world_rank, local_rank)
[rank14]:   File "train.py", line 663, in main
[rank14]:     dist.barrier()
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank14]:     return func(*args, **kwargs)
[rank14]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank14]:     work = default_pg.barrier(opts=opts)
[rank14]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank14]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank14]: Last error:
[rank14]: socketStartConnect: Connect to 100.64.201.93<35531> failed : Software caused connection abort
sleeping...
Done
[rank5]:[E ProcessGroupNCCL.cpp:574] [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600020 milliseconds before timing out.
[rank5]:[E ProcessGroupNCCL.cpp:588] [Rank 5] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank5]:[E ProcessGroupNCCL.cpp:594] [Rank 5] To avoid data inconsistency, we are taking the entire process down.
[rank5]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 5] NCCL watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600020 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 5] NCCL watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600020 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank3]:[E ProcessGroupNCCL.cpp:574] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600008 milliseconds before timing out.
[rank3]:[E ProcessGroupNCCL.cpp:588] [Rank 3] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank3]:[E ProcessGroupNCCL.cpp:594] [Rank 3] To avoid data inconsistency, we are taking the entire process down.
[rank3]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600008 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600008 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank7]:[E ProcessGroupNCCL.cpp:574] [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600097 milliseconds before timing out.
[rank7]:[E ProcessGroupNCCL.cpp:588] [Rank 7] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank7]:[E ProcessGroupNCCL.cpp:594] [Rank 7] To avoid data inconsistency, we are taking the entire process down.
[rank7]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 7] NCCL watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600097 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 7] NCCL watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600097 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank2]:[E ProcessGroupNCCL.cpp:574] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600088 milliseconds before timing out.
[rank2]:[E ProcessGroupNCCL.cpp:588] [Rank 2] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank2]:[E ProcessGroupNCCL.cpp:594] [Rank 2] To avoid data inconsistency, we are taking the entire process down.
[rank2]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600088 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600088 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank13]:[E ProcessGroupNCCL.cpp:574] [Rank 13] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600013 milliseconds before timing out.
[rank13]:[E ProcessGroupNCCL.cpp:588] [Rank 13] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank13]:[E ProcessGroupNCCL.cpp:594] [Rank 13] To avoid data inconsistency, we are taking the entire process down.
[rank13]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 13] NCCL watchdog thread terminated with exception: [Rank 13] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600013 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 13] NCCL watchdog thread terminated with exception: [Rank 13] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600013 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank4]:[E ProcessGroupNCCL.cpp:574] [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600031 milliseconds before timing out.
[rank4]:[E ProcessGroupNCCL.cpp:588] [Rank 4] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank4]:[E ProcessGroupNCCL.cpp:594] [Rank 4] To avoid data inconsistency, we are taking the entire process down.
[rank4]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 4] NCCL watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600031 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 4] NCCL watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600031 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank6]:[E ProcessGroupNCCL.cpp:574] [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600061 milliseconds before timing out.
[rank6]:[E ProcessGroupNCCL.cpp:588] [Rank 6] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank6]:[E ProcessGroupNCCL.cpp:594] [Rank 6] To avoid data inconsistency, we are taking the entire process down.
[rank6]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 6] NCCL watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600061 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 6] NCCL watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600061 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank10]:[E ProcessGroupNCCL.cpp:574] [Rank 10] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600092 milliseconds before timing out.
[rank10]:[E ProcessGroupNCCL.cpp:588] [Rank 10] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank10]:[E ProcessGroupNCCL.cpp:594] [Rank 10] To avoid data inconsistency, we are taking the entire process down.
[rank10]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 10] NCCL watchdog thread terminated with exception: [Rank 10] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600092 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 10] NCCL watchdog thread terminated with exception: [Rank 10] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600092 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank0]:[E ProcessGroupNCCL.cpp:574] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600035 milliseconds before timing out.
[rank0]:[E ProcessGroupNCCL.cpp:588] [Rank 0] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank0]:[E ProcessGroupNCCL.cpp:594] [Rank 0] To avoid data inconsistency, we are taking the entire process down.
[rank0]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600035 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=337, OpType=ALLREDUCE, NumelIn=25165824, NumelOut=25165824, Timeout(ms)=600000) ran for 600035 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

/usr/bin/bash: line 3: 1155924 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size $j --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim 6144 --depth 32 --num_heads 32
sleeping...
sleeping...
/usr/bin/bash: line 3: 1155925 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size $j --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim 6144 --depth 32 --num_heads 32
/usr/bin/bash: line 3: 445844 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size $j --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim 6144 --depth 32 --num_heads 32
sleeping...
/usr/bin/bash: line 3: 445843 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size $j --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim 6144 --depth 32 --num_heads 32
sleeping...
sleeping...
/usr/bin/bash: line 3: 1155922 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size $j --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim 6144 --depth 32 --num_heads 32
sleeping...
/usr/bin/bash: line 3: 1155927 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size $j --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim 6144 --depth 32 --num_heads 32
sleeping...
/usr/bin/bash: line 3: 1155926 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size $j --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim 6144 --depth 32 --num_heads 32
/usr/bin/bash: line 3: 1155928 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size $j --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim 6144 --depth 32 --num_heads 32
sleeping...
/usr/bin/bash: line 3: 1155920 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size $j --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim 6144 --depth 32 --num_heads 32
sleeping...
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:24,050] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:24,050] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:24,544] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:24,544] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:24,544] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:24,544] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:24,544] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:24,544] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:24,544] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=512, depth=32, embed_dim=6144, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier09437.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 13 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 10 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
slurmstepd: error: *** STEP 3136481.0 ON frontier09437 CANCELLED AT 2025-03-07T23:51:59 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 3136481 ON frontier09437 CANCELLED AT 2025-03-07T23:51:59 DUE TO TIME LIMIT ***

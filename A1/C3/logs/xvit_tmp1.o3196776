
Lmod is automatically replacing "cce/18.0.1" with "gcc-native/13.2".


Lmod is automatically replacing "PrgEnv-cray/8.6.0" with "PrgEnv-gnu/8.6.0".


Due to MODULEPATH changes, the following have been reloaded:
  1) cray-libsci/24.11.0     2) cray-mpich/8.1.31     3) darshan-runtime/3.4.6-mpi


Lmod is automatically replacing "gcc-native/13.2" with "gcc/12.2.0".


Inactive Modules:
  1) darshan-runtime

The following have been reloaded with a version change:
  1) cray-libsci/24.11.0 => cray-libsci/23.09.1.1
  2) cray-mpich/8.1.31 => cray-mpich/8.1.27
  3) libfabric/1.22.0 => libfabric/1.20.1

Lmod has detected the following error: These module(s) or extension(s) exist
but cannot be loaded as requested: "darshan-runtime"
   Try: "module spider darshan-runtime" to see how to load the module(s).



for i in {orbit,orbit_token,orbit_hier_token,orbit_hier_token_allGather,orbit_hier_token_noagg,orbit_hier_token_agg,orbit_hier_token_noagg_self,orbit_hier,orbit_linear}; do for j in {8192,}; do for k in {32,64,128}; do python train.py \ configs/ERA5-100million-91variables.yaml \ --max_epochs 1 \ --fa2 \ --fsdp_size 1 \ --simple_ddp_size 1 \ --seq_par_size 1 \ --tensor_par_size 16 \ --batch_size 2 \ --arch $i \ --channels $k \ --imagex 128 \ --imagey 256 \ --embed_dim $j \ --depth 32 \ --num_heads 32 echo "sleeping..." sleep 5 echo "Done" done done done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:04:13,223] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 4 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 5 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 14 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 11 Before initialize parallelism groups
rank 10 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 11 After initialize parallelism groups
rank 12 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 9 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 9 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 8192])
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  norm.weight  requires_gradient  True size torch.Size([8192])
parameter name  norm.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(26209608192) params_per_gpu tensor(1789051392)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=8192, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=8192, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=8192, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=8192, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
MIOpen(HIP): Warning [PlainTextDb] Unable to create a directory: "/tmp/.config/miopen"
MIOpen(HIP): Warning [PlainTextDb] Unable to create a directory: "/tmp/.config/miopen"
MIOpen(HIP): Warning [PlainTextDb] Unable to create a directory: "/tmp/.config/miopen"
epoch-train:  0 batch_idx 0 world_rank 0  loss  10.5
epoch-train:  0 batch_idx 1 world_rank 0  loss  nan
epoch-train:  0 batch_idx 2 world_rank 0  loss  nan
[2025-03-14 13:05:09,858] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,858] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,859] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,860] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,860] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,860] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  nan
[2025-03-14 13:05:09,861] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,863] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,863] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,863] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,863] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,863] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,864] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,864] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,865] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:09,866] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:05:10,771] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,771] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,772] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,772] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,772] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,772] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,772] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,772] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,772] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,772] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,772] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,772] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,772] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,772] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,773] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:05:10,773] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 1789.051392 M TFLOPS: 26.778468440290947

--> cuda max reserved memory = 45.8438
--> max reserved percentage = 71.65 %

--> cuda max memory allocated = 33.5432
--> max allocated percentage = 52.42 %

--> peak active memory = 41.7875
--> peak active memory 65.31 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 45.8438 26.778468440290947 tensor(26209608192)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,946] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,946] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,946] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,946] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,946] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,946] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,946] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,946] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,950] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,950] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,950] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,950] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,950] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,950] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,950] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:05:24,950] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 2 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 9 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 4 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 10 After initialize parallelism groups
rank 8 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 8 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 8192])
rank 9 After the second dist.barrier()
rank 13 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
rank 12 After the second dist.barrier()
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
rank 10 After the second dist.barrier()
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 11 After the second dist.barrier()
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  norm.weight  requires_gradient  True size torch.Size([8192])
parameter name  norm.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(26218521600) params_per_gpu tensor(1797964800)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=8192, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=8192, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=8192, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=8192, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  5.65625
epoch-train:  0 batch_idx 1 world_rank 0  loss  nan
epoch-train:  0 batch_idx 2 world_rank 0  loss  nan
[2025-03-14 13:06:16,342] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,343] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,343] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,343] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  nan
[2025-03-14 13:06:16,344] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,344] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,344] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,344] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,346] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,346] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,346] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,346] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,346] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,346] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,347] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:16,348] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:06:17,452] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,452] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,452] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,452] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,452] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,452] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,452] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,452] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,452] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,453] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,453] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,453] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,453] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,453] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,453] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:06:17,453] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 1797.9648 M TFLOPS: 25.112497306497065

--> cuda max reserved memory = 52.1523
--> max reserved percentage = 81.51 %

--> cuda max memory allocated = 40.0795
--> max allocated percentage = 62.64 %

--> peak active memory = 46.4102
--> peak active memory 72.53 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 52.1523 25.112497306497065 tensor(26218521600)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:30,993] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:30,993] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:30,993] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:30,993] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:30,993] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:30,993] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:30,994] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:30,993] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:31,193] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:31,193] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:31,193] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:31,193] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:31,193] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:31,193] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:31,193] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:06:31,193] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
HERE0 Namespace(arch='orbit', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 2 After initialize parallelism groups
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 13 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 13 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 12 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'sperank 11 After initialize parallelism groups
cific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 10 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 9 After initialize parallelism groups
rank 12 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 10 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 8192])
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 2 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  norm.weight  requires_gradient  True size torch.Size([8192])
parameter name  norm.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(26236348416) params_per_gpu tensor(1815791616)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=8192, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=8192, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=8192, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=8192, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  6.46875
epoch-train:  0 batch_idx 1 world_rank 0  loss  nan
epoch-train:  0 batch_idx 2 world_rank 0  loss  nan
[2025-03-14 13:07:30,831] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  nan
[2025-03-14 13:07:30,832] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:30,832] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:30,832] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:30,833] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:30,833] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:30,833] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:30,833] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:30,833] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:30,833] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:30,834] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:30,834] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:30,834] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:31,127] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:31,132] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:31,407] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:07:32,662] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,663] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,663] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,663] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,663] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,663] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,663] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,663] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,663] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,663] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,663] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,663] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,663] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,664] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,664] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:07:32,664] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 1815.791616 M TFLOPS: 12.347941143359048

--> cuda max reserved memory = 62.7266
--> max reserved percentage = 98.03 %

--> cuda max memory allocated = 53.1542
--> max allocated percentage = 83.07 %

--> peak active memory = 53.1542
--> peak active memory 83.07 %

cudaMalloc retries = 4
cuda OOM = 0

--> Recommend decreasing batch size...cuda retries can greatly degrade perf!
HERE1 Namespace(arch='orbit', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 62.7266 12.347941143359048 tensor(26236348416)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,245] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,245] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,245] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,245] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,245] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,245] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,245] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,245] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,250] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,250] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,250] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,250] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,250] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,250] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,250] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:07:46,250] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_token', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 10 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 10 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 14 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 1 Before initialize parallelism groups
rank 4 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 8 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 6 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 8 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 4 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 8192])
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 3 After the second dist.barrier()
rank 2 After the second dist.barrier()
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(159941120) params_per_gpu tensor(159941120)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  2.921875
epoch-train:  0 batch_idx 1 world_rank 0  loss  2.90625
epoch-train:  0 batch_idx 2 world_rank 0  loss  2.90625
epoch-train:  0 batch_idx 3 world_rank 0  loss  2.90625
[2025-03-14 13:08:09,004] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,147] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[2025-03-14 13:08:09,603] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,603] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,604] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,604] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,604] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,604] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,604] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,604] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,604] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,605] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,605] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,605] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,605] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,606] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:09,606] [INFO] [profiler.py:80:start_profile] Flops profiler started
MUST: Model 159.94112 M TFLOPS: 15.959266450358406

--> cuda max reserved memory = 9.9824
--> max reserved percentage = 15.6 %

--> cuda max memory allocated = 8.6968
--> max allocated percentage = 13.59 %

--> peak active memory = 8.6968
--> peak active memory 13.59 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_token', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 9.9824 15.959266450358406 tensor(159941120)
[2025-03-14 13:08:09,747] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,748] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,748] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,748] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,748] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,748] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,748] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,748] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,748] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,749] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,749] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,749] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,749] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,749] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:09,749] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:21,649] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_token', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:22,782] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:22,782] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:22,782] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:22,782] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:22,782] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:22,782] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:22,782] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 2 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 6 After initialize parallelism groups
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:23,566] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:23,566] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:23,566] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:23,566] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:23,566] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:23,566] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:23,566] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:23,566] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 15 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 13 After initialize parallelism groups
rank 9 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 8 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 10 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 8192])
rank 8 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
rank 9 After the second dist.barrier()
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
rank 13 After the second dist.barrier()
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
rank 12 After the second dist.barrier()
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 14 After the second dist.barrier()
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
rank 15 After the second dist.barrier()
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 11 After the second dist.barrier()
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
rank 10 After the second dist.barrier()
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(168854528) params_per_gpu tensor(168854528)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  4.5625
epoch-train:  0 batch_idx 1 world_rank 0  loss  4.53125
epoch-train:  0 batch_idx 2 world_rank 0  loss  4.53125
epoch-train:  0 batch_idx 3 world_rank 0  loss  4.53125
[2025-03-14 13:08:46,718] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:46,861] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 168.854528 M TFLOPS: 14.58855140193856

--> cuda max reserved memory = 18.0527
--> max reserved percentage = 28.21 %

--> cuda max memory allocated = 14.8575
--> max allocated percentage = 23.22 %

--> peak active memory = 14.8575
--> peak active memory 23.22 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_token', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 18.0527 14.58855140193856 tensor(168854528)
[2025-03-14 13:08:47,694] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,694] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,694] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,694] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,694] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,694] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,695] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,695] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,695] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,695] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,695] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,695] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,696] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,696] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,696] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:08:47,838] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,839] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,839] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,839] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,839] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,839] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,839] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,839] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,839] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,839] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,840] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,840] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,840] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,840] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:08:47,840] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:08:59,430] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_token', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,118] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,118] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,118] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,118] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,118] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,118] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,118] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,458] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,458] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,458] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,458] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,458] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,458] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,458] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:01,458] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 6 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 4 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 13 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 10 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 9 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 2 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 8192])
rank 9 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 12 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(186681344) params_per_gpu tensor(186681344)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  6.0
epoch-train:  0 batch_idx 1 world_rank 0  loss  5.96875
epoch-train:  0 batch_idx 2 world_rank 0  loss  5.96875
epoch-train:  0 batch_idx 3 world_rank 0  loss  5.96875
[2025-03-14 13:09:25,359] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:25,635] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 186.681344 M TFLOPS: 9.073160630719094

--> cuda max reserved memory = 34.3281
--> max reserved percentage = 53.65 %

--> cuda max memory allocated = 27.1808
--> max allocated percentage = 42.48 %

--> peak active memory = 27.1808
--> peak active memory 42.48 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_token', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 34.3281 9.073160630719094 tensor(186681344)
[2025-03-14 13:09:26,630] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,630] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,631] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,631] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,631] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,631] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,632] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,632] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,632] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,633] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,633] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,633] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,634] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,634] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,634] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:09:26,903] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,903] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,904] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,904] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,904] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,904] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,904] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,904] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,905] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,905] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,905] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,905] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,905] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,906] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:09:26,906] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:38,164] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,159] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,159] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,159] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,159] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,159] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,159] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,159] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,165] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,165] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,165] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,165] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,165] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,165] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,165] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:09:40,165] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 10 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 15 After initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 3 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 8192])
rank 5 After the second dist.barrier()
rank 4 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(159941120) params_per_gpu tensor(159941120)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  3.875
epoch-train:  0 batch_idx 1 world_rank 0  loss  3.875
epoch-train:  0 batch_idx 2 world_rank 0  loss  3.859375
epoch-train:  0 batch_idx 3 world_rank 0  loss  3.859375
[2025-03-14 13:10:02,745] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:02,774] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[2025-03-14 13:10:03,074] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,074] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,074] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,075] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,075] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,075] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,075] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,075] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,075] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,076] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,076] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,076] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,076] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,077] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,077] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:03,106] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 159.94112 M TFLOPS: 51.864194565969726

--> cuda max reserved memory = 4.4082
--> max reserved percentage = 6.89 %

--> cuda max memory allocated = 3.1416
--> max allocated percentage = 4.91 %

--> peak active memory = 3.8354
--> peak active memory 5.99 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 4.4082 51.864194565969726 tensor(159941120)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,217] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,217] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,217] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,217] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,217] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,217] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,217] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,217] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,595] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,595] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,595] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,595] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,595] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,595] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,595] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:16,595] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 10 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 12 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 14 After initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 11 After initialize model
rank 12 After initialize model
rank 11 Before the second dist.barrier()
rank 12 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 8192])
rank 5 After the second dist.barrier()
rank 4 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 6 After the second dist.barrier()
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
rank 7 After the second dist.barrier()
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
rank 3 After the second dist.barrier()
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
rank 2 After the second dist.barrier()
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(168854528) params_per_gpu tensor(168854528)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  2.625
epoch-train:  0 batch_idx 1 world_rank 0  loss  2.625
epoch-train:  0 batch_idx 2 world_rank 0  loss  2.625
epoch-train:  0 batch_idx 3 world_rank 0  loss  2.609375
[2025-03-14 13:10:39,140] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:39,182] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 168.854528 M TFLOPS: 44.57596851826024

--> cuda max reserved memory = 5.0586
--> max reserved percentage = 7.91 %

--> cuda max memory allocated = 3.6066
--> max allocated percentage = 5.64 %

--> peak active memory = 4.0414
--> peak active memory 6.32 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 5.0586 44.57596851826024 tensor(168854528)
[2025-03-14 13:10:40,226] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,226] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,227] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,227] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,227] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,227] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,227] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,227] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,227] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,228] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,228] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,228] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,228] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,228] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,229] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:10:40,275] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,275] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,275] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,275] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,275] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,275] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,275] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,276] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,276] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,276] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,276] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,276] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,276] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,276] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:10:40,277] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:51,905] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:53,728] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:53,728] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:53,728] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:53,728] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:53,728] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:53,728] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:53,728] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:54,032] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:54,032] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:54,032] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:54,032] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:54,032] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:54,032] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:54,032] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:10:54,032] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 7 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 3 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 9 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 9 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 14 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 12 After initialize parallelism groups
rank 15 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 9 After initialize model
rank 12 After initialize model
rank 9 Before the second dist.barrier()
rank 12 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 3 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 8192])
rank 13 After the second dist.barrier()
rank 12 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(186681344) params_per_gpu tensor(186681344)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  3.515625
epoch-train:  0 batch_idx 1 world_rank 0  loss  3.515625
epoch-train:  0 batch_idx 2 world_rank 0  loss  3.5
epoch-train:  0 batch_idx 3 world_rank 0  loss  3.5
[2025-03-14 13:11:16,955] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,024] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 186.681344 M TFLOPS: 35.74326429194241

--> cuda max reserved memory = 5.3984
--> max reserved percentage = 8.44 %

--> cuda max memory allocated = 4.6789
--> max allocated percentage = 7.31 %

--> peak active memory = 4.6789
--> peak active memory 7.31 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 5.3984 35.74326429194241 tensor(186681344)
[2025-03-14 13:11:17,751] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,751] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,751] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,751] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,751] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,751] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,751] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,752] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,752] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,752] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,752] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,752] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,753] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,753] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,753] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:17,846] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,846] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,847] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,847] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,847] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,847] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,847] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,847] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,847] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,847] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,847] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,848] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,848] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,850] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:17,851] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:29,618] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_allGather', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,088] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,088] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,088] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,088] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,088] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,089] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,089] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,499] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,499] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,499] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,499] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,499] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,499] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,499] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:11:31,499] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 7 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 15 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 13 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 12 After initialize parallelism groups
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 11 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 5 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 8192])
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
rank 3 After the second dist.barrier()
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 2 After the second dist.barrier()
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(428515840) params_per_gpu tensor(176734720)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  4.0625
epoch-train:  0 batch_idx 1 world_rank 0  loss  4.0625
epoch-train:  0 batch_idx 2 world_rank 0  loss  4.03125
[2025-03-14 13:11:55,115] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,116] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,116] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,116] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  4.03125
[2025-03-14 13:11:55,117] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,117] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,117] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,117] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,117] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,118] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,118] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,118] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,118] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,118] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,118] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,118] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:11:55,222] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,222] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,222] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,223] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,223] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,223] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,223] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,223] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,223] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,223] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,223] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,224] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,224] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,224] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,224] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:11:55,226] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 176.73472 M TFLOPS: 23.77589418762606

--> cuda max reserved memory = 9.625
--> max reserved percentage = 15.04 %

--> cuda max memory allocated = 7.009
--> max allocated percentage = 10.95 %

--> peak active memory = 9.2042
--> peak active memory 14.39 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_allGather', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 9.625 23.77589418762606 tensor(428515840)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,701] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,701] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,701] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,701] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,701] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,701] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,701] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,701] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,907] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,907] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,907] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,907] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,907] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,907] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,907] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:08,907] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_allGather', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 5 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 1 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 14 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 11 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 8 After initialize parallelism groups
rank 13 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 10 After initialize parallelism groups
rank 13 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 11 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 8192])
rank 13 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 15 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
rank 12 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
rank 6 After the second dist.barrier()
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 7 After the second dist.barrier()
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(437429248) params_per_gpu tensor(185648128)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  6.5625
epoch-train:  0 batch_idx 1 world_rank 0  loss  6.53125
epoch-train:  0 batch_idx 2 world_rank 0  loss  6.53125
[2025-03-14 13:12:33,208] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  6.53125
[2025-03-14 13:12:33,208] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,209] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,209] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,209] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,209] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,209] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,209] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,210] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,210] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,210] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,210] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,210] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,210] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,210] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,210] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:12:33,402] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,402] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,403] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,403] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,403] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,403] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,404] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,404] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,404] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,405] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,405] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,406] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,406] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,406] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,406] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:12:33,406] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 185.648128 M TFLOPS: 15.573226408572207

--> cuda max reserved memory = 16.1094
--> max reserved percentage = 25.18 %

--> cuda max memory allocated = 11.4192
--> max allocated percentage = 17.85 %

--> peak active memory = 15.4973
--> peak active memory 24.22 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_allGather', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 16.1094 15.573226408572207 tensor(437429248)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,023] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,023] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,023] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,023] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,023] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,023] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,024] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,024] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,027] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,027] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,027] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,027] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,027] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,027] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,027] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:12:47,027] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_allGather', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 4 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 6 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 6 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 8192])
rank 7 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
rank 14 After the second dist.barrier()
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 15 After the second dist.barrier()
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 11 After the second dist.barrier()
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
rank 10 After the second dist.barrier()
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(455256064) params_per_gpu tensor(203474944)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  4.15625
epoch-train:  0 batch_idx 1 world_rank 0  loss  4.15625
epoch-train:  0 batch_idx 2 world_rank 0  loss  4.125
epoch-train:  0 batch_idx 3 world_rank 0  loss  4.125
[2025-03-14 13:13:11,324] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,324] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,324] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,325] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,325] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,325] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,325] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,325] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,325] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,325] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,326] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,326] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,326] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,326] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,326] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,328] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:11,691] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,691] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,693] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,693] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,694] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,695] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,695] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,695] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,695] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,697] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,697] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,698] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,700] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,701] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,704] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:11,704] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 203.474944 M TFLOPS: 9.365300490338411

--> cuda max reserved memory = 28.8672
--> max reserved percentage = 45.12 %

--> cuda max memory allocated = 20.2416
--> max allocated percentage = 31.64 %

--> peak active memory = 28.2416
--> peak active memory 44.14 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_allGather', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 28.8672 9.365300490338411 tensor(455256064)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,357] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,357] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,357] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,357] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,357] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,357] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,357] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,357] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,362] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,362] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,362] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,362] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,362] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,362] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,362] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:13:25,362] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 9 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 15 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 10 After initialize parallelism groups
rank 13 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 6 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 9 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 11 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 8192])
rank 10 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(428515840) params_per_gpu tensor(176734720)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  23.0
epoch-train:  0 batch_idx 1 world_rank 0  loss  22.875
epoch-train:  0 batch_idx 2 world_rank 0  loss  22.75
[2025-03-14 13:13:49,785] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,785] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  22.625
[2025-03-14 13:13:49,785] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,786] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,786] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,786] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,786] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,786] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,786] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,786] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,786] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,786] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,786] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,786] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,786] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,787] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:13:49,972] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,972] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,972] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,972] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,972] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,972] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,972] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,972] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,972] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,972] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,973] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,973] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,974] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,975] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,975] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:13:49,975] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 176.73472 M TFLOPS: 23.55020408268704

--> cuda max reserved memory = 12.377
--> max reserved percentage = 19.34 %

--> cuda max memory allocated = 9.5486
--> max allocated percentage = 14.92 %

--> peak active memory = 11.6736
--> peak active memory 18.24 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 12.377 23.55020408268704 tensor(428515840)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,665] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,665] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,665] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,665] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,665] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,665] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,665] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,665] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:03,671] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 6 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 7 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 2 After initialize model
rank 13 After initialize model
rank 2 Before the second dist.barrier()
rank 13 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 8192])
rank 13 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 12 After the second dist.barrier()
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 14 After the second dist.barrier()
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 15 After the second dist.barrier()
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 11 After the second dist.barrier()
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 10 After the second dist.barrier()
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(437429248) params_per_gpu tensor(185648128)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  51.25
epoch-train:  0 batch_idx 1 world_rank 0  loss  51.0
epoch-train:  0 batch_idx 2 world_rank 0  loss  50.75
epoch-train:  0 batch_idx 3 world_rank 0  loss  50.5
[2025-03-14 13:14:30,145] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,145] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,145] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,145] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,145] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,145] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,145] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,145] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,145] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,145] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,146] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,146] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,146] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,146] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,146] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,146] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:14:30,485] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 185.648128 M TFLOPS: 21.12208073317551

--> cuda max reserved memory = 21.5059
--> max reserved percentage = 33.61 %

--> cuda max memory allocated = 16.2094
--> max allocated percentage = 25.33 %

--> peak active memory = 20.4594
--> peak active memory 31.98 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 21.5059 21.12208073317551 tensor(437429248)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,152] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,152] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,152] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,152] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,152] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,152] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,152] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,152] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,479] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,479] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,479] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,479] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,479] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,479] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,479] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:14:44,479] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 5 After initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 7 After initialize parallelism groups
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 8 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 11 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'sperank 9 After initialize parallelism groups
cific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 14 After initialize parallelism groups
rank 13 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 8192])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 14 After the second dist.barrier()
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
rank 15 After the second dist.barrier()
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
rank 11 After the second dist.barrier()
rank 10 After the second dist.barrier()
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(455256064) params_per_gpu tensor(203474944)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  39.0
epoch-train:  0 batch_idx 1 world_rank 0  loss  39.0
epoch-train:  0 batch_idx 2 world_rank 0  loss  38.75
epoch-train:  0 batch_idx 3 world_rank 0  loss  38.5
[2025-03-14 13:15:14,531] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,531] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,531] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,531] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,532] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,532] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,532] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,532] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,532] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,532] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,532] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,532] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,532] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,532] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,532] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:14,532] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,189] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,190] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,190] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:15,190] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 203.474944 M TFLOPS: 19.56722787863783

--> cuda max reserved memory = 39.2715
--> max reserved percentage = 61.38 %

--> cuda max memory allocated = 29.5327
--> max allocated percentage = 46.16 %

--> peak active memory = 38.0327
--> peak active memory 59.44 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 39.2715 19.56722787863783 tensor(455256064)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,045] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,045] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,045] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,045] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,045] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,045] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,045] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,045] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,051] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,051] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,051] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,051] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,051] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,051] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,051] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:15:29,051] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_agg', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 13 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 6 After initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 7 After initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 5 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 11 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 9 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 8192])
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  var_query_per_rank  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 11 After the second dist.barrier()
rank 10 After the second dist.barrier()
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg_per_rank.q.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  var_agg_per_rank.kv.weight  requires_gradient  True size torch.Size([16384, 8192])
parameter name  var_agg_per_rank.proj.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  var_agg_per_rank.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(4723622400) params_per_gpu tensor(445186560)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (var_agg_per_rank): CustomCrossAttention(
      (q): Linear(in_features=8192, out_features=8192, bias=False)
      (kv): Linear(in_features=8192, out_features=16384, bias=False)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=8192, out_features=8192, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  31.875
epoch-train:  0 batch_idx 1 world_rank 0  loss  31.375
epoch-train:  0 batch_idx 2 world_rank 0  loss  30.875
[2025-03-14 13:15:57,569] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,570] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,570] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  30.5
[2025-03-14 13:15:57,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,571] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,572] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,572] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,572] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,572] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,572] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,573] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,573] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,573] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,573] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,575] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:15:57,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 445.18656 M TFLOPS: 43.749483810163305

--> cuda max reserved memory = 14.5156
--> max reserved percentage = 22.69 %

--> cuda max memory allocated = 11.424
--> max allocated percentage = 17.85 %

--> peak active memory = 12.4865
--> peak active memory 19.51 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_agg', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 14.5156 43.749483810163305 tensor(4723622400)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,322] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,322] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,322] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,322] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,322] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,322] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,322] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,322] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,323] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,323] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,323] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,323] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,323] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,323] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,323] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:11,323] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_agg', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 10 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 10 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 4 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 3 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 8192])
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  var_query_per_rank  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg_per_rank.q.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  var_agg_per_rank.kv.weight  requires_gradient  True size torch.Size([16384, 8192])
parameter name  var_agg_per_rank.proj.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  var_agg_per_rank.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(4732535808) params_per_gpu tensor(454099968)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (var_agg_per_rank): CustomCrossAttention(
      (q): Linear(in_features=8192, out_features=8192, bias=False)
      (kv): Linear(in_features=8192, out_features=16384, bias=False)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=8192, out_features=8192, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  27.375
epoch-train:  0 batch_idx 1 world_rank 0  loss  26.875
epoch-train:  0 batch_idx 2 world_rank 0  loss  26.375
[2025-03-14 13:16:38,945] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,945] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,945] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,946] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  26.0
[2025-03-14 13:16:38,946] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,946] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,946] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,947] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,948] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,948] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,948] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,948] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,949] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,950] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,950] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:38,952] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:16:39,124] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,124] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,124] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,124] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,124] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,124] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,125] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,124] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,124] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,125] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,125] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,125] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,125] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,125] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,125] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:16:39,125] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 454.099968 M TFLOPS: 51.59699179461659

--> cuda max reserved memory = 16.7168
--> max reserved percentage = 26.13 %

--> cuda max memory allocated = 12.0848
--> max allocated percentage = 18.89 %

--> peak active memory = 13.1473
--> peak active memory 20.55 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_agg', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 16.7168 51.59699179461659 tensor(4732535808)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:16:52,657] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_agg', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 5 After initialize parallelism groups
rank 12 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 7 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 8192])
rank 6 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  var_query_per_rank  requires_gradient  True size torch.Size([1, 1, 8192])
rank 14 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
rank 15 After the second dist.barrier()
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 10 After the second dist.barrier()
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
rank 11 After the second dist.barrier()
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg_per_rank.q.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  var_agg_per_rank.kv.weight  requires_gradient  True size torch.Size([16384, 8192])
parameter name  var_agg_per_rank.proj.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  var_agg_per_rank.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(4750362624) params_per_gpu tensor(471926784)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (var_agg_per_rank): CustomCrossAttention(
      (q): Linear(in_features=8192, out_features=8192, bias=False)
      (kv): Linear(in_features=8192, out_features=16384, bias=False)
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=8192, out_features=8192, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  24.625
epoch-train:  0 batch_idx 1 world_rank 0  loss  24.25
epoch-train:  0 batch_idx 2 world_rank 0  loss  23.75
[2025-03-14 13:17:21,449] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,450] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,450] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,450] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,450] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,451] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,451] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,451] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,452] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,452] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  23.375
[2025-03-14 13:17:21,452] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,452] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,452] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,453] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,454] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,454] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:17:21,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,715] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,714] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,715] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,715] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:17:21,715] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 471.926784 M TFLOPS: 60.04124105887294

--> cuda max reserved memory = 18.5605
--> max reserved percentage = 29.01 %

--> cuda max memory allocated = 13.4081
--> max allocated percentage = 20.96 %

--> peak active memory = 14.4706
--> peak active memory 22.62 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_agg', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 18.5605 60.04124105887294 tensor(4750362624)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,349] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,349] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,349] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,349] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,349] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,349] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,350] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,350] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:17:35,353] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 11 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 11 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 12 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_corank 10 After initialize parallelism groups
mponent_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 6 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 8192])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  norm.weight  requires_gradient  True size torch.Size([8192])
parameter name  norm.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(26209608192) params_per_gpu tensor(1789051392)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=8192, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=8192, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=8192, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=8192, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  8.5
epoch-train:  0 batch_idx 1 world_rank 0  loss  nan
epoch-train:  0 batch_idx 2 world_rank 0  loss  nan
[2025-03-14 13:18:24,681] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  nan
[2025-03-14 13:18:24,682] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,683] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,683] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,683] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,683] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,683] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,684] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,684] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,684] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,685] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,685] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,686] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,686] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,687] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:24,690] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:18:25,550] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,550] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,550] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,550] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,550] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,550] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,550] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,550] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,550] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,550] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,550] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,550] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,551] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,551] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,551] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:18:25,551] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 1789.051392 M TFLOPS: 28.773220109888644

--> cuda max reserved memory = 45.6504
--> max reserved percentage = 71.35 %

--> cuda max memory allocated = 33.6678
--> max allocated percentage = 52.62 %

--> peak active memory = 41.9477
--> peak active memory 65.56 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 45.6504 28.773220109888644 tensor(26209608192)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,255] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,255] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,255] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,255] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,255] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,256] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,256] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,255] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,259] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,259] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,259] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,259] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,259] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,259] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,259] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:18:39,259] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 12 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 5 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 15 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 10 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 14 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
rank 1 After initialize parallelism groups
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 4 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
rank 13 After the second dist.barrier()
rank 14 After the second dist.barrier()
rank 15 After the second dist.barrier()
rank 12 After the second dist.barrier()
rank 8 After the second dist.barrier()
rank 9 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 8192])
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
rank 6 After the second dist.barrier()
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
rank 7 After the second dist.barrier()
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
rank 3 After the second dist.barrier()
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
rank 2 After the second dist.barrier()
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  norm.weight  requires_gradient  True size torch.Size([8192])
parameter name  norm.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(26218521600) params_per_gpu tensor(1797964800)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=8192, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=8192, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=8192, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=8192, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  7.0625
epoch-train:  0 batch_idx 1 world_rank 0  loss  nan
epoch-train:  0 batch_idx 2 world_rank 0  loss  nan
[2025-03-14 13:19:29,893] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,895] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,895] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  nan
[2025-03-14 13:19:29,895] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,896] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,897] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,897] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,897] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,897] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,897] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,897] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,898] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,898] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,899] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,899] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:29,901] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-14 13:19:30,918] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,918] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,918] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,918] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,918] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,918] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,918] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,918] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,918] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,918] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,919] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,919] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,919] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,919] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,919] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-14 13:19:30,919] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 1797.9648 M TFLOPS: 27.099773761683366

--> cuda max reserved memory = 56.4863
--> max reserved percentage = 88.28 %

--> cuda max memory allocated = 40.3286
--> max allocated percentage = 63.03 %

--> peak active memory = 49.0104
--> peak active memory 76.6 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=64, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml') 56.4863 27.099773761683366 tensor(26218521600)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,579] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,579] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,579] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,579] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,579] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,579] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,579] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:19:44,579] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=128, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
config_path  configs/ERA5-100million-91variables.yaml
rank 13 Before initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 9 Before initialize parallelism groups
rank 11 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 12 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 9 After initialize parallelism groups
rank 14 After initialize parallelism groups
rank 11 After initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 10 After initialize parallelism groups
rank 8 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 1 After initialize parallelism groups
rank 7 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 16 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 8192 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
rank 8 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 8192])
rank 9 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 8192])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 8192])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 13 After the second dist.barrier()
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 12 After the second dist.barrier()
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([8192])
rank 15 After the second dist.barrier()
rank 14 After the second dist.barrier()
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
rank 10 After the second dist.barrier()
rank 11 After the second dist.barrier()
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([8192, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 8192])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 8192])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([8192, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 8192])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([8192, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([8192])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([8192, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([8192])
parameter name  norm.weight  requires_gradient  True size torch.Size([8192])
parameter name  norm.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.0.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.0.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.2.weight  requires_gradient  True size torch.Size([8192, 8192])
parameter name  head.2.bias  requires_gradient  True size torch.Size([8192])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 8192])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(26236348416) params_per_gpu tensor(1815791616)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 8192, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=8192, out_features=512, bias=False)
          (kv): Linear(in_features=8192, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=8192, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=8192, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=8192, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=8192, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=8192, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=8192, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((8192,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=8192, out_features=8192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8192, out_features=8192, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=8192, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  15 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  7.40625
epoch-train:  0 batch_idx 1 world_rank 0  loss  nan
epoch-train:  0 batch_idx 2 world_rank 0  loss  nan
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 988, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 887, in main
[rank3]:     loss.backward()
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/_tensor.py", line 524, in backward
[rank3]:     torch.autograd.backward(
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
[rank3]:     _engine_run_backward(
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
[rank3]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank3]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 8.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 7.87 GiB is free. Of the allocated memory 36.10 GiB is allocated by PyTorch, and 18.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
sleeping...
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:20:54,424] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 3 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 3 After initialize model
rank 3 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 988, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 665, in main
[rank3]:     dist.barrier()
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank3]:     work = default_pg.barrier(opts=opts)
[rank3]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank3]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank3]: Last error:
[rank3]: socketStartConnect: Connect to 100.64.173.109<52829> failed : Software caused connection abort
sleeping...
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:21:32,571] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 3 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 3 After initialize model
rank 3 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 988, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 665, in main
[rank3]:     dist.barrier()
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank3]:     work = default_pg.barrier(opts=opts)
[rank3]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank3]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank3]: Last error:
[rank3]: socketStartConnect: Connect to 100.64.173.109<52829> failed : Software caused connection abort
sleeping...
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:22:10,908] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 3 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 3 After initialize model
rank 3 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 988, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 665, in main
[rank3]:     dist.barrier()
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank3]:     work = default_pg.barrier(opts=opts)
[rank3]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank3]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank3]: Last error:
[rank3]: socketStartConnect: Connect to 100.64.173.109<52829> failed : Software caused connection abort
sleeping...
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:22:49,324] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 3 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 3 After initialize model
rank 3 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 988, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 665, in main
[rank3]:     dist.barrier()
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank3]:     work = default_pg.barrier(opts=opts)
[rank3]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank3]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank3]: Last error:
[rank3]: socketStartConnect: Connect to 100.64.173.109<52829> failed : Software caused connection abort
sleeping...
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:23:24,307] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 3 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 3 After initialize model
rank 3 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 988, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 665, in main
[rank3]:     dist.barrier()
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank3]:     work = default_pg.barrier(opts=opts)
[rank3]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank3]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank3]: Last error:
[rank3]: socketStartConnect: Connect to 100.64.173.109<52829> failed : Software caused connection abort
sleeping...
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:23:59,601] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 3 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 3 After initialize model
rank 3 Before the second dist.barrier()
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 988, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 665, in main
[rank3]:     dist.barrier()
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 3571, in barrier
[rank3]:     work = default_pg.barrier(opts=opts)
[rank3]: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1975, unhandled system error, NCCL version 2.17.1
[rank3]: ncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. 
[rank3]: Last error:
[rank3]: socketStartConnect: Connect to 100.64.173.109<52829> failed : Software caused connection abort
sleeping...
Done
[rank11]:[E ProcessGroupNCCL.cpp:574] [Rank 11] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600015 milliseconds before timing out.
[rank11]:[E ProcessGroupNCCL.cpp:588] [Rank 11] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank11]:[E ProcessGroupNCCL.cpp:594] [Rank 11] To avoid data inconsistency, we are taking the entire process down.
[rank11]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 11] NCCL watchdog thread terminated with exception: [Rank 11] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600015 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 11] NCCL watchdog thread terminated with exception: [Rank 11] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600015 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank5]:[E ProcessGroupNCCL.cpp:574] [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600091 milliseconds before timing out.
[rank1]:[E ProcessGroupNCCL.cpp:574] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600086 milliseconds before timing out.
[rank5]:[E ProcessGroupNCCL.cpp:588] [Rank 5] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank5]:[E ProcessGroupNCCL.cpp:594] [Rank 5] To avoid data inconsistency, we are taking the entire process down.
[rank5]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 5] NCCL watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600091 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank1]:[E ProcessGroupNCCL.cpp:588] [Rank 1] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank1]:[E ProcessGroupNCCL.cpp:594] [Rank 1] To avoid data inconsistency, we are taking the entire process down.
[rank1]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600086 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 5] NCCL watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600091 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600086 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank12]:[E ProcessGroupNCCL.cpp:574] [Rank 12] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600075 milliseconds before timing out.
[rank14]:[E ProcessGroupNCCL.cpp:574] [Rank 14] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600084 milliseconds before timing out.
[rank12]:[E ProcessGroupNCCL.cpp:588] [Rank 12] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank12]:[E ProcessGroupNCCL.cpp:594] [Rank 12] To avoid data inconsistency, we are taking the entire process down.
[rank15]:[E ProcessGroupNCCL.cpp:574] [Rank 15] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600008 milliseconds before timing out.
[rank12]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 12] NCCL watchdog thread terminated with exception: [Rank 12] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600075 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 12] NCCL watchdog thread terminated with exception: [Rank 12] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600075 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank14]:[E ProcessGroupNCCL.cpp:588] [Rank 14] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank14]:[E ProcessGroupNCCL.cpp:594] [Rank 14] To avoid data inconsistency, we are taking the entire process down.
[rank15]:[E ProcessGroupNCCL.cpp:588] [Rank 15] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank15]:[E ProcessGroupNCCL.cpp:594] [Rank 15] To avoid data inconsistency, we are taking the entire process down.
[rank14]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 14] NCCL watchdog thread terminated with exception: [Rank 14] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600084 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank15]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 15] NCCL watchdog thread terminated with exception: [Rank 15] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600008 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 14] NCCL watchdog thread terminated with exception: [Rank 14] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600084 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 15] NCCL watchdog thread terminated with exception: [Rank 15] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600008 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank6]:[E ProcessGroupNCCL.cpp:574] [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600086 milliseconds before timing out.
[rank6]:[E ProcessGroupNCCL.cpp:588] [Rank 6] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank6]:[E ProcessGroupNCCL.cpp:594] [Rank 6] To avoid data inconsistency, we are taking the entire process down.
[rank6]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 6] NCCL watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600086 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 6] NCCL watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600086 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank7]:[E ProcessGroupNCCL.cpp:574] [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600053 milliseconds before timing out.
[rank0]:[E ProcessGroupNCCL.cpp:574] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600092 milliseconds before timing out.
[rank0]:[E ProcessGroupNCCL.cpp:588] [Rank 0] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank0]:[E ProcessGroupNCCL.cpp:594] [Rank 0] To avoid data inconsistency, we are taking the entire process down.
[rank0]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600092 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank7]:[E ProcessGroupNCCL.cpp:588] [Rank 7] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank7]:[E ProcessGroupNCCL.cpp:594] [Rank 7] To avoid data inconsistency, we are taking the entire process down.
[rank7]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 7] NCCL watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600053 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600092 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 7] NCCL watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600053 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank4]:[E ProcessGroupNCCL.cpp:574] [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600088 milliseconds before timing out.
[rank4]:[E ProcessGroupNCCL.cpp:588] [Rank 4] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank4]:[E ProcessGroupNCCL.cpp:594] [Rank 4] To avoid data inconsistency, we are taking the entire process down.
[rank4]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 4] NCCL watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600088 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 4] NCCL watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600088 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank2]:[E ProcessGroupNCCL.cpp:574] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600099 milliseconds before timing out.
[rank2]:[E ProcessGroupNCCL.cpp:588] [Rank 2] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank2]:[E ProcessGroupNCCL.cpp:594] [Rank 2] To avoid data inconsistency, we are taking the entire process down.
[rank2]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600099 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600099 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank13]:[E ProcessGroupNCCL.cpp:574] [Rank 13] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600003 milliseconds before timing out.
[rank13]:[E ProcessGroupNCCL.cpp:588] [Rank 13] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank13]:[E ProcessGroupNCCL.cpp:594] [Rank 13] To avoid data inconsistency, we are taking the entire process down.
[rank13]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 13] NCCL watchdog thread terminated with exception: [Rank 13] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600003 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 13] NCCL watchdog thread terminated with exception: [Rank 13] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600003 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank10]:[E ProcessGroupNCCL.cpp:574] [Rank 10] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600030 milliseconds before timing out.
[rank10]:[E ProcessGroupNCCL.cpp:588] [Rank 10] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank10]:[E ProcessGroupNCCL.cpp:594] [Rank 10] To avoid data inconsistency, we are taking the entire process down.
[rank10]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 10] NCCL watchdog thread terminated with exception: [Rank 10] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600030 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 10] NCCL watchdog thread terminated with exception: [Rank 10] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600030 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank8]:[E ProcessGroupNCCL.cpp:574] [Rank 8] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600066 milliseconds before timing out.
[rank8]:[E ProcessGroupNCCL.cpp:588] [Rank 8] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank8]:[E ProcessGroupNCCL.cpp:594] [Rank 8] To avoid data inconsistency, we are taking the entire process down.
[rank8]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 8] NCCL watchdog thread terminated with exception: [Rank 8] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600066 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 8] NCCL watchdog thread terminated with exception: [Rank 8] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600066 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank9]:[E ProcessGroupNCCL.cpp:574] [Rank 9] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600070 milliseconds before timing out.
[rank9]:[E ProcessGroupNCCL.cpp:574] [Rank 9] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=170, OpType=ALLREDUCE, NumelIn=50384384, NumelOut=50384384, Timeout(ms)=600000) ran for 600069 milliseconds before timing out.
[rank9]:[E ProcessGroupNCCL.cpp:588] [Rank 9] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank9]:[E ProcessGroupNCCL.cpp:594] [Rank 9] To avoid data inconsistency, we are taking the entire process down.
[rank9]:[E ProcessGroupNCCL.cpp:1373] [PG 1 Rank 9] NCCL watchdog thread terminated with exception: [Rank 9] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600070 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

[rank9]:[E ProcessGroupNCCL.cpp:588] [Rank 9] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank9]:[E ProcessGroupNCCL.cpp:594] [Rank 9] To avoid data inconsistency, we are taking the entire process down.
[rank9]:[E ProcessGroupNCCL.cpp:1373] [PG 4 Rank 0] NCCL watchdog thread terminated with exception: [Rank 9] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=170, OpType=ALLREDUCE, NumelIn=50384384, NumelOut=50384384, Timeout(ms)=600000) ran for 600069 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG 1 Rank 9] NCCL watchdog thread terminated with exception: [Rank 9] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=675, OpType=ALLREDUCE, NumelIn=33554432, NumelOut=33554432, Timeout(ms)=600000) ran for 600070 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:576 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7fff9ed303a2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x207 (0x7fff9ed36927 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x122 (0x7fff9ed37aa2 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #4: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #6: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1377 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7fff9cfe9167 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x4bf33d (0x7fff9d5a833d in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch_hip.so)
frame #2: <unknown function> + 0x145a0 (0x7fffed0635a0 in /lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0xa761c (0x7fffed74f61c in /lib64/libc.so.6)
frame #4: <unknown function> + 0x12eaa8 (0x7fffed7d6aa8 in /lib64/libc.so.6)

/usr/bin/bash: line 3: 1763656 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
sleeping...
sleeping...
/usr/bin/bash: line 3: 1763659 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
sleeping...
/usr/bin/bash: line 3: 1763657 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
/usr/bin/bash: line 3: 1763658 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
sleeping...
sleeping...
/usr/bin/bash: line 3: 2389114 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
/usr/bin/bash: line 3: 2389110 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
sleeping...
/usr/bin/bash: line 3: 2389113 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
sleeping...
sleeping...
/usr/bin/bash: line 3: 1763662 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
/usr/bin/bash: line 3: 1763661 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
sleeping...
sleeping...
/usr/bin/bash: line 3: 1763660 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
/usr/bin/bash: line 3: 1763663 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
sleeping...
sleeping...
/usr/bin/bash: line 3: 2389117 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
/usr/bin/bash: line 3: 2389115 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
sleeping...
/usr/bin/bash: line 3: 2389116 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
sleeping...
/usr/bin/bash: line 3: 2389112 Aborted                 (core dumped) python train.py configs/ERA5-100million-91variables.yaml --max_epochs 1 --fa2 --fsdp_size 1 --simple_ddp_size 1 --seq_par_size 1 --tensor_par_size 16 --batch_size 2 --arch $i --channels $k --imagex 128 --imagey 256 --embed_dim $j --depth 32 --num_heads 32
sleeping...
global rank 8: ddp rank 0 iter_start,iter_end = 0 8
global rank 8: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 9: ddp rank 0 iter_start,iter_end = 0 8
global rank 9: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 11: ddp rank 0 iter_start,iter_end = 0 8
global rank 11: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 13: ddp rank 0 iter_start,iter_end = 0 8
global rank 13: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 12: ddp rank 0 iter_start,iter_end = 0 8
global rank 12: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 14: ddp rank 0 iter_start,iter_end = 0 8
global rank 14: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 15: ddp rank 0 iter_start,iter_end = 0 8
global rank 15: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 10: ddp rank 0 iter_start,iter_end = 0 8
global rank 10: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:55,869] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:56,335] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:56,335] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:56,335] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:56,732] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:56,732] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:56,733] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:57,162] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:57,162] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:57,162] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:57,162] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:57,178] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:57,178] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:57,178] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-14 13:30:57,178] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
HERE0 Namespace(arch='orbit_hier', batch_size=2, channels=32, depth=32, embed_dim=8192, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=16, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
rank 2 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
Using dist.init_process_group. world_size  16
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier05869.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  16
rank 7 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 8 Before initialize parallelism groups
rank 15 Before initialize parallelism groups
rank 13 Before initialize parallelism groups
rank 10 Before initialize parallelism groups
rank 15 After initialize parallelism groups
rank 8 After initialize parallelism groups
rank 13 After initialize parallelism groups
rank 10 After initialize parallelism groups
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 9 Before initialize parallelism groups
rank 9 After initialize parallelism groups
rank 14 Before initialize parallelism groups
rank 12 Before initialize parallelism groups
rank 14 After initialize parallelism groups
rank 12 After initialize parallelism groups
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
Using dist.init_process_group. world_size  16
rank 4 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 4 After initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 6 After initialize parallelism groups
Using dist.init_process_group. world_size  16
rank 11 Before initialize parallelism groups
rank 11 After initialize parallelism groups
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 10 After initialize model
rank 10 Before the second dist.barrier()
rank 8 After initialize model
rank 8 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 12 After initialize model
rank 12 Before the second dist.barrier()
rank 9 After initialize model
rank 9 Before the second dist.barrier()
rank 15 After initialize model
rank 15 Before the second dist.barrier()
rank 14 After initialize model
rank 14 Before the second dist.barrier()
rank 13 After initialize model
rank 13 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 11 After initialize model
rank 11 Before the second dist.barrier()
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 3196776.0 ON frontier05869 CANCELLED AT 2025-03-14T14:47:43 ***
slurmstepd: error: *** JOB 3196776 ON frontier05869 CANCELLED AT 2025-03-14T14:47:43 ***

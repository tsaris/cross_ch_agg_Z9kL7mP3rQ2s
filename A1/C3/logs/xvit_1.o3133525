
Lmod is automatically replacing "cce/18.0.1" with "gcc-native/13.2".


Lmod is automatically replacing "PrgEnv-cray/8.6.0" with "PrgEnv-gnu/8.6.0".


Due to MODULEPATH changes, the following have been reloaded:
  1) cray-libsci/24.11.0     2) cray-mpich/8.1.31     3) darshan-runtime/3.4.6-mpi


Lmod is automatically replacing "gcc-native/13.2" with "gcc/12.2.0".


Inactive Modules:
  1) darshan-runtime

The following have been reloaded with a version change:
  1) cray-libsci/24.11.0 => cray-libsci/23.09.1.1
  2) cray-mpich/8.1.31 => cray-mpich/8.1.27
  3) libfabric/1.22.0 => libfabric/1.20.1

Lmod has detected the following error: These module(s) or extension(s) exist
but cannot be loaded as requested: "darshan-runtime"
   Try: "module spider darshan-runtime" to see how to load the module(s).



for i in {orbit_hier_token,orbit_hier_token_noagg,orbit_hier_token_noagg_self,orbit_linear}; do for j in {2,}; do for k in {32,64,128,256,512,768,1024}; do python train.py \ configs/ERA5-100million-91variables.yaml \ --max_epochs 1 \ --fa2 \ --fsdp_size 1 \ --simple_ddp_size 1 \ --seq_par_size 1 \ --tensor_par_size 8 \ --batch_size $j \ --arch $i \ --channels $k \ --imagex 128 \ --imagey 256 \ --embed_dim 4096 \ --depth 32 \ --num_heads 32 echo "sleeping..." sleep 5 echo "Done" done done done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:41,660] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:41,660] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:41,660] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:41,660] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:41,660] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:41,660] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:41,660] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:07:41,660] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=32, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 5 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 7 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 3 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(46416384) params_per_gpu tensor(46416384)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
MIOpen(HIP): Warning [PlainTextDb] Unable to create a directory: "/tmp/.config/miopen"
MIOpen(HIP): Warning [PlainTextDb] Unable to create a directory: "/tmp/.config/miopen"
epoch-train:  0 batch_idx 0 world_rank 0  loss  0.455078125
epoch-train:  0 batch_idx 1 world_rank 0  loss  0.455078125
epoch-train:  0 batch_idx 2 world_rank 0  loss  0.453125
epoch-train:  0 batch_idx 3 world_rank 0  loss  0.453125
[2025-03-07 22:08:03,184] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:03,184] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:03,184] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:03,184] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:03,184] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:03,185] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:03,185] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:03,185] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:03,204] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:03,205] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:03,205] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:03,205] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:03,205] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:03,205] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:03,206] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:03,206] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 46.416384 M TFLOPS: 32.00321510293518

--> cuda max reserved memory = 2.2715
--> max reserved percentage = 3.55 %

--> cuda max memory allocated = 1.2408
--> max allocated percentage = 1.94 %

--> peak active memory = 1.2408
--> peak active memory 1.94 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=32, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 2.2715 32.00321510293518 tensor(46416384)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:16,837] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:16,837] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:16,837] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:16,837] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:16,837] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:16,837] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:16,837] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:16,837] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=64, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 3 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 4 After initialize model
rank 5 After initialize model
rank 4 Before the second dist.barrier()
rank 5 Before the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(50873344) params_per_gpu tensor(50873344)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  0.828125
epoch-train:  0 batch_idx 1 world_rank 0  loss  0.828125
epoch-train:  0 batch_idx 2 world_rank 0  loss  0.828125
epoch-train:  0 batch_idx 3 world_rank 0  loss  0.828125
[2025-03-07 22:08:31,105] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:31,106] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:31,106] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:31,106] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:31,106] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:31,106] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:31,106] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:31,106] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:31,140] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:31,142] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:31,142] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:31,142] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:31,142] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:31,142] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:31,142] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:31,142] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 50.873344 M TFLOPS: 23.346885202979703

--> cuda max reserved memory = 2.8066
--> max reserved percentage = 4.39 %

--> cuda max memory allocated = 1.6298
--> max allocated percentage = 2.55 %

--> peak active memory = 1.6298
--> peak active memory 2.55 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=64, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 2.8066 23.346885202979703 tensor(50873344)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:44,748] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:44,748] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:44,748] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:44,748] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:44,748] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:44,748] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:44,748] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:08:44,748] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=128, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 7 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(59787264) params_per_gpu tensor(59787264)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  0.474609375
epoch-train:  0 batch_idx 1 world_rank 0  loss  0.47265625
epoch-train:  0 batch_idx 2 world_rank 0  loss  0.47265625
epoch-train:  0 batch_idx 3 world_rank 0  loss  0.47265625
[2025-03-07 22:08:59,161] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:59,243] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[2025-03-07 22:08:59,328] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:59,328] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:59,328] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:59,328] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:59,328] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:59,328] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:59,328] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:08:59,393] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:59,393] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:59,393] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:59,393] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:59,393] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:59,394] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:08:59,394] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 59.787264 M TFLOPS: 1.6389381749397094

--> cuda max reserved memory = 2.8633
--> max reserved percentage = 4.47 %

--> cuda max memory allocated = 2.5518
--> max allocated percentage = 3.99 %

--> peak active memory = 2.5518
--> peak active memory 3.99 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=128, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 2.8633 1.6389381749397094 tensor(59787264)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:12,609] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:12,609] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:12,609] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:12,609] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:12,609] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:12,609] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:12,609] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:12,609] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=256, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 5 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 256, 4096])
rank 7 After the second dist.barrier()
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([4096])
total_params before FSDP tensor(77615104) params_per_gpu tensor(77615104)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-255): 256 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=4096, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  0.63671875
epoch-train:  0 batch_idx 1 world_rank 0  loss  0.63671875
epoch-train:  0 batch_idx 2 world_rank 0  loss  0.63671875
epoch-train:  0 batch_idx 3 world_rank 0  loss  0.63671875
[2025-03-07 22:09:27,238] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:27,238] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:27,239] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:27,239] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:27,239] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:27,239] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:27,239] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:27,239] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:27,358] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:27,359] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:27,360] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:27,360] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:27,360] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:27,360] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:27,360] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:27,360] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 77.615104 M TFLOPS: 11.18346270322011

--> cuda max reserved memory = 4.7715
--> max reserved percentage = 7.46 %

--> cuda max memory allocated = 4.3976
--> max allocated percentage = 6.87 %

--> peak active memory = 4.3976
--> peak active memory 6.87 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=256, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 4.7715 11.18346270322011 tensor(77615104)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:41,052] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:41,052] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:41,052] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:41,052] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:41,052] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:41,052] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:41,052] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:09:41,052] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=512, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 1 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 6 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 512, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([8192, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([8192])
total_params before FSDP tensor(113270784) params_per_gpu tensor(113270784)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-511): 512 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=8192, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  0.671875
epoch-train:  0 batch_idx 1 world_rank 0  loss  0.671875
epoch-train:  0 batch_idx 2 world_rank 0  loss  0.671875
epoch-train:  0 batch_idx 3 world_rank 0  loss  0.671875
[2025-03-07 22:09:56,721] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:56,724] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:56,724] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:56,724] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:56,724] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:56,725] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:56,725] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:56,726] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:09:57,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:57,076] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:57,077] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:57,077] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:57,078] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:57,078] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:57,078] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:09:57,079] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 113.270784 M TFLOPS: 8.041906237196988

--> cuda max reserved memory = 8.5801
--> max reserved percentage = 13.41 %

--> cuda max memory allocated = 8.0893
--> max allocated percentage = 12.64 %

--> peak active memory = 8.0893
--> peak active memory 12.64 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=512, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 8.5801 8.041906237196988 tensor(113270784)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:10,937] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:10,937] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:10,937] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:10,937] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:10,937] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:10,937] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:10,937] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:10,937] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=768, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 2 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 768, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.512.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.512.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.513.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.513.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.514.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.514.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.515.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.515.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.516.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.516.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.517.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.517.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.518.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.518.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.519.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.519.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.520.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.520.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.521.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.521.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.522.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.522.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.523.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.523.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.524.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.524.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.525.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.525.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.526.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.526.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.527.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.527.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.528.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.528.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.529.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.529.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.530.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.530.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.531.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.531.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.532.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.532.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.533.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.533.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.534.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.534.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.535.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.535.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.536.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.536.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.537.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.537.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.538.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.538.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.539.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.539.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.540.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.540.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.541.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.541.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.542.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.542.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.543.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.543.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.544.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.544.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.545.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.545.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.546.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.546.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.547.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.547.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.548.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.548.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.549.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.549.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.550.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.550.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.551.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.551.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.552.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.552.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.553.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.553.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.554.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.554.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.555.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.555.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.556.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.556.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.557.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.557.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.558.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.558.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.559.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.559.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.560.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.560.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.561.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.561.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.562.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.562.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.563.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.563.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.564.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.564.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.565.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.565.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.566.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.566.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.567.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.567.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.568.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.568.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.569.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.569.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.570.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.570.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.571.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.571.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.572.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.572.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.573.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.573.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.574.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.574.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.575.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.575.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.576.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.576.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.577.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.577.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.578.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.578.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.579.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.579.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.580.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.580.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.581.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.581.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.582.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.582.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.583.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.583.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.584.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.584.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.585.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.585.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.586.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.586.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.587.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.587.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.588.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.588.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.589.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.589.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.590.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.590.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.591.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.591.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.592.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.592.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.593.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.593.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.594.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.594.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.595.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.595.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.596.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.596.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.597.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.597.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.598.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.598.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.599.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.599.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.600.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.600.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.601.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.601.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.602.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.602.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.603.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.603.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.604.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.604.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.605.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.605.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.606.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.606.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.607.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.607.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.608.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.608.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.609.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.609.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.610.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.610.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.611.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.611.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.612.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.612.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.613.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.613.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.614.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.614.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.615.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.615.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.616.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.616.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.617.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.617.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.618.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.618.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.619.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.619.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.620.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.620.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.621.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.621.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.622.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.622.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.623.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.623.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.624.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.624.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.625.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.625.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.626.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.626.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.627.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.627.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.628.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.628.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.629.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.629.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.630.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.630.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.631.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.631.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.632.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.632.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.633.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.633.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.634.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.634.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.635.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.635.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.636.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.636.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.637.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.637.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.638.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.638.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.639.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.639.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.640.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.640.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.641.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.641.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.642.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.642.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.643.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.643.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.644.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.644.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.645.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.645.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.646.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.646.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.647.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.647.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.648.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.648.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.649.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.649.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.650.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.650.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.651.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.651.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.652.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.652.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.653.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.653.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.654.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.654.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.655.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.655.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.656.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.656.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.657.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.657.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.658.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.658.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.659.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.659.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.660.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.660.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.661.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.661.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.662.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.662.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.663.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.663.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.664.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.664.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.665.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.665.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.666.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.666.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.667.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.667.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.668.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.668.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.669.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.669.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.670.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.670.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.671.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.671.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.672.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.672.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.673.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.673.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.674.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.674.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.675.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.675.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.676.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.676.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.677.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.677.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.678.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.678.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.679.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.679.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.680.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.680.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.681.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.681.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.682.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.682.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.683.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.683.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.684.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.684.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.685.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.685.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.686.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.686.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.687.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.687.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.688.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.688.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.689.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.689.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.690.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.690.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.691.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.691.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.692.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.692.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.693.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.693.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.694.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.694.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.695.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.695.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.696.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.696.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.697.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.697.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.698.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.698.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.699.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.699.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.700.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.700.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.701.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.701.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.702.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.702.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.703.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.703.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.704.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.704.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.705.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.705.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.706.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.706.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.707.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.707.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.708.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.708.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.709.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.709.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.710.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.710.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.711.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.711.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.712.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.712.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.713.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.713.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.714.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.714.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.715.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.715.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.716.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.716.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.717.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.717.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.718.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.718.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.719.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.719.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.720.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.720.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.721.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.721.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.722.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.722.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.723.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.723.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.724.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.724.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.725.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.725.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.726.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.726.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.727.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.727.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.728.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.728.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.729.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.729.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.730.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.730.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.731.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.731.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.732.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.732.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.733.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.733.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.734.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.734.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.735.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.735.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.736.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.736.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.737.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.737.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.738.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.738.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.739.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.739.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.740.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.740.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.741.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.741.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.742.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.742.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.743.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.743.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.744.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.744.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.745.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.745.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.746.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.746.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.747.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.747.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.748.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.748.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.749.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.749.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.750.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.750.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.751.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.751.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.752.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.752.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.753.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.753.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.754.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.754.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.755.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.755.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.756.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.756.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.757.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.757.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.758.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.758.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.759.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.759.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.760.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.760.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.761.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.761.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.762.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.762.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.763.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.763.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.764.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.764.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.765.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.765.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.766.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.766.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.767.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.767.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([12288, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([12288])
total_params before FSDP tensor(148926464) params_per_gpu tensor(148926464)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-767): 768 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=12288, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  0.97265625
epoch-train:  0 batch_idx 1 world_rank 0  loss  0.97265625
epoch-train:  0 batch_idx 2 world_rank 0  loss  0.97265625
epoch-train:  0 batch_idx 3 world_rank 0  loss  0.97265625
[2025-03-07 22:10:28,272] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:28,274] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:28,276] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:28,276] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:28,276] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:28,276] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:28,277] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:28,277] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:28,620] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:28,624] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:28,624] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:28,625] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:28,626] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:28,626] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:28,627] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:28,629] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 148.926464 M TFLOPS: 6.876968080683772

--> cuda max reserved memory = 12.3594
--> max reserved percentage = 19.32 %

--> cuda max memory allocated = 11.7811
--> max allocated percentage = 18.41 %

--> peak active memory = 11.7811
--> peak active memory 18.41 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=768, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 12.3594 6.876968080683772 tensor(148926464)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:42,163] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:42,163] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:42,163] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:42,163] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:42,163] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:42,163] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:42,163] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:10:42,163] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token', batch_size=2, channels=1024, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 7 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 4 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 1024, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.512.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.512.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.513.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.513.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.514.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.514.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.515.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.515.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.516.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.516.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.517.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.517.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.518.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.518.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.519.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.519.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.520.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.520.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.521.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.521.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.522.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.522.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.523.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.523.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.524.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.524.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.525.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.525.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.526.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.526.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.527.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.527.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.528.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.528.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.529.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.529.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.530.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.530.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.531.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.531.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.532.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.532.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.533.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.533.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.534.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.534.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.535.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.535.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.536.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.536.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.537.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.537.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.538.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.538.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.539.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.539.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.540.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.540.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.541.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.541.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.542.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.542.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.543.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.543.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.544.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.544.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.545.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.545.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.546.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.546.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.547.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.547.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.548.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.548.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.549.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.549.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.550.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.550.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.551.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.551.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.552.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.552.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.553.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.553.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.554.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.554.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.555.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.555.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.556.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.556.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.557.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.557.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.558.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.558.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.559.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.559.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.560.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.560.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.561.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.561.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.562.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.562.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.563.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.563.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.564.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.564.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.565.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.565.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.566.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.566.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.567.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.567.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.568.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.568.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.569.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.569.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.570.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.570.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.571.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.571.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.572.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.572.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.573.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.573.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.574.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.574.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.575.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.575.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.576.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.576.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.577.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.577.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.578.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.578.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.579.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.579.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.580.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.580.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.581.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.581.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.582.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.582.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.583.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.583.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.584.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.584.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.585.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.585.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.586.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.586.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.587.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.587.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.588.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.588.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.589.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.589.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.590.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.590.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.591.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.591.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.592.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.592.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.593.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.593.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.594.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.594.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.595.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.595.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.596.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.596.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.597.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.597.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.598.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.598.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.599.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.599.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.600.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.600.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.601.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.601.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.602.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.602.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.603.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.603.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.604.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.604.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.605.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.605.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.606.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.606.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.607.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.607.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.608.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.608.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.609.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.609.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.610.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.610.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.611.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.611.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.612.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.612.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.613.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.613.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.614.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.614.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.615.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.615.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.616.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.616.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.617.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.617.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.618.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.618.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.619.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.619.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.620.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.620.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.621.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.621.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.622.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.622.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.623.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.623.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.624.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.624.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.625.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.625.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.626.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.626.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.627.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.627.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.628.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.628.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.629.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.629.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.630.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.630.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.631.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.631.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.632.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.632.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.633.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.633.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.634.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.634.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.635.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.635.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.636.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.636.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.637.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.637.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.638.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.638.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.639.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.639.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.640.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.640.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.641.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.641.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.642.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.642.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.643.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.643.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.644.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.644.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.645.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.645.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.646.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.646.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.647.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.647.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.648.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.648.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.649.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.649.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.650.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.650.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.651.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.651.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.652.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.652.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.653.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.653.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.654.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.654.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.655.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.655.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.656.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.656.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.657.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.657.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.658.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.658.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.659.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.659.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.660.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.660.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.661.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.661.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.662.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.662.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.663.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.663.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.664.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.664.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.665.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.665.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.666.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.666.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.667.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.667.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.668.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.668.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.669.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.669.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.670.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.670.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.671.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.671.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.672.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.672.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.673.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.673.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.674.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.674.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.675.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.675.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.676.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.676.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.677.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.677.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.678.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.678.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.679.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.679.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.680.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.680.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.681.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.681.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.682.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.682.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.683.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.683.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.684.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.684.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.685.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.685.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.686.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.686.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.687.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.687.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.688.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.688.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.689.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.689.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.690.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.690.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.691.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.691.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.692.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.692.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.693.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.693.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.694.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.694.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.695.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.695.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.696.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.696.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.697.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.697.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.698.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.698.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.699.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.699.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.700.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.700.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.701.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.701.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.702.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.702.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.703.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.703.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.704.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.704.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.705.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.705.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.706.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.706.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.707.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.707.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.708.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.708.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.709.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.709.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.710.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.710.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.711.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.711.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.712.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.712.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.713.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.713.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.714.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.714.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.715.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.715.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.716.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.716.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.717.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.717.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.718.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.718.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.719.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.719.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.720.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.720.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.721.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.721.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.722.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.722.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.723.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.723.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.724.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.724.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.725.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.725.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.726.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.726.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.727.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.727.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.728.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.728.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.729.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.729.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.730.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.730.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.731.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.731.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.732.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.732.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.733.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.733.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.734.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.734.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.735.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.735.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.736.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.736.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.737.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.737.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.738.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.738.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.739.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.739.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.740.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.740.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.741.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.741.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.742.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.742.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.743.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.743.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.744.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.744.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.745.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.745.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.746.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.746.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.747.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.747.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.748.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.748.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.749.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.749.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.750.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.750.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.751.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.751.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.752.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.752.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.753.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.753.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.754.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.754.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.755.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.755.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.756.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.756.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.757.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.757.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.758.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.758.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.759.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.759.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.760.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.760.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.761.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.761.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.762.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.762.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.763.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.763.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.764.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.764.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.765.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.765.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.766.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.766.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.767.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.767.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.768.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.768.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.769.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.769.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.770.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.770.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.771.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.771.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.772.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.772.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.773.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.773.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.774.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.774.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.775.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.775.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.776.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.776.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.777.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.777.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.778.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.778.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.779.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.779.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.780.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.780.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.781.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.781.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.782.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.782.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.783.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.783.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.784.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.784.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.785.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.785.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.786.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.786.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.787.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.787.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.788.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.788.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.789.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.789.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.790.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.790.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.791.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.791.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.792.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.792.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.793.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.793.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.794.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.794.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.795.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.795.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.796.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.796.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.797.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.797.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.798.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.798.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.799.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.799.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.800.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.800.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.801.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.801.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.802.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.802.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.803.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.803.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.804.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.804.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.805.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.805.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.806.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.806.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.807.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.807.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.808.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.808.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.809.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.809.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.810.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.810.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.811.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.811.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.812.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.812.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.813.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.813.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.814.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.814.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.815.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.815.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.816.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.816.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.817.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.817.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.818.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.818.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.819.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.819.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.820.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.820.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.821.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.821.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.822.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.822.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.823.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.823.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.824.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.824.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.825.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.825.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.826.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.826.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.827.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.827.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.828.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.828.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.829.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.829.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.830.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.830.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.831.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.831.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.832.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.832.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.833.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.833.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.834.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.834.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.835.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.835.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.836.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.836.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.837.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.837.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.838.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.838.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.839.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.839.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.840.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.840.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.841.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.841.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.842.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.842.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.843.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.843.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.844.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.844.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.845.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.845.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.846.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.846.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.847.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.847.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.848.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.848.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.849.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.849.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.850.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.850.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.851.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.851.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.852.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.852.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.853.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.853.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.854.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.854.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.855.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.855.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.856.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.856.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.857.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.857.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.858.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.858.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.859.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.859.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.860.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.860.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.861.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.861.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.862.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.862.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.863.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.863.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.864.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.864.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.865.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.865.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.866.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.866.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.867.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.867.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.868.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.868.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.869.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.869.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.870.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.870.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.871.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.871.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.872.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.872.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.873.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.873.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.874.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.874.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.875.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.875.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.876.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.876.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.877.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.877.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.878.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.878.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.879.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.879.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.880.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.880.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.881.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.881.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.882.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.882.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.883.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.883.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.884.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.884.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.885.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.885.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.886.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.886.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.887.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.887.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.888.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.888.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.889.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.889.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.890.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.890.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.891.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.891.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.892.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.892.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.893.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.893.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.894.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.894.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.895.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.895.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.896.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.896.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.897.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.897.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.898.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.898.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.899.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.899.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.900.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.900.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.901.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.901.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.902.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.902.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.903.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.903.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.904.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.904.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.905.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.905.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.906.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.906.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.907.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.907.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.908.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.908.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.909.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.909.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.910.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.910.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.911.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.911.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.912.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.912.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.913.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.913.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.914.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.914.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.915.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.915.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.916.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.916.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.917.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.917.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.918.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.918.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.919.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.919.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.920.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.920.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.921.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.921.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.922.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.922.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.923.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.923.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.924.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.924.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.925.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.925.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.926.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.926.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.927.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.927.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.928.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.928.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.929.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.929.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.930.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.930.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.931.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.931.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.932.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.932.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.933.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.933.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.934.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.934.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.935.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.935.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.936.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.936.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.937.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.937.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.938.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.938.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.939.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.939.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.940.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.940.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.941.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.941.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.942.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.942.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.943.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.943.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.944.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.944.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.945.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.945.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.946.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.946.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.947.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.947.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.948.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.948.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.949.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.949.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.950.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.950.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.951.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.951.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.952.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.952.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.953.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.953.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.954.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.954.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.955.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.955.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.956.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.956.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.957.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.957.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.958.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.958.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.959.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.959.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.960.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.960.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.961.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.961.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.962.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.962.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.963.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.963.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.964.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.964.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.965.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.965.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.966.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.966.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.967.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.967.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.968.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.968.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.969.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.969.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.970.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.970.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.971.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.971.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.972.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.972.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.973.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.973.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.974.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.974.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.975.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.975.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.976.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.976.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.977.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.977.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.978.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.978.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.979.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.979.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.980.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.980.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.981.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.981.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.982.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.982.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.983.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.983.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.984.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.984.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.985.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.985.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.986.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.986.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.987.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.987.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.988.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.988.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.989.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.989.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.990.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.990.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.991.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.991.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.992.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.992.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.993.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.993.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.994.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.994.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.995.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.995.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.996.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.996.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.997.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.997.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.998.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.998.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.999.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.999.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1000.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1000.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1001.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1001.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1002.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1002.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1003.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1003.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1004.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1004.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1005.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1005.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1006.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1006.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1007.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1007.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1008.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1008.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1009.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1009.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1010.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1010.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1011.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1011.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1012.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1012.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1013.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1013.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1014.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1014.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1015.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1015.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1016.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1016.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1017.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1017.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1018.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1018.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1019.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1019.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1020.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1020.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1021.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1021.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1022.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1022.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1023.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1023.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([16384, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([16384])
total_params before FSDP tensor(184582144) params_per_gpu tensor(184582144)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-1023): 1024 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=16384, bias=True)
    )
  )
)
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  0.5546875
epoch-train:  0 batch_idx 1 world_rank 0  loss  0.55078125
epoch-train:  0 batch_idx 2 world_rank 0  loss  0.55078125
epoch-train:  0 batch_idx 3 world_rank 0  loss  0.55078125
[2025-03-07 22:10:59,414] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:59,415] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:59,416] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:59,416] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:59,416] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:59,416] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:59,416] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:59,417] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:10:59,765] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:59,766] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:59,766] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:59,767] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:59,767] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:59,767] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:59,767] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:10:59,767] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 184.582144 M TFLOPS: 8.675835840337761

--> cuda max reserved memory = 16.1309
--> max reserved percentage = 25.21 %

--> cuda max memory allocated = 15.4728
--> max allocated percentage = 24.18 %

--> peak active memory = 15.4728
--> peak active memory 24.18 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token', batch_size=2, channels=1024, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 16.1309 8.675835840337761 tensor(184582144)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:13,486] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:13,486] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:13,486] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:13,486] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:13,486] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:13,486] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:13,486] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:13,486] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=32, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 3 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(113562112) params_per_gpu tensor(54813184)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.1875
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.1875
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.1796875
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.1796875
[2025-03-07 22:11:28,360] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:28,360] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:28,360] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:28,360] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:28,360] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:28,360] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:28,360] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:28,360] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:28,432] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:28,432] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:28,432] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:28,432] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:28,432] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:28,432] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:28,432] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:28,432] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 54.813184 M TFLOPS: 28.01264016761787

--> cuda max reserved memory = 5.8652
--> max reserved percentage = 9.17 %

--> cuda max memory allocated = 4.475
--> max allocated percentage = 6.99 %

--> peak active memory = 5.6
--> peak active memory 8.75 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=32, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 5.8652 28.01264016761787 tensor(113562112)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:11:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=64, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 3 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 1 After initialize model
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 1 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 5 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(118019072) params_per_gpu tensor(59270144)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.6796875
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.6796875
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.671875
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.671875
[2025-03-07 22:11:57,784] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:57,784] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:57,784] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:57,784] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:57,784] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:57,784] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:57,784] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:57,784] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:11:57,917] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:57,917] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:57,917] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:57,917] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:57,917] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:57,917] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:57,917] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:11:57,917] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 59.270144 M TFLOPS: 26.18410165867628

--> cuda max reserved memory = 10.6895
--> max reserved percentage = 16.71 %

--> cuda max memory allocated = 8.0615
--> max allocated percentage = 12.6 %

--> peak active memory = 10.3115
--> peak active memory 16.12 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=64, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 10.6895 26.18410165867628 tensor(118019072)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:11,523] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:11,523] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:11,523] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:11,523] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:11,523] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:11,523] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:11,523] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:11,523] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=128, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 6 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(126932992) params_per_gpu tensor(68184064)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.0703125
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.0703125
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.0703125
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.0625
[2025-03-07 22:12:28,172] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:12:28,172] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:12:28,172] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:12:28,172] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:12:28,172] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:12:28,172] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:12:28,172] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:12:28,172] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:12:28,425] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:12:28,425] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:12:28,425] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:12:28,425] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:12:28,425] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:12:28,425] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:12:28,426] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:12:28,426] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 68.184064 M TFLOPS: 24.83315953339129

--> cuda max reserved memory = 20.1445
--> max reserved percentage = 31.48 %

--> cuda max memory allocated = 15.2355
--> max allocated percentage = 23.81 %

--> peak active memory = 19.7355
--> peak active memory 30.84 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=128, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 20.1445 24.83315953339129 tensor(126932992)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:42,068] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:42,069] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:12:42,069] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=256, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 7 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 0 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 256, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([4096])
total_params before FSDP tensor(144760832) params_per_gpu tensor(86011904)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-255): 256 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=4096, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.6640625
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.6640625
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.65625
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.65625
[2025-03-07 22:13:01,475] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:01,475] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:01,475] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:01,475] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:01,475] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:01,475] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:01,475] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:01,476] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:01,977] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:01,977] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:01,977] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:01,977] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:01,977] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:01,977] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:01,977] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:01,977] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 86.011904 M TFLOPS: 24.157858201921183

--> cuda max reserved memory = 39.3457
--> max reserved percentage = 61.49 %

--> cuda max memory allocated = 29.5852
--> max allocated percentage = 46.24 %

--> peak active memory = 38.5852
--> peak active memory 60.3 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=256, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 39.3457 24.157858201921183 tensor(144760832)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:15,563] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:15,563] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:15,563] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:15,563] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:15,563] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:15,563] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:15,563] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:15,563] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=512, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 2 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 512, 4096])
rank 6 After the second dist.barrier()
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([8192, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([8192])
total_params before FSDP tensor(180416512) params_per_gpu tensor(121667584)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-511): 512 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=8192, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  2.453125
epoch-train:  0 batch_idx 1 world_rank 0  loss  2.4375
epoch-train:  0 batch_idx 2 world_rank 0  loss  2.4375
epoch-train:  0 batch_idx 3 world_rank 0  loss  2.4375
[2025-03-07 22:13:41,761] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:41,761] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:41,761] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:41,761] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:41,761] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:41,762] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:41,762] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:41,762] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:13:43,524] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:43,524] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:43,524] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:43,524] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:43,524] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:43,524] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:43,524] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:13:43,524] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 121.667584 M TFLOPS: 19.40733448547961

--> cuda max reserved memory = 59.7148
--> max reserved percentage = 93.33 %

--> cuda max memory allocated = 58.2848
--> max allocated percentage = 91.09 %

--> peak active memory = 58.2848
--> peak active memory 91.09 %

cudaMalloc retries = 6
cuda OOM = 0

--> Recommend decreasing batch size...cuda retries can greatly degrade perf!
HERE1 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=512, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 59.7148 19.40733448547961 tensor(180416512)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:57,097] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:57,097] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:57,097] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:57,097] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:57,097] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:57,097] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:57,098] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:13:57,098] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=768, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 7 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 0 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 768, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.512.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.512.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.513.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.513.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.514.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.514.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.515.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.515.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.516.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.516.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.517.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.517.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.518.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.518.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.519.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.519.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.520.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.520.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.521.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.521.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.522.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.522.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.523.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.523.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.524.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.524.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.525.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.525.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.526.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.526.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.527.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.527.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.528.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.528.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.529.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.529.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.530.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.530.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.531.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.531.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.532.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.532.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.533.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.533.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.534.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.534.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.535.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.535.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.536.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.536.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.537.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.537.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.538.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.538.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.539.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.539.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.540.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.540.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.541.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.541.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.542.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.542.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.543.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.543.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.544.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.544.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.545.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.545.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.546.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.546.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.547.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.547.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.548.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.548.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.549.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.549.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.550.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.550.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.551.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.551.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.552.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.552.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.553.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.553.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.554.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.554.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.555.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.555.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.556.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.556.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.557.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.557.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.558.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.558.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.559.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.559.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.560.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.560.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.561.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.561.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.562.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.562.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.563.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.563.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.564.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.564.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.565.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.565.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.566.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.566.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.567.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.567.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.568.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.568.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.569.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.569.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.570.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.570.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.571.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.571.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.572.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.572.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.573.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.573.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.574.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.574.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.575.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.575.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.576.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.576.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.577.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.577.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.578.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.578.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.579.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.579.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.580.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.580.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.581.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.581.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.582.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.582.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.583.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.583.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.584.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.584.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.585.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.585.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.586.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.586.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.587.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.587.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.588.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.588.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.589.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.589.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.590.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.590.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.591.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.591.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.592.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.592.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.593.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.593.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.594.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.594.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.595.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.595.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.596.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.596.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.597.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.597.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.598.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.598.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.599.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.599.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.600.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.600.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.601.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.601.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.602.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.602.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.603.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.603.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.604.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.604.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.605.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.605.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.606.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.606.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.607.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.607.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.608.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.608.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.609.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.609.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.610.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.610.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.611.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.611.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.612.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.612.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.613.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.613.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.614.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.614.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.615.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.615.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.616.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.616.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.617.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.617.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.618.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.618.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.619.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.619.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.620.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.620.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.621.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.621.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.622.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.622.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.623.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.623.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.624.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.624.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.625.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.625.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.626.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.626.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.627.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.627.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.628.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.628.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.629.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.629.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.630.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.630.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.631.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.631.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.632.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.632.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.633.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.633.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.634.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.634.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.635.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.635.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.636.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.636.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.637.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.637.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.638.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.638.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.639.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.639.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.640.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.640.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.641.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.641.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.642.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.642.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.643.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.643.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.644.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.644.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.645.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.645.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.646.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.646.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.647.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.647.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.648.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.648.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.649.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.649.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.650.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.650.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.651.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.651.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.652.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.652.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.653.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.653.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.654.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.654.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.655.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.655.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.656.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.656.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.657.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.657.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.658.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.658.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.659.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.659.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.660.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.660.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.661.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.661.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.662.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.662.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.663.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.663.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.664.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.664.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.665.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.665.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.666.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.666.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.667.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.667.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.668.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.668.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.669.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.669.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.670.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.670.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.671.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.671.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.672.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.672.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.673.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.673.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.674.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.674.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.675.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.675.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.676.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.676.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.677.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.677.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.678.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.678.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.679.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.679.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.680.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.680.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.681.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.681.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.682.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.682.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.683.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.683.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.684.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.684.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.685.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.685.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.686.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.686.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.687.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.687.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.688.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.688.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.689.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.689.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.690.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.690.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.691.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.691.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.692.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.692.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.693.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.693.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.694.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.694.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.695.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.695.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.696.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.696.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.697.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.697.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.698.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.698.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.699.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.699.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.700.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.700.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.701.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.701.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.702.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.702.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.703.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.703.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.704.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.704.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.705.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.705.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.706.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.706.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.707.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.707.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.708.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.708.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.709.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.709.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.710.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.710.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.711.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.711.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.712.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.712.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.713.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.713.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.714.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.714.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.715.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.715.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.716.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.716.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.717.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.717.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.718.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.718.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.719.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.719.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.720.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.720.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.721.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.721.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.722.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.722.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.723.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.723.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.724.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.724.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.725.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.725.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.726.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.726.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.727.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.727.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.728.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.728.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.729.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.729.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.730.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.730.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.731.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.731.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.732.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.732.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.733.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.733.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.734.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.734.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.735.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.735.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.736.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.736.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.737.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.737.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.738.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.738.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.739.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.739.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.740.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.740.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.741.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.741.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.742.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.742.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.743.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.743.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.744.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.744.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.745.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.745.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.746.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.746.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.747.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.747.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.748.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.748.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.749.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.749.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.750.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.750.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.751.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.751.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.752.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.752.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.753.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.753.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.754.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.754.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.755.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.755.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.756.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.756.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.757.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.757.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.758.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.758.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.759.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.759.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.760.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.760.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.761.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.761.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.762.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.762.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.763.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.763.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.764.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.764.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.765.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.765.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.766.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.766.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.767.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.767.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([12288, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([12288])
total_params before FSDP tensor(216072192) params_per_gpu tensor(157323264)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-767): 768 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=12288, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank5]: Traceback (most recent call last):
[rank5]:   File "train.py", line 986, in <module>
[rank5]:     main(args, device, world_size, world_rank, local_rank)
[rank5]:   File "train.py", line 890, in main
[rank5]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank5]:   File "train.py", line 372, in training_step
[rank5]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank5]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank5]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank5]:     x = self.aggregate_variables(x)        
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank5]:     x = x.flatten(0, 1)  # BxL, V, D
[rank5]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 5 has a total capacity of 63.98 GiB of which 10.69 GiB is free. Of the allocated memory 52.15 GiB is allocated by PyTorch, and 6.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 986, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 890, in main
[rank3]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank3]:   File "train.py", line 372, in training_step
[rank3]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank3]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank3]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank3]:     x = self.aggregate_variables(x)        
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank3]:     x = x.flatten(0, 1)  # BxL, V, D
[rank3]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 10.69 GiB is free. Of the allocated memory 52.15 GiB is allocated by PyTorch, and 6.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 890, in main
[rank1]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank1]:   File "train.py", line 372, in training_step
[rank1]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank1]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank1]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank1]:     x = self.aggregate_variables(x)        
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank1]:     x = x.flatten(0, 1)  # BxL, V, D
[rank1]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 10.69 GiB is free. Of the allocated memory 52.15 GiB is allocated by PyTorch, and 6.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank6]: Traceback (most recent call last):
[rank6]:   File "train.py", line 986, in <module>
[rank6]:     main(args, device, world_size, world_rank, local_rank)
[rank6]:   File "train.py", line 890, in main
[rank6]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank6]:   File "train.py", line 372, in training_step
[rank6]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank6]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank6]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank6]:     x = self.aggregate_variables(x)        
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank6]:     x = x.flatten(0, 1)  # BxL, V, D
[rank6]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 6 has a total capacity of 63.98 GiB of which 10.75 GiB is free. Of the allocated memory 52.15 GiB is allocated by PyTorch, and 6.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank7]: Traceback (most recent call last):
[rank7]:   File "train.py", line 986, in <module>
[rank7]:     main(args, device, world_size, world_rank, local_rank)
[rank7]:   File "train.py", line 890, in main
[rank7]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank7]:   File "train.py", line 372, in training_step
[rank7]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank7]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank7]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank7]:     x = self.aggregate_variables(x)        
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank7]:     x = x.flatten(0, 1)  # BxL, V, D
[rank7]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 7 has a total capacity of 63.98 GiB of which 10.69 GiB is free. Of the allocated memory 52.15 GiB is allocated by PyTorch, and 6.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "train.py", line 986, in <module>
[rank0]:     main(args, device, world_size, world_rank, local_rank)
[rank0]:   File "train.py", line 890, in main
[rank0]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank0]:   File "train.py", line 372, in training_step
[rank0]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank0]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank0]:     x = self.aggregate_variables(x)        
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank0]:     x = x.flatten(0, 1)  # BxL, V, D
[rank0]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 63.98 GiB of which 10.81 GiB is free. Of the allocated memory 52.15 GiB is allocated by PyTorch, and 6.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank2]: Traceback (most recent call last):
[rank2]:   File "train.py", line 986, in <module>
[rank2]:     main(args, device, world_size, world_rank, local_rank)
[rank2]:   File "train.py", line 890, in main
[rank2]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank2]:   File "train.py", line 372, in training_step
[rank2]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank2]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank2]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank2]:     x = self.aggregate_variables(x)        
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank2]:     x = x.flatten(0, 1)  # BxL, V, D
[rank2]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 2 has a total capacity of 63.98 GiB of which 10.75 GiB is free. Of the allocated memory 52.15 GiB is allocated by PyTorch, and 6.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank4]: Traceback (most recent call last):
[rank4]:   File "train.py", line 986, in <module>
[rank4]:     main(args, device, world_size, world_rank, local_rank)
[rank4]:   File "train.py", line 890, in main
[rank4]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank4]:   File "train.py", line 372, in training_step
[rank4]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank4]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank4]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 355, in forward_encoder
[rank4]:     x = self.aggregate_variables(x)        
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 302, in aggregate_variables
[rank4]:     x = x.flatten(0, 1)  # BxL, V, D
[rank4]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 4 has a total capacity of 63.98 GiB of which 10.69 GiB is free. Of the allocated memory 52.15 GiB is allocated by PyTorch, and 6.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:25,128] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:25,128] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:25,128] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:25,128] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:25,128] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:25,128] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:25,128] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:25,128] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg', batch_size=2, channels=1024, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 5 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 1024, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.512.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.512.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.513.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.513.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.514.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.514.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.515.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.515.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.516.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.516.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.517.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.517.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.518.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.518.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.519.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.519.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.520.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.520.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.521.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.521.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.522.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.522.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.523.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.523.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.524.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.524.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.525.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.525.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.526.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.526.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.527.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.527.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.528.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.528.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.529.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.529.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.530.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.530.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.531.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.531.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.532.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.532.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.533.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.533.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.534.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.534.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.535.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.535.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.536.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.536.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.537.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.537.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.538.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.538.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.539.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.539.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.540.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.540.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.541.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.541.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.542.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.542.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.543.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.543.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.544.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.544.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.545.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.545.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.546.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.546.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.547.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.547.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.548.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.548.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.549.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.549.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.550.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.550.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.551.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.551.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.552.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.552.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.553.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.553.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.554.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.554.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.555.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.555.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.556.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.556.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.557.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.557.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.558.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.558.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.559.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.559.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.560.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.560.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.561.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.561.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.562.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.562.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.563.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.563.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.564.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.564.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.565.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.565.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.566.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.566.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.567.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.567.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.568.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.568.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.569.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.569.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.570.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.570.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.571.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.571.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.572.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.572.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.573.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.573.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.574.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.574.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.575.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.575.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.576.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.576.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.577.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.577.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.578.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.578.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.579.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.579.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.580.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.580.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.581.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.581.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.582.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.582.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.583.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.583.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.584.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.584.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.585.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.585.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.586.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.586.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.587.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.587.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.588.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.588.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.589.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.589.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.590.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.590.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.591.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.591.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.592.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.592.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.593.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.593.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.594.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.594.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.595.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.595.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.596.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.596.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.597.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.597.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.598.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.598.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.599.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.599.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.600.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.600.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.601.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.601.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.602.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.602.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.603.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.603.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.604.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.604.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.605.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.605.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.606.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.606.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.607.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.607.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.608.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.608.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.609.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.609.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.610.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.610.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.611.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.611.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.612.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.612.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.613.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.613.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.614.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.614.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.615.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.615.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.616.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.616.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.617.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.617.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.618.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.618.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.619.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.619.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.620.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.620.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.621.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.621.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.622.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.622.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.623.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.623.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.624.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.624.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.625.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.625.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.626.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.626.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.627.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.627.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.628.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.628.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.629.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.629.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.630.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.630.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.631.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.631.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.632.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.632.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.633.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.633.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.634.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.634.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.635.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.635.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.636.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.636.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.637.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.637.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.638.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.638.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.639.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.639.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.640.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.640.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.641.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.641.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.642.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.642.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.643.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.643.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.644.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.644.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.645.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.645.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.646.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.646.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.647.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.647.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.648.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.648.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.649.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.649.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.650.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.650.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.651.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.651.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.652.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.652.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.653.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.653.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.654.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.654.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.655.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.655.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.656.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.656.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.657.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.657.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.658.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.658.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.659.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.659.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.660.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.660.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.661.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.661.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.662.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.662.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.663.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.663.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.664.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.664.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.665.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.665.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.666.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.666.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.667.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.667.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.668.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.668.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.669.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.669.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.670.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.670.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.671.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.671.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.672.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.672.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.673.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.673.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.674.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.674.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.675.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.675.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.676.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.676.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.677.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.677.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.678.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.678.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.679.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.679.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.680.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.680.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.681.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.681.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.682.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.682.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.683.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.683.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.684.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.684.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.685.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.685.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.686.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.686.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.687.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.687.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.688.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.688.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.689.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.689.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.690.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.690.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.691.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.691.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.692.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.692.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.693.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.693.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.694.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.694.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.695.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.695.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.696.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.696.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.697.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.697.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.698.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.698.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.699.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.699.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.700.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.700.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.701.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.701.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.702.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.702.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.703.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.703.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.704.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.704.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.705.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.705.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.706.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.706.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.707.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.707.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.708.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.708.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.709.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.709.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.710.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.710.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.711.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.711.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.712.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.712.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.713.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.713.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.714.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.714.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.715.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.715.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.716.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.716.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.717.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.717.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.718.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.718.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.719.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.719.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.720.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.720.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.721.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.721.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.722.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.722.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.723.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.723.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.724.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.724.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.725.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.725.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.726.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.726.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.727.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.727.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.728.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.728.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.729.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.729.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.730.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.730.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.731.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.731.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.732.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.732.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.733.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.733.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.734.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.734.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.735.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.735.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.736.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.736.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.737.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.737.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.738.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.738.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.739.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.739.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.740.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.740.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.741.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.741.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.742.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.742.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.743.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.743.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.744.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.744.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.745.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.745.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.746.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.746.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.747.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.747.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.748.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.748.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.749.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.749.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.750.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.750.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.751.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.751.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.752.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.752.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.753.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.753.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.754.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.754.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.755.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.755.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.756.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.756.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.757.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.757.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.758.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.758.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.759.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.759.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.760.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.760.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.761.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.761.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.762.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.762.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.763.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.763.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.764.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.764.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.765.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.765.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.766.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.766.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.767.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.767.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.768.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.768.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.769.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.769.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.770.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.770.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.771.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.771.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.772.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.772.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.773.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.773.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.774.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.774.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.775.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.775.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.776.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.776.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.777.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.777.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.778.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.778.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.779.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.779.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.780.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.780.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.781.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.781.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.782.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.782.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.783.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.783.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.784.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.784.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.785.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.785.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.786.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.786.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.787.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.787.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.788.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.788.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.789.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.789.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.790.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.790.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.791.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.791.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.792.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.792.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.793.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.793.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.794.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.794.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.795.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.795.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.796.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.796.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.797.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.797.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.798.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.798.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.799.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.799.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.800.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.800.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.801.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.801.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.802.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.802.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.803.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.803.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.804.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.804.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.805.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.805.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.806.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.806.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.807.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.807.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.808.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.808.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.809.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.809.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.810.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.810.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.811.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.811.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.812.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.812.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.813.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.813.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.814.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.814.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.815.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.815.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.816.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.816.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.817.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.817.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.818.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.818.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.819.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.819.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.820.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.820.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.821.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.821.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.822.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.822.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.823.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.823.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.824.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.824.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.825.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.825.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.826.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.826.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.827.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.827.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.828.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.828.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.829.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.829.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.830.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.830.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.831.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.831.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.832.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.832.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.833.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.833.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.834.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.834.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.835.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.835.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.836.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.836.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.837.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.837.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.838.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.838.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.839.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.839.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.840.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.840.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.841.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.841.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.842.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.842.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.843.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.843.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.844.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.844.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.845.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.845.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.846.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.846.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.847.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.847.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.848.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.848.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.849.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.849.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.850.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.850.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.851.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.851.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.852.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.852.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.853.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.853.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.854.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.854.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.855.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.855.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.856.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.856.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.857.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.857.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.858.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.858.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.859.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.859.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.860.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.860.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.861.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.861.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.862.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.862.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.863.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.863.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.864.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.864.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.865.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.865.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.866.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.866.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.867.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.867.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.868.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.868.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.869.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.869.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.870.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.870.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.871.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.871.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.872.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.872.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.873.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.873.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.874.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.874.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.875.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.875.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.876.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.876.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.877.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.877.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.878.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.878.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.879.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.879.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.880.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.880.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.881.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.881.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.882.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.882.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.883.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.883.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.884.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.884.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.885.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.885.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.886.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.886.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.887.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.887.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.888.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.888.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.889.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.889.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.890.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.890.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.891.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.891.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.892.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.892.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.893.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.893.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.894.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.894.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.895.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.895.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.896.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.896.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.897.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.897.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.898.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.898.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.899.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.899.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.900.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.900.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.901.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.901.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.902.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.902.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.903.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.903.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.904.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.904.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.905.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.905.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.906.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.906.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.907.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.907.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.908.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.908.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.909.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.909.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.910.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.910.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.911.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.911.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.912.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.912.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.913.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.913.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.914.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.914.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.915.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.915.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.916.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.916.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.917.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.917.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.918.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.918.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.919.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.919.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.920.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.920.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.921.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.921.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.922.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.922.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.923.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.923.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.924.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.924.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.925.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.925.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.926.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.926.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.927.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.927.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.928.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.928.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.929.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.929.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.930.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.930.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.931.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.931.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.932.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.932.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.933.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.933.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.934.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.934.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.935.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.935.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.936.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.936.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.937.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.937.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.938.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.938.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.939.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.939.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.940.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.940.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.941.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.941.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.942.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.942.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.943.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.943.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.944.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.944.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.945.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.945.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.946.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.946.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.947.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.947.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.948.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.948.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.949.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.949.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.950.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.950.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.951.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.951.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.952.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.952.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.953.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.953.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.954.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.954.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.955.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.955.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.956.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.956.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.957.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.957.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.958.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.958.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.959.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.959.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.960.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.960.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.961.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.961.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.962.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.962.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.963.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.963.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.964.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.964.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.965.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.965.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.966.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.966.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.967.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.967.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.968.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.968.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.969.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.969.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.970.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.970.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.971.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.971.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.972.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.972.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.973.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.973.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.974.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.974.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.975.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.975.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.976.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.976.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.977.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.977.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.978.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.978.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.979.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.979.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.980.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.980.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.981.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.981.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.982.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.982.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.983.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.983.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.984.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.984.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.985.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.985.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.986.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.986.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.987.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.987.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.988.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.988.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.989.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.989.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.990.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.990.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.991.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.991.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.992.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.992.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.993.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.993.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.994.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.994.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.995.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.995.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.996.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.996.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.997.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.997.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.998.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.998.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.999.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.999.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1000.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1000.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1001.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1001.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1002.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1002.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1003.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1003.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1004.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1004.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1005.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1005.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1006.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1006.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1007.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1007.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1008.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1008.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1009.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1009.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1010.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1010.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1011.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1011.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1012.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1012.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1013.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1013.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1014.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1014.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1015.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1015.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1016.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1016.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1017.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1017.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1018.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1018.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1019.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1019.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1020.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1020.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1021.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1021.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1022.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1022.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1023.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1023.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([16384, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([16384])
total_params before FSDP tensor(251727872) params_per_gpu tensor(192978944)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-1023): 1024 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=16384, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank4]: Traceback (most recent call last):
[rank4]:   File "train.py", line 986, in <module>
[rank4]:     main(args, device, world_size, world_rank, local_rank)
[rank4]:   File "train.py", line 890, in main
[rank4]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank4]:   File "train.py", line 372, in training_step
[rank4]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank4]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank4]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank4]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank4]:     return _AllGather.apply(group, tensor)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank4]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank4]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank4]:     return func(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank4]:     work = group.allgather([tensor_list], [tensor])
[rank4]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 4 has a total capacity of 63.98 GiB of which 21.31 GiB is free. Of the allocated memory 41.44 GiB is allocated by PyTorch, and 96.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 986, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 890, in main
[rank3]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank3]:   File "train.py", line 372, in training_step
[rank3]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank3]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank3]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank3]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank3]:     return _AllGather.apply(group, tensor)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank3]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank3]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank3]:     work = group.allgather([tensor_list], [tensor])
[rank3]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 21.31 GiB is free. Of the allocated memory 41.44 GiB is allocated by PyTorch, and 96.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 890, in main
[rank1]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank1]:   File "train.py", line 372, in training_step
[rank1]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank1]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank1]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank1]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank1]:     return _AllGather.apply(group, tensor)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank1]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank1]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank1]:     work = group.allgather([tensor_list], [tensor])
[rank1]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 21.31 GiB is free. Of the allocated memory 41.44 GiB is allocated by PyTorch, and 96.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank6]: Traceback (most recent call last):
[rank6]:   File "train.py", line 986, in <module>
[rank6]:     main(args, device, world_size, world_rank, local_rank)
[rank6]:   File "train.py", line 890, in main
[rank6]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank6]:   File "train.py", line 372, in training_step
[rank6]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank6]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank6]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank6]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank6]:     return _AllGather.apply(group, tensor)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank6]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank6]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank6]:     return func(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank6]:     work = group.allgather([tensor_list], [tensor])
[rank6]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 6 has a total capacity of 63.98 GiB of which 21.37 GiB is free. Of the allocated memory 41.44 GiB is allocated by PyTorch, and 96.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank5]: Traceback (most recent call last):
[rank5]:   File "train.py", line 986, in <module>
[rank5]:     main(args, device, world_size, world_rank, local_rank)
[rank5]:   File "train.py", line 890, in main
[rank5]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank5]:   File "train.py", line 372, in training_step
[rank5]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank5]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank5]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank5]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank5]:     return _AllGather.apply(group, tensor)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank5]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank5]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank5]:     return func(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank5]:     work = group.allgather([tensor_list], [tensor])
[rank5]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 5 has a total capacity of 63.98 GiB of which 21.31 GiB is free. Of the allocated memory 41.44 GiB is allocated by PyTorch, and 96.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank7]: Traceback (most recent call last):
[rank7]:   File "train.py", line 986, in <module>
[rank7]:     main(args, device, world_size, world_rank, local_rank)
[rank7]:   File "train.py", line 890, in main
[rank7]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank7]:   File "train.py", line 372, in training_step
[rank7]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank7]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank7]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank7]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank7]:     return _AllGather.apply(group, tensor)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank7]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank7]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank7]:     return func(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank7]:     work = group.allgather([tensor_list], [tensor])
[rank7]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 7 has a total capacity of 63.98 GiB of which 21.31 GiB is free. Of the allocated memory 41.44 GiB is allocated by PyTorch, and 96.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "train.py", line 986, in <module>
[rank0]:     main(args, device, world_size, world_rank, local_rank)
[rank0]:   File "train.py", line 890, in main
[rank0]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank0]:   File "train.py", line 372, in training_step
[rank0]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank0]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank0]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank0]:     return _AllGather.apply(group, tensor)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank0]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank0]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank0]:     work = group.allgather([tensor_list], [tensor])
[rank0]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 63.98 GiB of which 21.43 GiB is free. Of the allocated memory 41.44 GiB is allocated by PyTorch, and 96.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank2]: Traceback (most recent call last):
[rank2]:   File "train.py", line 986, in <module>
[rank2]:     main(args, device, world_size, world_rank, local_rank)
[rank2]:   File "train.py", line 890, in main
[rank2]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank2]:   File "train.py", line 372, in training_step
[rank2]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank2]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 400, in forward
[rank2]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg.py", line 352, in forward_encoder
[rank2]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank2]:     return _AllGather.apply(group, tensor)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank2]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank2]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank2]:     work = group.allgather([tensor_list], [tensor])
[rank2]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 2 has a total capacity of 63.98 GiB of which 21.37 GiB is free. Of the allocated memory 41.44 GiB is allocated by PyTorch, and 96.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:53,418] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:53,418] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:53,418] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:53,418] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:53,418] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:53,418] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:53,418] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:14:53,418] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=32, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 2 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(6559560192) params_per_gpu tensor(861028864)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.2265625
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.203125
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.1875
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.171875
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:23,467] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:23,467] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:23,467] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:15:23,467] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:23,469] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:23,469] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:23,470] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:23,470] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:24,115] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:24,115] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:24,115] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:24,116] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:24,116] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:24,116] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:24,116] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 4, 2048, 4096])
2 torch.Size([2, 32, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:15:24,117] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 861.028864 M TFLOPS: 19.02314132976013

--> cuda max reserved memory = 23.5195
--> max reserved percentage = 36.76 %

--> cuda max memory allocated = 16.5354
--> max allocated percentage = 25.84 %

--> peak active memory = 20.475
--> peak active memory 32.0 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=32, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 23.5195 19.02314132976013 tensor(6559560192)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:37,684] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:37,684] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:37,684] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:37,684] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:37,684] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:37,684] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:37,684] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:15:37,684] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=64, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(6564017152) params_per_gpu tensor(865485824)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.1796875
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.15625
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.140625
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:08,352] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.125
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:08,354] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:16:08,354] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:08,354] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:08,355] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:08,355] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:08,356] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:08,356] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:09,062] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:09,062] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:09,062] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:09,062] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:09,063] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:09,063] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:09,063] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 8, 2048, 4096])
2 torch.Size([2, 64, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:09,063] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 865.485824 M TFLOPS: 19.537036131897924

--> cuda max reserved memory = 28.4316
--> max reserved percentage = 44.44 %

--> cuda max memory allocated = 20.122
--> max allocated percentage = 31.45 %

--> peak active memory = 22.7914
--> peak active memory 35.62 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=64, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 28.4316 19.537036131897924 tensor(6564017152)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:16:22,681] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:16:22,681] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:16:22,681] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:16:22,681] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:16:22,681] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:16:22,681] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:16:22,681] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:16:22,681] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=128, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(6572931072) params_per_gpu tensor(874399744)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.1875
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.171875
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.15625
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:53,976] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:53,976] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:53,977] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:53,978] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:53,978] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.1328125
[2025-03-07 22:16:53,980] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:53,982] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:53,983] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:54,809] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:54,809] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:54,809] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:54,809] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:54,809] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:54,810] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:54,810] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 16, 2048, 4096])
2 torch.Size([2, 128, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:16:54,810] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 874.399744 M TFLOPS: 20.29529589487302

--> cuda max reserved memory = 37.8223
--> max reserved percentage = 59.11 %

--> cuda max memory allocated = 27.2959
--> max allocated percentage = 42.66 %

--> peak active memory = 31.7959
--> peak active memory 49.69 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=128, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 37.8223 20.29529589487302 tensor(6572931072)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:08,483] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:08,483] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:08,483] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:08,483] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:08,483] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:08,483] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:08,483] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:08,483] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=256, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 7 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 0 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 256, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([4096])
total_params before FSDP tensor(6590758912) params_per_gpu tensor(892227584)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-255): 256 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=4096, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.0625
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.0546875
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.0390625
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.015625
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:41,695] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:41,695] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:41,695] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:41,695] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:41,695] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:41,695] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:17:41,696] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:41,696] [INFO] [profiler.py:80:start_profile] Flops profiler started
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:42,641] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:42,642] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:42,642] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:42,642] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:42,642] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:42,642] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:42,642] [INFO] [profiler.py:226:end_profile] Flops profiler finished
torch.Size([2, 32, 2048, 4096])
2 torch.Size([2, 256, 2048, 4096])
3 torch.Size([2, 2048, 4096])
[2025-03-07 22:17:42,643] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 892.227584 M TFLOPS: 21.112204966368797

--> cuda max reserved memory = 54.7734
--> max reserved percentage = 85.6 %

--> cuda max memory allocated = 41.6457
--> max allocated percentage = 65.09 %

--> peak active memory = 50.6457
--> peak active memory 79.15 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=256, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 54.7734 21.112204966368797 tensor(6590758912)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:56,208] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:56,208] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:56,208] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:56,208] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:56,208] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:56,208] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:56,208] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:17:56,208] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=512, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 4 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 512, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([8192, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([8192])
total_params before FSDP tensor(6626414592) params_per_gpu tensor(927883264)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-511): 512 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=8192, bias=True)
    )
  )
)
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
3 torch.Size([2, 2048, 4096])
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.2265625
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank5]: Traceback (most recent call last):
[rank5]:   File "train.py", line 986, in <module>
[rank5]:     main(args, device, world_size, world_rank, local_rank)
[rank5]:   File "train.py", line 890, in main
[rank5]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank5]:   File "train.py", line 372, in training_step
[rank5]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank5]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank5]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank5]:     x = self.aggregate_variables(x)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank5]:     x = x.flatten(0, 1)  # BxL, V, D
[rank5]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 16.00 GiB. GPU 5 has a total capacity of 63.98 GiB of which 11.25 GiB is free. Of the allocated memory 48.24 GiB is allocated by PyTorch, and 3.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank7]: Traceback (most recent call last):
[rank7]:   File "train.py", line 986, in <module>
[rank7]:     main(args, device, world_size, world_rank, local_rank)
[rank7]:   File "train.py", line 890, in main
[rank7]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank7]:   File "train.py", line 372, in training_step
[rank7]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank7]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank7]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank7]:     x = self.aggregate_variables(x)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank7]:     x = x.flatten(0, 1)  # BxL, V, D
[rank7]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 16.00 GiB. GPU 7 has a total capacity of 63.98 GiB of which 11.25 GiB is free. Of the allocated memory 48.24 GiB is allocated by PyTorch, and 3.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]: Traceback (most recent call last):
[rank0]:   File "train.py", line 986, in <module>
[rank0]:     main(args, device, world_size, world_rank, local_rank)
[rank0]:   File "train.py", line 890, in main
[rank0]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank0]:   File "train.py", line 372, in training_step
[rank0]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank0]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank0]:     x = self.aggregate_variables(x)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank0]:     x = x.flatten(0, 1)  # BxL, V, D
[rank0]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 63.98 GiB of which 11.37 GiB is free. Of the allocated memory 48.24 GiB is allocated by PyTorch, and 3.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 986, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 890, in main
[rank3]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank3]:   File "train.py", line 372, in training_step
[rank3]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank3]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank3]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank3]:     x = self.aggregate_variables(x)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank3]:     x = x.flatten(0, 1)  # BxL, V, D
[rank3]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 16.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 11.25 GiB is free. Of the allocated memory 48.24 GiB is allocated by PyTorch, and 3.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
[rank4]: Traceback (most recent call last):
[rank4]:   File "train.py", line 986, in <module>
[rank4]:     main(args, device, world_size, world_rank, local_rank)
[rank4]:   File "train.py", line 890, in main
[rank4]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank4]:   File "train.py", line 372, in training_step
[rank4]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank4]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank4]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank4]:     x = self.aggregate_variables(x)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank4]:     x = x.flatten(0, 1)  # BxL, V, D
[rank4]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 16.00 GiB. GPU 4 has a total capacity of 63.98 GiB of which 11.25 GiB is free. Of the allocated memory 48.24 GiB is allocated by PyTorch, and 3.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank6]: Traceback (most recent call last):
[rank6]:   File "train.py", line 986, in <module>
[rank6]:     main(args, device, world_size, world_rank, local_rank)
[rank6]:   File "train.py", line 890, in main
[rank6]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank6]:   File "train.py", line 372, in training_step
[rank6]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank6]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank6]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank6]:     x = self.aggregate_variables(x)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank6]:     x = x.flatten(0, 1)  # BxL, V, D
[rank6]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 16.00 GiB. GPU 6 has a total capacity of 63.98 GiB of which 11.31 GiB is free. Of the allocated memory 48.24 GiB is allocated by PyTorch, and 3.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 890, in main
[rank1]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank1]:   File "train.py", line 372, in training_step
[rank1]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank1]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank1]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank1]:     x = self.aggregate_variables(x)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank1]:     x = x.flatten(0, 1)  # BxL, V, D
[rank1]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 16.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 11.25 GiB is free. Of the allocated memory 48.24 GiB is allocated by PyTorch, and 3.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
3 torch.Size([2, 2048, 4096])
torch.Size([2, 64, 2048, 4096])
2 torch.Size([2, 512, 2048, 4096])
[rank2]: Traceback (most recent call last):
[rank2]:   File "train.py", line 986, in <module>
[rank2]:     main(args, device, world_size, world_rank, local_rank)
[rank2]:   File "train.py", line 890, in main
[rank2]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank2]:   File "train.py", line 372, in training_step
[rank2]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank2]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank2]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank2]:     x = self.aggregate_variables(x)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank2]:     x = x.flatten(0, 1)  # BxL, V, D
[rank2]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 16.00 GiB. GPU 2 has a total capacity of 63.98 GiB of which 11.31 GiB is free. Of the allocated memory 48.24 GiB is allocated by PyTorch, and 3.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:18:39,397] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:18:39,397] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:18:39,397] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:18:39,397] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:18:39,397] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:18:39,397] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:18:39,397] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:18:39,397] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=768, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 3 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 3 After initialize model
rank 2 After initialize model
rank 3 Before the second dist.barrier()
rank 2 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 3 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 768, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.512.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.512.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.513.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.513.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.514.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.514.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.515.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.515.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.516.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.516.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.517.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.517.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.518.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.518.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.519.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.519.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.520.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.520.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.521.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.521.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.522.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.522.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.523.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.523.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.524.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.524.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.525.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.525.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.526.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.526.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.527.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.527.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.528.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.528.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.529.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.529.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.530.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.530.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.531.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.531.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.532.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.532.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.533.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.533.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.534.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.534.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.535.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.535.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.536.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.536.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.537.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.537.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.538.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.538.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.539.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.539.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.540.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.540.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.541.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.541.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.542.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.542.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.543.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.543.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.544.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.544.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.545.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.545.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.546.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.546.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.547.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.547.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.548.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.548.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.549.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.549.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.550.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.550.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.551.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.551.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.552.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.552.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.553.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.553.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.554.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.554.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.555.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.555.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.556.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.556.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.557.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.557.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.558.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.558.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.559.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.559.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.560.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.560.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.561.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.561.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.562.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.562.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.563.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.563.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.564.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.564.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.565.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.565.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.566.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.566.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.567.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.567.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.568.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.568.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.569.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.569.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.570.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.570.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.571.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.571.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.572.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.572.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.573.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.573.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.574.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.574.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.575.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.575.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.576.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.576.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.577.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.577.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.578.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.578.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.579.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.579.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.580.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.580.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.581.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.581.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.582.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.582.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.583.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.583.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.584.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.584.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.585.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.585.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.586.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.586.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.587.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.587.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.588.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.588.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.589.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.589.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.590.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.590.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.591.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.591.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.592.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.592.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.593.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.593.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.594.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.594.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.595.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.595.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.596.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.596.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.597.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.597.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.598.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.598.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.599.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.599.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.600.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.600.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.601.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.601.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.602.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.602.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.603.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.603.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.604.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.604.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.605.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.605.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.606.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.606.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.607.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.607.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.608.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.608.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.609.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.609.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.610.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.610.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.611.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.611.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.612.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.612.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.613.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.613.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.614.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.614.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.615.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.615.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.616.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.616.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.617.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.617.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.618.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.618.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.619.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.619.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.620.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.620.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.621.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.621.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.622.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.622.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.623.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.623.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.624.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.624.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.625.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.625.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.626.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.626.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.627.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.627.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.628.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.628.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.629.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.629.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.630.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.630.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.631.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.631.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.632.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.632.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.633.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.633.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.634.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.634.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.635.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.635.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.636.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.636.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.637.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.637.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.638.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.638.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.639.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.639.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.640.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.640.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.641.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.641.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.642.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.642.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.643.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.643.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.644.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.644.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.645.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.645.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.646.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.646.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.647.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.647.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.648.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.648.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.649.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.649.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.650.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.650.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.651.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.651.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.652.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.652.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.653.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.653.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.654.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.654.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.655.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.655.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.656.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.656.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.657.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.657.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.658.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.658.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.659.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.659.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.660.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.660.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.661.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.661.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.662.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.662.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.663.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.663.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.664.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.664.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.665.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.665.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.666.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.666.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.667.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.667.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.668.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.668.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.669.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.669.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.670.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.670.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.671.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.671.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.672.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.672.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.673.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.673.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.674.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.674.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.675.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.675.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.676.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.676.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.677.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.677.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.678.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.678.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.679.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.679.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.680.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.680.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.681.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.681.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.682.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.682.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.683.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.683.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.684.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.684.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.685.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.685.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.686.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.686.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.687.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.687.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.688.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.688.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.689.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.689.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.690.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.690.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.691.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.691.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.692.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.692.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.693.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.693.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.694.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.694.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.695.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.695.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.696.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.696.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.697.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.697.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.698.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.698.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.699.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.699.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.700.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.700.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.701.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.701.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.702.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.702.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.703.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.703.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.704.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.704.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.705.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.705.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.706.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.706.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.707.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.707.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.708.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.708.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.709.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.709.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.710.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.710.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.711.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.711.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.712.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.712.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.713.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.713.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.714.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.714.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.715.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.715.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.716.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.716.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.717.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.717.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.718.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.718.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.719.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.719.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.720.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.720.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.721.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.721.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.722.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.722.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.723.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.723.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.724.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.724.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.725.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.725.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.726.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.726.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.727.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.727.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.728.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.728.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.729.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.729.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.730.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.730.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.731.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.731.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.732.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.732.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.733.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.733.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.734.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.734.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.735.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.735.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.736.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.736.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.737.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.737.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.738.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.738.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.739.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.739.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.740.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.740.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.741.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.741.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.742.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.742.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.743.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.743.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.744.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.744.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.745.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.745.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.746.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.746.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.747.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.747.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.748.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.748.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.749.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.749.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.750.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.750.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.751.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.751.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.752.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.752.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.753.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.753.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.754.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.754.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.755.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.755.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.756.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.756.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.757.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.757.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.758.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.758.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.759.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.759.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.760.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.760.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.761.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.761.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.762.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.762.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.763.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.763.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.764.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.764.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.765.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.765.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.766.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.766.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.767.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.767.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([12288, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([12288])
total_params before FSDP tensor(6662070272) params_per_gpu tensor(963538944)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-767): 768 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=12288, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
torch.Size([2, 96, 2048, 4096])
2 torch.Size([2, 768, 2048, 4096])
torch.Size([2, 96, 2048, 4096])
2 torch.Size([2, 768, 2048, 4096])
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 986, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 890, in main
[rank3]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank3]:   File "train.py", line 372, in training_step
[rank3]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank3]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank3]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank3]:     x = self.aggregate_variables(x)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank3]:     x = x.flatten(0, 1)  # BxL, V, D
[rank3]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 7.62 GiB is free. Of the allocated memory 55.15 GiB is allocated by PyTorch, and 67.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank6]: Traceback (most recent call last):
[rank6]:   File "train.py", line 986, in <module>
[rank6]:     main(args, device, world_size, world_rank, local_rank)
[rank6]:   File "train.py", line 890, in main
[rank6]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank6]:   File "train.py", line 372, in training_step
[rank6]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank6]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank6]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank6]:     x = self.aggregate_variables(x)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank6]:     x = x.flatten(0, 1)  # BxL, V, D
[rank6]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 6 has a total capacity of 63.98 GiB of which 7.69 GiB is free. Of the allocated memory 55.15 GiB is allocated by PyTorch, and 67.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 96, 2048, 4096])
2 torch.Size([2, 768, 2048, 4096])
torch.Size([2, 96, 2048, 4096])
2 torch.Size([2, 768, 2048, 4096])
[rank4]: Traceback (most recent call last):
[rank4]:   File "train.py", line 986, in <module>
[rank4]:     main(args, device, world_size, world_rank, local_rank)
[rank4]:   File "train.py", line 890, in main
[rank4]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank4]:   File "train.py", line 372, in training_step
[rank4]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank4]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank4]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank4]:     x = self.aggregate_variables(x)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank4]:     x = x.flatten(0, 1)  # BxL, V, D
[rank4]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 4 has a total capacity of 63.98 GiB of which 7.62 GiB is free. Of the allocated memory 55.15 GiB is allocated by PyTorch, and 67.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 890, in main
[rank1]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank1]:   File "train.py", line 372, in training_step
[rank1]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank1]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank1]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank1]:     x = self.aggregate_variables(x)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank1]:     x = x.flatten(0, 1)  # BxL, V, D
[rank1]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 7.62 GiB is free. Of the allocated memory 55.15 GiB is allocated by PyTorch, and 67.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 96, 2048, 4096])
2 torch.Size([2, 768, 2048, 4096])
[rank5]: Traceback (most recent call last):
[rank5]:   File "train.py", line 986, in <module>
[rank5]:     main(args, device, world_size, world_rank, local_rank)
[rank5]:   File "train.py", line 890, in main
[rank5]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank5]:   File "train.py", line 372, in training_step
[rank5]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank5]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank5]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank5]:     x = self.aggregate_variables(x)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank5]:     x = x.flatten(0, 1)  # BxL, V, D
[rank5]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 5 has a total capacity of 63.98 GiB of which 7.62 GiB is free. Of the allocated memory 55.15 GiB is allocated by PyTorch, and 67.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 96, 2048, 4096])
2 torch.Size([2, 768, 2048, 4096])
torch.Size([2, 96, 2048, 4096])
2 torch.Size([2, 768, 2048, 4096])
torch.Size([2, 96, 2048, 4096])
2 torch.Size([2, 768, 2048, 4096])
[rank7]: Traceback (most recent call last):
[rank7]:   File "train.py", line 986, in <module>
[rank7]:     main(args, device, world_size, world_rank, local_rank)
[rank7]:   File "train.py", line 890, in main
[rank7]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank7]:   File "train.py", line 372, in training_step
[rank7]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank7]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank7]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank7]:     x = self.aggregate_variables(x)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank7]:     x = x.flatten(0, 1)  # BxL, V, D
[rank7]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 7 has a total capacity of 63.98 GiB of which 7.62 GiB is free. Of the allocated memory 55.15 GiB is allocated by PyTorch, and 67.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "train.py", line 986, in <module>
[rank0]:     main(args, device, world_size, world_rank, local_rank)
[rank0]:   File "train.py", line 890, in main
[rank0]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank0]:   File "train.py", line 372, in training_step
[rank0]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank0]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank0]:     x = self.aggregate_variables(x)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank0]:     x = x.flatten(0, 1)  # BxL, V, D
[rank0]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 63.98 GiB of which 7.75 GiB is free. Of the allocated memory 55.15 GiB is allocated by PyTorch, and 69.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank2]: Traceback (most recent call last):
[rank2]:   File "train.py", line 986, in <module>
[rank2]:     main(args, device, world_size, world_rank, local_rank)
[rank2]:   File "train.py", line 890, in main
[rank2]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank2]:   File "train.py", line 372, in training_step
[rank2]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank2]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank2]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 359, in forward_encoder
[rank2]:     x = self.aggregate_variables(x)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 302, in aggregate_variables
[rank2]:     x = x.flatten(0, 1)  # BxL, V, D
[rank2]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 24.00 GiB. GPU 2 has a total capacity of 63.98 GiB of which 7.69 GiB is free. Of the allocated memory 55.15 GiB is allocated by PyTorch, and 67.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:17,015] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:17,015] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:17,015] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:17,015] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:17,015] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:17,015] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:17,015] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:17,015] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_hier_token_noagg_self', batch_size=2, channels=1024, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 0 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 1024, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.512.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.512.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.513.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.513.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.514.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.514.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.515.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.515.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.516.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.516.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.517.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.517.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.518.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.518.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.519.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.519.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.520.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.520.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.521.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.521.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.522.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.522.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.523.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.523.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.524.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.524.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.525.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.525.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.526.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.526.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.527.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.527.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.528.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.528.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.529.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.529.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.530.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.530.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.531.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.531.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.532.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.532.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.533.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.533.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.534.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.534.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.535.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.535.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.536.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.536.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.537.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.537.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.538.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.538.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.539.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.539.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.540.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.540.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.541.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.541.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.542.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.542.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.543.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.543.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.544.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.544.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.545.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.545.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.546.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.546.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.547.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.547.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.548.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.548.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.549.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.549.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.550.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.550.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.551.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.551.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.552.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.552.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.553.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.553.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.554.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.554.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.555.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.555.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.556.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.556.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.557.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.557.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.558.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.558.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.559.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.559.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.560.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.560.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.561.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.561.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.562.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.562.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.563.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.563.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.564.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.564.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.565.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.565.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.566.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.566.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.567.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.567.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.568.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.568.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.569.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.569.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.570.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.570.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.571.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.571.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.572.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.572.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.573.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.573.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.574.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.574.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.575.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.575.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.576.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.576.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.577.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.577.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.578.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.578.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.579.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.579.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.580.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.580.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.581.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.581.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.582.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.582.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.583.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.583.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.584.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.584.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.585.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.585.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.586.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.586.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.587.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.587.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.588.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.588.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.589.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.589.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.590.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.590.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.591.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.591.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.592.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.592.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.593.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.593.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.594.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.594.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.595.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.595.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.596.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.596.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.597.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.597.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.598.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.598.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.599.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.599.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.600.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.600.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.601.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.601.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.602.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.602.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.603.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.603.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.604.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.604.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.605.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.605.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.606.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.606.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.607.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.607.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.608.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.608.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.609.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.609.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.610.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.610.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.611.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.611.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.612.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.612.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.613.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.613.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.614.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.614.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.615.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.615.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.616.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.616.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.617.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.617.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.618.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.618.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.619.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.619.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.620.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.620.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.621.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.621.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.622.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.622.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.623.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.623.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.624.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.624.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.625.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.625.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.626.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.626.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.627.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.627.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.628.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.628.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.629.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.629.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.630.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.630.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.631.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.631.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.632.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.632.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.633.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.633.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.634.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.634.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.635.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.635.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.636.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.636.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.637.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.637.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.638.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.638.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.639.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.639.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.640.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.640.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.641.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.641.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.642.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.642.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.643.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.643.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.644.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.644.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.645.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.645.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.646.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.646.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.647.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.647.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.648.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.648.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.649.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.649.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.650.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.650.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.651.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.651.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.652.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.652.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.653.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.653.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.654.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.654.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.655.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.655.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.656.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.656.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.657.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.657.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.658.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.658.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.659.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.659.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.660.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.660.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.661.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.661.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.662.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.662.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.663.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.663.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.664.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.664.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.665.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.665.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.666.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.666.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.667.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.667.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.668.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.668.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.669.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.669.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.670.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.670.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.671.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.671.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.672.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.672.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.673.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.673.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.674.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.674.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.675.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.675.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.676.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.676.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.677.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.677.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.678.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.678.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.679.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.679.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.680.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.680.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.681.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.681.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.682.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.682.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.683.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.683.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.684.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.684.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.685.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.685.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.686.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.686.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.687.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.687.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.688.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.688.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.689.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.689.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.690.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.690.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.691.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.691.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.692.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.692.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.693.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.693.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.694.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.694.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.695.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.695.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.696.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.696.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.697.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.697.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.698.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.698.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.699.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.699.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.700.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.700.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.701.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.701.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.702.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.702.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.703.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.703.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.704.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.704.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.705.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.705.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.706.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.706.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.707.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.707.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.708.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.708.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.709.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.709.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.710.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.710.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.711.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.711.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.712.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.712.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.713.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.713.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.714.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.714.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.715.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.715.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.716.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.716.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.717.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.717.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.718.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.718.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.719.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.719.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.720.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.720.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.721.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.721.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.722.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.722.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.723.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.723.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.724.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.724.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.725.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.725.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.726.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.726.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.727.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.727.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.728.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.728.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.729.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.729.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.730.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.730.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.731.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.731.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.732.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.732.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.733.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.733.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.734.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.734.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.735.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.735.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.736.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.736.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.737.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.737.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.738.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.738.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.739.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.739.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.740.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.740.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.741.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.741.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.742.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.742.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.743.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.743.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.744.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.744.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.745.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.745.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.746.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.746.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.747.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.747.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.748.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.748.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.749.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.749.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.750.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.750.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.751.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.751.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.752.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.752.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.753.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.753.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.754.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.754.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.755.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.755.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.756.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.756.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.757.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.757.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.758.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.758.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.759.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.759.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.760.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.760.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.761.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.761.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.762.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.762.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.763.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.763.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.764.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.764.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.765.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.765.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.766.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.766.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.767.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.767.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.768.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.768.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.769.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.769.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.770.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.770.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.771.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.771.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.772.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.772.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.773.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.773.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.774.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.774.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.775.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.775.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.776.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.776.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.777.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.777.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.778.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.778.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.779.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.779.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.780.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.780.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.781.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.781.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.782.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.782.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.783.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.783.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.784.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.784.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.785.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.785.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.786.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.786.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.787.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.787.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.788.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.788.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.789.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.789.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.790.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.790.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.791.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.791.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.792.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.792.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.793.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.793.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.794.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.794.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.795.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.795.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.796.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.796.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.797.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.797.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.798.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.798.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.799.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.799.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.800.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.800.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.801.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.801.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.802.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.802.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.803.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.803.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.804.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.804.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.805.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.805.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.806.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.806.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.807.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.807.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.808.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.808.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.809.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.809.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.810.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.810.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.811.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.811.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.812.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.812.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.813.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.813.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.814.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.814.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.815.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.815.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.816.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.816.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.817.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.817.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.818.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.818.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.819.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.819.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.820.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.820.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.821.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.821.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.822.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.822.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.823.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.823.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.824.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.824.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.825.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.825.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.826.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.826.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.827.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.827.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.828.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.828.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.829.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.829.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.830.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.830.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.831.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.831.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.832.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.832.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.833.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.833.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.834.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.834.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.835.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.835.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.836.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.836.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.837.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.837.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.838.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.838.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.839.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.839.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.840.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.840.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.841.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.841.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.842.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.842.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.843.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.843.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.844.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.844.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.845.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.845.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.846.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.846.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.847.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.847.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.848.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.848.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.849.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.849.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.850.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.850.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.851.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.851.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.852.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.852.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.853.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.853.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.854.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.854.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.855.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.855.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.856.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.856.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.857.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.857.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.858.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.858.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.859.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.859.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.860.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.860.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.861.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.861.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.862.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.862.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.863.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.863.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.864.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.864.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.865.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.865.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.866.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.866.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.867.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.867.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.868.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.868.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.869.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.869.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.870.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.870.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.871.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.871.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.872.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.872.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.873.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.873.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.874.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.874.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.875.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.875.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.876.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.876.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.877.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.877.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.878.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.878.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.879.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.879.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.880.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.880.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.881.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.881.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.882.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.882.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.883.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.883.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.884.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.884.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.885.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.885.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.886.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.886.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.887.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.887.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.888.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.888.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.889.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.889.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.890.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.890.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.891.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.891.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.892.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.892.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.893.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.893.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.894.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.894.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.895.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.895.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.896.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.896.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.897.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.897.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.898.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.898.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.899.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.899.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.900.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.900.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.901.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.901.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.902.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.902.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.903.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.903.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.904.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.904.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.905.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.905.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.906.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.906.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.907.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.907.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.908.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.908.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.909.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.909.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.910.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.910.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.911.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.911.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.912.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.912.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.913.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.913.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.914.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.914.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.915.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.915.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.916.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.916.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.917.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.917.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.918.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.918.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.919.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.919.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.920.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.920.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.921.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.921.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.922.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.922.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.923.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.923.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.924.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.924.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.925.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.925.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.926.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.926.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.927.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.927.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.928.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.928.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.929.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.929.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.930.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.930.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.931.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.931.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.932.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.932.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.933.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.933.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.934.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.934.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.935.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.935.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.936.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.936.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.937.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.937.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.938.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.938.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.939.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.939.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.940.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.940.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.941.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.941.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.942.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.942.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.943.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.943.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.944.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.944.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.945.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.945.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.946.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.946.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.947.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.947.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.948.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.948.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.949.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.949.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.950.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.950.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.951.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.951.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.952.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.952.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.953.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.953.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.954.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.954.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.955.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.955.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.956.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.956.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.957.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.957.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.958.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.958.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.959.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.959.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.960.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.960.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.961.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.961.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.962.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.962.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.963.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.963.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.964.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.964.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.965.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.965.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.966.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.966.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.967.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.967.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.968.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.968.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.969.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.969.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.970.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.970.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.971.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.971.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.972.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.972.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.973.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.973.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.974.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.974.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.975.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.975.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.976.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.976.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.977.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.977.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.978.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.978.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.979.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.979.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.980.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.980.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.981.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.981.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.982.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.982.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.983.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.983.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.984.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.984.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.985.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.985.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.986.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.986.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.987.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.987.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.988.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.988.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.989.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.989.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.990.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.990.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.991.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.991.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.992.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.992.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.993.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.993.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.994.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.994.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.995.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.995.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.996.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.996.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.997.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.997.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.998.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.998.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.999.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.999.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1000.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1000.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1001.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1001.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1002.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1002.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1003.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1003.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1004.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1004.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1005.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1005.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1006.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1006.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1007.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1007.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1008.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1008.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1009.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1009.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1010.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1010.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1011.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1011.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1012.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1012.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1013.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1013.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1014.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1014.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1015.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1015.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1016.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1016.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1017.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1017.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1018.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1018.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1019.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1019.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1020.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1020.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1021.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1021.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1022.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1022.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1023.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1023.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([16384, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([16384])
total_params before FSDP tensor(6697725952) params_per_gpu tensor(999194624)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-1023): 1024 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=16384, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
torch.Size([2, 128, 2048, 4096])
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank1]: Traceback (most recent call last):
[rank1]:   File "train.py", line 986, in <module>
[rank1]:     main(args, device, world_size, world_rank, local_rank)
[rank1]:   File "train.py", line 890, in main
[rank1]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank1]:   File "train.py", line 372, in training_step
[rank1]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank1]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank1]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 354, in forward_encoder
[rank1]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank1]:     return _AllGather.apply(group, tensor)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank1]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank1]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank1]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank1]:     work = group.allgather([tensor_list], [tensor])
[rank1]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 1 has a total capacity of 63.98 GiB of which 18.24 GiB is free. Of the allocated memory 44.44 GiB is allocated by PyTorch, and 156.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
torch.Size([2, 128, 2048, 4096])
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
[rank7]: Traceback (most recent call last):
[rank7]:   File "train.py", line 986, in <module>
[rank7]:     main(args, device, world_size, world_rank, local_rank)
[rank7]:   File "train.py", line 890, in main
[rank7]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank7]:   File "train.py", line 372, in training_step
[rank7]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank7]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank7]:     return self._call_impl(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank7]:     return forward_call(*args, **kwargs)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank7]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 354, in forward_encoder
[rank7]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank7]:     return _AllGather.apply(group, tensor)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank7]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank7]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank7]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank7]:     return func(*args, **kwargs)
[rank7]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank7]:     work = group.allgather([tensor_list], [tensor])
[rank7]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 7 has a total capacity of 63.98 GiB of which 18.24 GiB is free. Of the allocated memory 44.44 GiB is allocated by PyTorch, and 156.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 128, 2048, 4096])
[rank5]: Traceback (most recent call last):
[rank5]:   File "train.py", line 986, in <module>
[rank5]:     main(args, device, world_size, world_rank, local_rank)
[rank5]:   File "train.py", line 890, in main
[rank5]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank5]:   File "train.py", line 372, in training_step
[rank5]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank5]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank5]:     return self._call_impl(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank5]:     return forward_call(*args, **kwargs)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank5]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 354, in forward_encoder
[rank5]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank5]:     return _AllGather.apply(group, tensor)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank5]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank5]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank5]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank5]:     return func(*args, **kwargs)
[rank5]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank5]:     work = group.allgather([tensor_list], [tensor])
[rank5]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 5 has a total capacity of 63.98 GiB of which 18.24 GiB is free. Of the allocated memory 44.44 GiB is allocated by PyTorch, and 156.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 128, 2048, 4096])
[rank4]: Traceback (most recent call last):
[rank4]:   File "train.py", line 986, in <module>
[rank4]:     main(args, device, world_size, world_rank, local_rank)
[rank4]:   File "train.py", line 890, in main
[rank4]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank4]:   File "train.py", line 372, in training_step
[rank4]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank4]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank4]:     return self._call_impl(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank4]:     return forward_call(*args, **kwargs)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank4]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 354, in forward_encoder
[rank4]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank4]:     return _AllGather.apply(group, tensor)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank4]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank4]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank4]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank4]:     return func(*args, **kwargs)
[rank4]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank4]:     work = group.allgather([tensor_list], [tensor])
[rank4]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 4 has a total capacity of 63.98 GiB of which 18.24 GiB is free. Of the allocated memory 44.44 GiB is allocated by PyTorch, and 156.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 128, 2048, 4096])
[rank2]: Traceback (most recent call last):
[rank2]:   File "train.py", line 986, in <module>
[rank2]:     main(args, device, world_size, world_rank, local_rank)
[rank2]:   File "train.py", line 890, in main
[rank2]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank2]:   File "train.py", line 372, in training_step
[rank2]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank2]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank2]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 354, in forward_encoder
[rank2]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank2]:     return _AllGather.apply(group, tensor)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank2]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank2]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank2]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank2]:     work = group.allgather([tensor_list], [tensor])
[rank2]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 2 has a total capacity of 63.98 GiB of which 18.31 GiB is free. Of the allocated memory 44.44 GiB is allocated by PyTorch, and 156.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.Size([2, 128, 2048, 4096])
[rank0]: Traceback (most recent call last):
[rank0]:   File "train.py", line 986, in <module>
[rank0]:     main(args, device, world_size, world_rank, local_rank)
[rank0]:   File "train.py", line 890, in main
[rank0]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank0]:   File "train.py", line 372, in training_step
[rank0]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank0]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 354, in forward_encoder
[rank0]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank0]:     return _AllGather.apply(group, tensor)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank0]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank0]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank0]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank0]:     work = group.allgather([tensor_list], [tensor])
[rank0]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 63.98 GiB of which 18.37 GiB is free. Of the allocated memory 44.44 GiB is allocated by PyTorch, and 158.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
torch.Size([2, 128, 2048, 4096])
torch.Size([2, 128, 2048, 4096])
[rank6]: Traceback (most recent call last):
[rank6]:   File "train.py", line 986, in <module>
[rank6]:     main(args, device, world_size, world_rank, local_rank)
[rank6]:   File "train.py", line 890, in main
[rank6]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank6]:   File "train.py", line 372, in training_step
[rank6]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank6]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank6]:     return self._call_impl(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank6]:     return forward_call(*args, **kwargs)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank6]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 354, in forward_encoder
[rank6]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank6]:     return _AllGather.apply(group, tensor)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank6]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank6]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank6]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank6]:     return func(*args, **kwargs)
[rank6]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank6]:     work = group.allgather([tensor_list], [tensor])
[rank6]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 6 has a total capacity of 63.98 GiB of which 18.31 GiB is free. Of the allocated memory 44.44 GiB is allocated by PyTorch, and 156.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank3]: Traceback (most recent call last):
[rank3]:   File "train.py", line 986, in <module>
[rank3]:     main(args, device, world_size, world_rank, local_rank)
[rank3]:   File "train.py", line 890, in main
[rank3]:     loss = training_step(batch_syn, device, batch_idx,model,lat)
[rank3]:   File "train.py", line 372, in training_step
[rank3]:     loss_dict, _ = net.forward(x, y, lead_times, variables, out_variables, [lat_weighted_mse], lat=lat)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 853, in forward
[rank3]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 407, in forward
[rank3]:     out_transformers = self.forward_encoder(x, lead_times, variables)  # B, V~ * L, D
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/arch_hier_token_noagg_self.py", line 354, in forward_encoder
[rank3]:     gathered_tensors = mod_all_gather(x, self.tensor_par_group)
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 247, in all_gather
[rank3]:     return _AllGather.apply(group, tensor)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/function.py", line 562, in apply
[rank3]:     return super().apply(*args, **kwargs)  # type: ignore[misc]
[rank3]:   File "/lustre/orion/stf218/scratch/atsaris/code/dev_climax_gb/climax/dist_functions.py", line 576, in forward
[rank3]:     dist.all_gather(out_tensor_list, tensor, group=group)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/c10d_logger.py", line 75, in wrapper
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 2745, in all_gather
[rank3]:     work = group.allgather([tensor_list], [tensor])
[rank3]: torch.cuda.OutOfMemoryError: HIP out of memory. Tried to allocate 32.00 GiB. GPU 3 has a total capacity of 63.98 GiB of which 18.24 GiB is free. Of the allocated memory 44.44 GiB is allocated by PyTorch, and 156.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:54,279] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:54,279] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:54,279] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:54,279] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:54,279] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:54,279] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:54,279] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:19:54,279] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_linear', batch_size=2, channels=32, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 4 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 2 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 0 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 32, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  var_query_per_rank  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_linear_per_rank.weight  requires_gradient  True size torch.Size([1, 4])
parameter name  var_linear_per_rank.bias  requires_gradient  True size torch.Size([1])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([512])
total_params before FSDP tensor(6559564293) params_per_gpu tensor(861032965)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-31): 32 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (var_linear_per_rank): Linear(in_features=4, out_features=1, bias=True)
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=512, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.03125
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.0234375
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.0078125
[2025-03-07 22:20:23,972] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:20:23,972] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  0.984375
[2025-03-07 22:20:23,973] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:20:23,973] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:20:23,973] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:20:23,974] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:20:23,975] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:20:23,975] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:20:24,586] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:20:24,586] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:20:24,586] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:20:24,587] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:20:24,587] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:20:24,587] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:20:24,587] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:20:24,587] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 861.032965 M TFLOPS: 18.122474106491218

--> cuda max reserved memory = 20.752
--> max reserved percentage = 32.43 %

--> cuda max memory allocated = 16.0406
--> max allocated percentage = 25.07 %

--> peak active memory = 19.1392
--> peak active memory 29.91 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_linear', batch_size=2, channels=32, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 20.752 18.122474106491218 tensor(6559564293)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:20:38,238] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:20:38,238] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:20:38,238] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:20:38,238] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:20:38,238] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:20:38,238] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:20:38,238] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:20:38,238] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_linear', batch_size=2, channels=64, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 3 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 64, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  var_query_per_rank  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_linear_per_rank.weight  requires_gradient  True size torch.Size([1, 8])
parameter name  var_linear_per_rank.bias  requires_gradient  True size torch.Size([1])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([1024])
total_params before FSDP tensor(6564021257) params_per_gpu tensor(865489929)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-63): 64 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (var_linear_per_rank): Linear(in_features=8, out_features=1, bias=True)
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=1024, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.3359375
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.3125
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.3046875
[2025-03-07 22:21:07,641] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.2734375
[2025-03-07 22:21:07,642] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:07,642] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:07,642] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:07,643] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:07,643] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:07,643] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:07,643] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:08,278] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:08,277] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:08,277] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:08,278] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:08,278] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:08,278] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:08,278] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:08,279] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 865.489929 M TFLOPS: 17.89653926335276

--> cuda max reserved memory = 20.9297
--> max reserved percentage = 32.71 %

--> cuda max memory allocated = 16.121
--> max allocated percentage = 25.2 %

--> peak active memory = 19.3615
--> peak active memory 30.26 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_linear', batch_size=2, channels=64, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 20.9297 17.89653926335276 tensor(6564021257)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:21:21,854] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:21:21,854] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:21:21,854] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:21:21,854] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:21:21,854] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:21:21,854] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:21:21,854] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:21:21,855] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_linear', batch_size=2, channels=128, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 1 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 6 After initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 128, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  var_query_per_rank  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_linear_per_rank.weight  requires_gradient  True size torch.Size([1, 16])
parameter name  var_linear_per_rank.bias  requires_gradient  True size torch.Size([1])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([2048])
total_params before FSDP tensor(6572935185) params_per_gpu tensor(874403857)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-127): 128 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (var_linear_per_rank): Linear(in_features=16, out_features=1, bias=True)
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=2048, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.1796875
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.171875
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.1484375
[2025-03-07 22:21:51,907] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:51,907] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.1484375
[2025-03-07 22:21:51,908] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:51,909] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:51,909] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:51,910] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:51,910] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:51,910] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:21:52,565] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:52,565] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:52,565] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:52,565] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:52,565] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:52,565] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:52,565] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:21:52,565] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 874.403857 M TFLOPS: 17.496442429422366

--> cuda max reserved memory = 21.627
--> max reserved percentage = 33.8 %

--> cuda max memory allocated = 16.2871
--> max allocated percentage = 25.45 %

--> peak active memory = 19.844
--> peak active memory 31.01 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_linear', batch_size=2, channels=128, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 21.627 17.496442429422366 tensor(6572935185)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:06,173] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:06,173] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:06,173] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:06,173] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:06,173] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:06,173] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:06,173] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:06,173] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_linear', batch_size=2, channels=256, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
rank 6 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 3 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 5 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 256, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  var_query_per_rank  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_linear_per_rank.weight  requires_gradient  True size torch.Size([1, 32])
parameter name  var_linear_per_rank.bias  requires_gradient  True size torch.Size([1])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([4096])
total_params before FSDP tensor(6590763041) params_per_gpu tensor(892231713)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-255): 256 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (var_linear_per_rank): Linear(in_features=32, out_features=1, bias=True)
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=4096, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.203125
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.1953125
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.171875
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.1640625
[2025-03-07 22:22:36,719] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:22:36,720] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:22:36,721] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:22:36,721] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:22:36,722] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:22:36,722] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:22:36,722] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:22:36,723] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:22:37,344] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:22:37,344] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:22:37,344] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:22:37,344] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:22:37,344] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:22:37,344] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:22:37,344] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:22:37,345] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 892.231713 M TFLOPS: 16.238728907990055

--> cuda max reserved memory = 24.0703
--> max reserved percentage = 37.62 %

--> cuda max memory allocated = 17.2865
--> max allocated percentage = 27.02 %

--> peak active memory = 21.1077
--> peak active memory 32.99 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_linear', batch_size=2, channels=256, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 24.0703 16.238728907990055 tensor(6590763041)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:50,984] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:50,984] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:50,984] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:50,984] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:50,984] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:50,984] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:50,984] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:22:50,984] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_linear', batch_size=2, channels=512, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 1 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 512, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  var_query_per_rank  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_linear_per_rank.weight  requires_gradient  True size torch.Size([1, 64])
parameter name  var_linear_per_rank.bias  requires_gradient  True size torch.Size([1])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([8192, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([8192])
total_params before FSDP tensor(6626418753) params_per_gpu tensor(927887425)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-511): 512 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (var_linear_per_rank): Linear(in_features=64, out_features=1, bias=True)
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=8192, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.4140625
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.3984375
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.3828125
[2025-03-07 22:23:23,300] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.359375
[2025-03-07 22:23:23,302] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:23:23,302] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:23:23,303] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:23:23,304] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:23:23,305] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:23:23,305] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:23:23,306] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:23:24,150] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:23:24,150] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:23:24,150] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:23:24,150] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:23:24,151] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:23:24,151] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:23:24,151] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:23:24,151] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 927.887425 M TFLOPS: 13.760465102017193

--> cuda max reserved memory = 27.8262
--> max reserved percentage = 43.49 %

--> cuda max memory allocated = 20.2749
--> max allocated percentage = 31.69 %

--> peak active memory = 23.6985
--> peak active memory 37.04 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_linear', batch_size=2, channels=512, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 27.8262 13.760465102017193 tensor(6626418753)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:23:37,791] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:23:37,791] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:23:37,791] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:23:37,791] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:23:37,791] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:23:37,791] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:23:37,791] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:23:37,791] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_linear', batch_size=2, channels=768, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 1 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
rank 3 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 768, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  var_query_per_rank  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.512.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.512.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.513.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.513.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.514.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.514.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.515.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.515.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.516.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.516.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.517.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.517.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.518.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.518.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.519.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.519.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.520.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.520.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.521.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.521.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.522.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.522.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.523.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.523.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.524.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.524.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.525.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.525.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.526.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.526.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.527.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.527.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.528.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.528.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.529.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.529.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.530.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.530.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.531.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.531.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.532.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.532.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.533.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.533.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.534.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.534.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.535.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.535.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.536.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.536.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.537.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.537.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.538.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.538.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.539.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.539.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.540.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.540.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.541.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.541.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.542.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.542.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.543.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.543.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.544.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.544.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.545.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.545.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.546.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.546.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.547.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.547.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.548.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.548.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.549.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.549.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.550.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.550.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.551.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.551.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.552.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.552.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.553.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.553.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.554.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.554.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.555.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.555.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.556.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.556.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.557.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.557.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.558.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.558.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.559.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.559.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.560.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.560.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.561.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.561.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.562.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.562.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.563.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.563.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.564.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.564.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.565.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.565.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.566.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.566.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.567.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.567.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.568.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.568.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.569.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.569.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.570.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.570.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.571.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.571.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.572.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.572.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.573.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.573.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.574.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.574.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.575.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.575.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.576.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.576.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.577.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.577.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.578.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.578.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.579.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.579.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.580.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.580.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.581.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.581.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.582.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.582.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.583.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.583.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.584.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.584.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.585.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.585.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.586.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.586.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.587.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.587.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.588.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.588.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.589.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.589.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.590.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.590.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.591.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.591.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.592.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.592.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.593.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.593.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.594.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.594.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.595.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.595.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.596.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.596.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.597.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.597.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.598.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.598.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.599.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.599.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.600.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.600.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.601.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.601.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.602.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.602.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.603.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.603.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.604.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.604.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.605.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.605.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.606.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.606.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.607.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.607.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.608.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.608.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.609.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.609.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.610.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.610.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.611.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.611.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.612.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.612.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.613.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.613.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.614.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.614.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.615.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.615.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.616.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.616.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.617.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.617.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.618.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.618.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.619.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.619.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.620.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.620.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.621.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.621.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.622.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.622.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.623.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.623.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.624.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.624.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.625.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.625.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.626.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.626.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.627.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.627.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.628.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.628.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.629.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.629.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.630.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.630.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.631.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.631.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.632.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.632.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.633.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.633.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.634.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.634.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.635.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.635.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.636.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.636.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.637.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.637.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.638.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.638.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.639.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.639.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.640.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.640.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.641.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.641.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.642.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.642.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.643.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.643.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.644.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.644.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.645.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.645.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.646.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.646.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.647.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.647.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.648.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.648.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.649.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.649.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.650.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.650.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.651.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.651.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.652.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.652.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.653.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.653.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.654.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.654.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.655.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.655.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.656.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.656.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.657.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.657.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.658.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.658.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.659.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.659.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.660.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.660.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.661.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.661.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.662.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.662.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.663.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.663.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.664.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.664.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.665.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.665.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.666.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.666.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.667.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.667.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.668.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.668.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.669.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.669.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.670.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.670.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.671.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.671.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.672.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.672.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.673.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.673.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.674.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.674.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.675.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.675.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.676.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.676.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.677.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.677.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.678.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.678.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.679.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.679.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.680.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.680.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.681.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.681.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.682.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.682.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.683.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.683.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.684.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.684.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.685.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.685.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.686.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.686.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.687.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.687.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.688.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.688.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.689.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.689.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.690.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.690.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.691.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.691.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.692.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.692.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.693.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.693.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.694.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.694.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.695.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.695.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.696.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.696.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.697.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.697.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.698.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.698.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.699.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.699.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.700.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.700.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.701.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.701.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.702.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.702.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.703.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.703.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.704.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.704.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.705.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.705.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.706.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.706.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.707.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.707.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.708.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.708.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.709.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.709.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.710.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.710.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.711.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.711.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.712.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.712.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.713.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.713.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.714.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.714.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.715.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.715.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.716.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.716.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.717.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.717.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.718.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.718.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.719.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.719.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.720.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.720.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.721.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.721.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.722.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.722.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.723.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.723.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.724.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.724.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.725.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.725.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.726.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.726.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.727.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.727.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.728.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.728.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.729.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.729.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.730.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.730.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.731.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.731.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.732.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.732.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.733.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.733.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.734.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.734.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.735.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.735.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.736.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.736.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.737.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.737.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.738.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.738.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.739.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.739.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.740.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.740.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.741.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.741.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.742.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.742.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.743.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.743.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.744.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.744.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.745.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.745.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.746.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.746.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.747.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.747.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.748.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.748.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.749.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.749.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.750.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.750.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.751.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.751.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.752.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.752.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.753.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.753.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.754.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.754.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.755.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.755.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.756.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.756.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.757.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.757.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.758.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.758.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.759.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.759.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.760.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.760.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.761.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.761.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.762.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.762.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.763.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.763.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.764.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.764.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.765.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.765.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.766.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.766.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.767.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.767.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_linear_per_rank.weight  requires_gradient  True size torch.Size([1, 96])
parameter name  var_linear_per_rank.bias  requires_gradient  True size torch.Size([1])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([12288, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([12288])
total_params before FSDP tensor(6662074465) params_per_gpu tensor(963543137)
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-767): 768 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (var_linear_per_rank): Linear(in_features=96, out_features=1, bias=True)
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=12288, bias=True)
    )
  )
)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.2421875
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.21875
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.1953125
[2025-03-07 22:24:10,749] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:24:10,750] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.1796875
[2025-03-07 22:24:10,752] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:24:10,752] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:24:10,752] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:24:10,753] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:24:10,755] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:24:10,756] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:24:11,962] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:24:11,962] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:24:11,963] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:24:11,963] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:24:11,963] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:24:11,963] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:24:11,964] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:24:11,966] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
MUST: Model 963.543137 M TFLOPS: 11.909027774044425

--> cuda max reserved memory = 31.1484
--> max reserved percentage = 48.68 %

--> cuda max memory allocated = 23.9667
--> max allocated percentage = 37.46 %

--> peak active memory = 26.3902
--> peak active memory 41.24 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_linear', batch_size=2, channels=768, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 31.1484 11.909027774044425 tensor(6662074465)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:24:25,629] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:24:25,629] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:24:25,629] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:24:25,629] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:24:25,629] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:24:25,629] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:24:25,629] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--> total memory per gpu (GB) = 63.9844
[2025-03-07 22:24:25,629] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
HERE0 Namespace(arch='orbit_linear', batch_size=2, channels=1024, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml')
[W socket.cpp:464] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
[W socket.cpp:697] [c10d] The client socket cannot be initialized to connect to [frontier08166.frontier.olcf.ornl.gov]:29500 (errno: 97 - Address family not supported by protocol).
Using dist.init_process_group. world_size  8
config_path  configs/ERA5-100million-91variables.yaml
{'seed_everything': 42, 'trainer': {'checkpoint_path': '/lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints', 'checkpoint_filename': 'multi_last', 'resume_from_checkpoint': False}, 'parallelism': {'cpu_offloading': False}, 'model': {'lr': 2e-05, 'beta_1': 0.9, 'beta_2': 0.95, 'weight_decay': '1e-5', 'warmup_steps': 1000, 'max_steps': 20000, 'warmup_start_lr': '1e-8', 'eta_min': '1e-8', 'net': {'class_path': 'climax.arch.ClimaX', 'init_args': {'default_vars': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000'], 'patch_size': 4, 'decoder_depth': 2, 'mlp_ratio': 4, 'drop_path': 0.1, 'drop_rate': 0.1, 'aggregated_variables': 1}}}, 'data': {'dict_root_dirs': {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'}, 'dict_start_idx': {'mpi-esm': 0}, 'dict_end_idx': {'mpi-esm': 1}, 'dict_in_variables': {'mpi-esm': ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']}, 'dict_out_variables': {'mpi-esm': ['geopotential_500', 'temperature_850', '2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind']}, 'dict_max_predict_ranges': {'mpi-esm': 24}, 'dict_random_lead_time': {'mpi-esm': False}, 'dict_hrs_each_step': {'mpi-esm': 1}, 'dict_buffer_sizes': {'mpi-esm': 1}, 'num_workers': 1, 'pin_memory': False}}
rank 3 Before initialize parallelism groups
rank 4 Before initialize parallelism groups
rank 5 Before initialize parallelism groups
rank 1 Before initialize parallelism groups
rank 6 Before initialize parallelism groups
rank 7 Before initialize parallelism groups
rank 2 Before initialize parallelism groups
max_epochs 1 data_par_size 1 fsdp_size 1 simple_ddp_size 1 tensor_par_size 8 seq_par_size 1 cpu_offloading False
lr  2e-05 beta_1  0.9 beta_2 0.95 weight_decay 1e-05 class_path climax.arch.ClimaX default_vars ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'geopotential_50', 'geopotential_70', 'geopotential_100', 'geopotential_150', 'geopotential_200', 'geopotential_250', 'geopotential_300', 'geopotential_400', 'geopotential_500', 'geopotential_600', 'geopotential_700', 'geopotential_850', 'geopotential_925', 'geopotential_1000', 'specific_humidity_10', 'specific_humidity_20', 'specific_humidity_30', 'specific_humidity_50', 'specific_humidity_70', 'specific_humidity_100', 'specific_humidity_150', 'specific_humidity_200', 'specific_humidity_250', 'specific_humidity_300', 'specific_humidity_400', 'specific_humidity_500', 'specific_humidity_600', 'specific_humidity_700', 'specific_humidity_850', 'specific_humidity_925', 'specific_humidity_1000', 'temperature_10', 'temperature_20', 'temperature_30', 'temperature_50', 'temperature_70', 'temperature_100', 'temperature_150', 'temperature_200', 'temperature_250', 'temperature_300', 'temperature_400', 'temperature_500', 'temperature_600', 'temperature_700', 'temperature_850', 'temperature_925', 'temperature_1000', 'u_component_of_wind_10', 'u_component_of_wind_20', 'u_component_of_wind_30', 'u_component_of_wind_50', 'u_component_of_wind_70', 'u_component_of_wind_100', 'u_component_of_wind_150', 'u_component_of_wind_200', 'u_component_of_wind_250', 'u_component_of_wind_300', 'u_component_of_wind_400', 'u_component_of_wind_500', 'u_component_of_wind_600', 'u_component_of_wind_700', 'u_component_of_wind_850', 'u_component_of_wind_925', 'u_component_of_wind_1000', 'v_component_of_wind_10', 'v_component_of_wind_20', 'v_component_of_wind_30', 'v_component_of_wind_50', 'v_component_of_wind_70', 'v_component_of_wind_100', 'v_component_of_wind_150', 'v_component_of_wind_200', 'v_component_of_wind_250', 'v_component_of_wind_300', 'v_component_of_wind_400', 'v_component_of_wind_500', 'v_component_of_wind_600', 'v_component_of_wind_700', 'v_component_of_wind_850', 'v_component_of_wind_925', 'v_component_of_wind_1000']
img_size_x 128 img_size_y 256 patch_size 4 emb_dim 4096 depth 32 decoder_depth 2 num_heads 32 mlp_ratio 4 drop_path 0.1 drop_rate 0.1 aggregated_variables 1
dict_root_dirs {'mpi-esm': '/lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0'} dict_start_idx {'mpi-esm': 0} dict_end_idx {'mpi-esm': 1} batch_size 2 num_workers 1
warmup_steps 1000 max_steps 20000 warmup_start_lr 1e-08 eta_min 1e-08
checkpoint_path /lustre/orion/stf218/world-shared/atsaris/tmp/tmp_checkpoints checkpoint_filename multi_last resume_from_checkpoint False
rank 0 Before initialize parallelism groups
rank 2 After initialize parallelism groups
rank 4 After initialize parallelism groups
rank 5 After initialize parallelism groups
rank 6 After initialize parallelism groups
rank 0 After initialize parallelism groups
rank 1 After initialize parallelism groups
rank 3 After initialize parallelism groups
rank 7 After initialize parallelism groups
rank 1 After initialize model
rank 1 Before the second dist.barrier()
rank 0 After initialize model
rank 0 Before the second dist.barrier()
rank 2 After initialize model
rank 2 Before the second dist.barrier()
rank 3 After initialize model
rank 3 Before the second dist.barrier()
rank 6 After initialize model
rank 6 Before the second dist.barrier()
rank 4 After initialize model
rank 4 Before the second dist.barrier()
rank 7 After initialize model
rank 7 Before the second dist.barrier()
rank 5 After initialize model
rank 5 Before the second dist.barrier()
rank 0 After the second dist.barrier()
rank 1 After the second dist.barrier()
rank 3 After the second dist.barrier()
rank 4 After the second dist.barrier()
rank 2 After the second dist.barrier()
rank 5 After the second dist.barrier()
rank 6 After the second dist.barrier()
rank 7 After the second dist.barrier()
parameter name  var_embed  requires_gradient  True size torch.Size([1, 1024, 4096])
parameter name  var_query  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  var_query_per_rank  requires_gradient  True size torch.Size([1, 1, 4096])
parameter name  pos_embed  requires_gradient  True size torch.Size([1, 2048, 4096])
parameter name  token_embeds.0.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.0.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.2.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.2.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.3.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.3.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.4.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.4.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.5.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.5.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.6.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.6.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.7.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.7.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.8.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.8.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.9.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.9.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.10.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.10.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.11.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.11.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.12.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.12.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.13.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.13.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.14.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.14.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.15.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.15.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.16.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.16.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.17.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.17.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.18.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.18.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.19.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.19.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.20.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.20.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.21.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.21.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.22.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.22.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.23.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.23.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.24.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.24.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.25.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.25.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.26.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.26.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.27.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.27.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.28.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.28.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.29.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.29.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.30.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.30.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.31.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.31.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.32.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.32.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.33.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.33.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.34.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.34.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.35.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.35.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.36.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.36.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.37.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.37.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.38.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.38.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.39.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.39.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.40.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.40.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.41.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.41.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.42.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.42.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.43.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.43.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.44.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.44.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.45.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.45.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.46.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.46.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.47.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.47.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.48.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.48.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.49.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.49.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.50.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.50.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.51.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.51.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.52.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.52.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.53.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.53.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.54.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.54.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.55.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.55.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.56.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.56.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.57.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.57.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.58.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.58.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.59.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.59.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.60.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.60.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.61.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.61.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.62.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.62.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.63.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.63.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.64.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.64.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.65.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.65.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.66.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.66.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.67.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.67.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.68.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.68.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.69.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.69.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.70.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.70.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.71.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.71.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.72.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.72.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.73.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.73.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.74.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.74.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.75.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.75.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.76.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.76.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.77.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.77.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.78.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.78.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.79.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.79.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.80.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.80.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.81.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.81.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.82.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.82.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.83.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.83.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.84.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.84.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.85.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.85.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.86.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.86.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.87.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.87.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.88.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.88.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.89.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.89.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.90.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.90.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.91.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.91.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.92.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.92.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.93.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.93.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.94.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.94.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.95.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.95.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.96.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.96.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.97.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.97.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.98.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.98.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.99.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.99.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.100.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.100.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.101.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.101.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.102.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.102.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.103.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.103.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.104.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.104.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.105.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.105.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.106.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.106.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.107.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.107.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.108.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.108.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.109.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.109.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.110.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.110.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.111.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.111.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.112.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.112.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.113.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.113.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.114.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.114.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.115.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.115.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.116.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.116.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.117.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.117.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.118.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.118.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.119.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.119.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.120.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.120.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.121.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.121.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.122.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.122.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.123.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.123.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.124.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.124.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.125.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.125.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.126.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.126.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.127.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.127.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.128.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.128.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.129.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.129.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.130.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.130.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.131.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.131.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.132.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.132.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.133.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.133.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.134.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.134.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.135.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.135.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.136.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.136.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.137.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.137.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.138.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.138.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.139.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.139.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.140.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.140.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.141.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.141.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.142.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.142.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.143.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.143.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.144.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.144.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.145.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.145.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.146.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.146.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.147.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.147.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.148.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.148.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.149.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.149.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.150.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.150.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.151.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.151.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.152.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.152.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.153.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.153.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.154.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.154.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.155.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.155.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.156.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.156.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.157.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.157.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.158.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.158.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.159.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.159.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.160.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.160.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.161.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.161.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.162.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.162.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.163.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.163.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.164.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.164.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.165.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.165.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.166.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.166.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.167.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.167.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.168.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.168.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.169.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.169.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.170.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.170.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.171.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.171.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.172.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.172.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.173.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.173.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.174.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.174.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.175.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.175.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.176.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.176.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.177.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.177.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.178.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.178.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.179.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.179.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.180.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.180.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.181.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.181.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.182.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.182.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.183.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.183.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.184.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.184.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.185.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.185.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.186.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.186.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.187.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.187.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.188.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.188.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.189.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.189.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.190.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.190.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.191.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.191.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.192.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.192.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.193.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.193.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.194.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.194.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.195.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.195.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.196.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.196.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.197.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.197.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.198.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.198.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.199.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.199.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.200.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.200.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.201.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.201.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.202.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.202.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.203.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.203.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.204.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.204.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.205.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.205.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.206.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.206.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.207.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.207.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.208.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.208.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.209.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.209.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.210.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.210.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.211.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.211.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.212.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.212.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.213.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.213.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.214.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.214.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.215.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.215.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.216.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.216.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.217.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.217.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.218.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.218.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.219.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.219.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.220.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.220.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.221.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.221.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.222.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.222.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.223.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.223.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.224.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.224.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.225.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.225.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.226.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.226.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.227.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.227.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.228.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.228.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.229.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.229.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.230.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.230.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.231.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.231.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.232.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.232.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.233.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.233.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.234.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.234.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.235.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.235.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.236.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.236.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.237.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.237.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.238.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.238.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.239.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.239.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.240.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.240.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.241.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.241.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.242.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.242.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.243.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.243.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.244.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.244.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.245.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.245.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.246.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.246.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.247.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.247.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.248.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.248.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.249.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.249.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.250.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.250.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.251.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.251.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.252.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.252.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.253.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.253.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.254.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.254.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.255.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.255.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.256.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.256.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.257.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.257.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.258.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.258.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.259.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.259.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.260.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.260.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.261.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.261.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.262.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.262.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.263.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.263.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.264.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.264.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.265.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.265.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.266.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.266.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.267.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.267.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.268.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.268.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.269.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.269.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.270.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.270.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.271.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.271.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.272.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.272.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.273.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.273.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.274.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.274.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.275.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.275.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.276.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.276.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.277.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.277.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.278.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.278.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.279.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.279.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.280.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.280.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.281.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.281.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.282.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.282.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.283.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.283.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.284.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.284.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.285.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.285.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.286.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.286.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.287.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.287.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.288.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.288.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.289.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.289.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.290.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.290.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.291.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.291.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.292.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.292.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.293.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.293.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.294.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.294.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.295.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.295.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.296.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.296.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.297.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.297.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.298.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.298.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.299.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.299.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.300.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.300.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.301.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.301.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.302.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.302.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.303.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.303.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.304.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.304.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.305.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.305.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.306.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.306.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.307.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.307.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.308.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.308.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.309.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.309.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.310.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.310.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.311.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.311.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.312.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.312.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.313.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.313.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.314.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.314.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.315.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.315.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.316.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.316.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.317.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.317.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.318.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.318.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.319.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.319.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.320.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.320.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.321.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.321.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.322.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.322.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.323.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.323.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.324.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.324.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.325.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.325.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.326.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.326.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.327.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.327.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.328.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.328.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.329.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.329.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.330.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.330.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.331.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.331.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.332.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.332.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.333.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.333.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.334.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.334.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.335.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.335.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.336.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.336.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.337.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.337.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.338.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.338.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.339.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.339.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.340.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.340.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.341.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.341.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.342.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.342.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.343.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.343.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.344.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.344.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.345.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.345.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.346.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.346.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.347.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.347.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.348.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.348.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.349.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.349.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.350.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.350.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.351.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.351.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.352.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.352.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.353.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.353.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.354.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.354.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.355.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.355.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.356.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.356.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.357.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.357.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.358.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.358.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.359.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.359.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.360.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.360.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.361.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.361.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.362.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.362.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.363.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.363.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.364.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.364.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.365.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.365.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.366.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.366.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.367.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.367.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.368.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.368.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.369.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.369.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.370.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.370.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.371.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.371.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.372.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.372.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.373.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.373.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.374.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.374.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.375.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.375.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.376.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.376.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.377.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.377.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.378.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.378.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.379.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.379.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.380.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.380.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.381.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.381.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.382.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.382.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.383.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.383.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.384.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.384.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.385.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.385.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.386.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.386.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.387.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.387.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.388.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.388.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.389.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.389.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.390.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.390.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.391.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.391.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.392.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.392.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.393.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.393.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.394.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.394.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.395.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.395.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.396.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.396.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.397.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.397.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.398.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.398.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.399.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.399.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.400.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.400.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.401.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.401.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.402.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.402.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.403.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.403.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.404.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.404.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.405.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.405.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.406.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.406.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.407.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.407.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.408.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.408.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.409.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.409.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.410.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.410.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.411.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.411.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.412.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.412.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.413.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.413.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.414.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.414.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.415.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.415.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.416.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.416.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.417.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.417.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.418.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.418.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.419.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.419.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.420.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.420.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.421.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.421.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.422.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.422.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.423.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.423.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.424.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.424.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.425.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.425.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.426.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.426.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.427.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.427.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.428.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.428.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.429.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.429.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.430.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.430.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.431.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.431.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.432.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.432.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.433.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.433.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.434.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.434.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.435.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.435.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.436.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.436.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.437.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.437.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.438.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.438.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.439.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.439.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.440.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.440.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.441.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.441.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.442.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.442.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.443.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.443.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.444.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.444.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.445.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.445.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.446.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.446.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.447.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.447.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.448.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.448.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.449.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.449.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.450.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.450.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.451.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.451.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.452.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.452.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.453.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.453.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.454.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.454.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.455.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.455.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.456.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.456.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.457.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.457.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.458.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.458.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.459.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.459.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.460.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.460.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.461.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.461.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.462.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.462.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.463.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.463.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.464.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.464.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.465.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.465.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.466.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.466.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.467.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.467.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.468.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.468.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.469.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.469.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.470.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.470.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.471.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.471.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.472.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.472.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.473.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.473.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.474.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.474.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.475.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.475.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.476.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.476.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.477.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.477.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.478.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.478.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.479.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.479.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.480.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.480.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.481.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.481.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.482.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.482.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.483.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.483.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.484.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.484.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.485.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.485.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.486.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.486.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.487.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.487.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.488.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.488.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.489.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.489.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.490.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.490.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.491.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.491.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.492.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.492.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.493.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.493.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.494.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.494.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.495.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.495.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.496.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.496.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.497.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.497.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.498.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.498.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.499.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.499.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.500.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.500.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.501.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.501.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.502.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.502.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.503.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.503.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.504.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.504.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.505.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.505.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.506.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.506.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.507.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.507.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.508.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.508.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.509.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.509.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.510.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.510.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.511.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.511.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.512.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.512.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.513.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.513.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.514.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.514.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.515.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.515.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.516.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.516.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.517.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.517.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.518.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.518.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.519.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.519.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.520.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.520.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.521.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.521.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.522.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.522.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.523.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.523.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.524.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.524.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.525.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.525.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.526.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.526.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.527.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.527.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.528.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.528.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.529.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.529.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.530.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.530.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.531.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.531.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.532.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.532.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.533.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.533.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.534.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.534.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.535.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.535.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.536.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.536.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.537.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.537.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.538.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.538.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.539.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.539.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.540.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.540.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.541.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.541.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.542.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.542.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.543.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.543.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.544.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.544.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.545.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.545.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.546.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.546.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.547.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.547.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.548.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.548.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.549.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.549.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.550.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.550.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.551.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.551.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.552.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.552.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.553.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.553.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.554.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.554.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.555.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.555.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.556.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.556.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.557.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.557.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.558.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.558.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.559.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.559.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.560.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.560.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.561.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.561.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.562.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.562.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.563.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.563.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.564.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.564.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.565.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.565.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.566.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.566.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.567.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.567.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.568.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.568.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.569.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.569.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.570.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.570.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.571.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.571.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.572.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.572.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.573.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.573.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.574.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.574.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.575.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.575.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.576.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.576.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.577.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.577.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.578.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.578.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.579.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.579.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.580.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.580.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.581.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.581.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.582.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.582.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.583.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.583.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.584.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.584.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.585.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.585.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.586.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.586.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.587.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.587.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.588.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.588.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.589.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.589.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.590.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.590.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.591.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.591.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.592.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.592.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.593.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.593.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.594.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.594.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.595.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.595.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.596.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.596.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.597.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.597.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.598.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.598.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.599.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.599.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.600.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.600.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.601.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.601.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.602.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.602.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.603.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.603.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.604.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.604.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.605.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.605.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.606.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.606.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.607.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.607.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.608.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.608.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.609.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.609.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.610.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.610.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.611.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.611.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.612.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.612.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.613.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.613.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.614.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.614.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.615.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.615.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.616.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.616.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.617.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.617.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.618.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.618.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.619.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.619.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.620.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.620.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.621.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.621.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.622.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.622.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.623.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.623.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.624.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.624.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.625.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.625.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.626.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.626.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.627.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.627.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.628.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.628.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.629.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.629.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.630.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.630.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.631.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.631.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.632.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.632.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.633.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.633.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.634.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.634.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.635.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.635.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.636.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.636.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.637.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.637.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.638.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.638.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.639.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.639.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.640.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.640.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.641.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.641.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.642.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.642.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.643.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.643.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.644.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.644.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.645.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.645.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.646.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.646.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.647.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.647.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.648.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.648.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.649.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.649.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.650.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.650.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.651.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.651.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.652.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.652.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.653.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.653.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.654.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.654.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.655.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.655.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.656.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.656.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.657.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.657.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.658.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.658.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.659.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.659.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.660.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.660.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.661.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.661.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.662.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.662.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.663.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.663.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.664.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.664.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.665.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.665.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.666.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.666.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.667.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.667.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.668.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.668.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.669.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.669.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.670.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.670.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.671.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.671.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.672.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.672.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.673.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.673.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.674.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.674.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.675.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.675.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.676.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.676.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.677.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.677.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.678.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.678.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.679.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.679.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.680.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.680.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.681.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.681.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.682.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.682.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.683.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.683.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.684.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.684.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.685.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.685.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.686.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.686.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.687.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.687.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.688.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.688.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.689.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.689.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.690.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.690.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.691.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.691.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.692.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.692.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.693.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.693.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.694.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.694.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.695.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.695.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.696.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.696.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.697.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.697.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.698.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.698.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.699.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.699.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.700.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.700.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.701.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.701.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.702.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.702.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.703.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.703.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.704.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.704.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.705.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.705.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.706.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.706.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.707.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.707.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.708.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.708.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.709.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.709.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.710.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.710.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.711.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.711.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.712.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.712.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.713.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.713.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.714.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.714.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.715.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.715.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.716.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.716.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.717.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.717.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.718.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.718.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.719.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.719.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.720.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.720.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.721.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.721.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.722.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.722.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.723.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.723.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.724.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.724.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.725.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.725.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.726.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.726.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.727.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.727.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.728.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.728.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.729.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.729.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.730.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.730.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.731.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.731.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.732.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.732.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.733.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.733.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.734.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.734.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.735.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.735.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.736.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.736.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.737.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.737.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.738.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.738.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.739.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.739.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.740.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.740.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.741.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.741.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.742.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.742.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.743.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.743.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.744.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.744.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.745.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.745.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.746.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.746.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.747.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.747.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.748.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.748.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.749.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.749.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.750.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.750.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.751.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.751.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.752.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.752.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.753.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.753.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.754.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.754.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.755.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.755.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.756.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.756.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.757.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.757.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.758.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.758.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.759.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.759.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.760.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.760.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.761.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.761.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.762.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.762.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.763.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.763.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.764.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.764.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.765.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.765.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.766.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.766.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.767.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.767.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.768.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.768.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.769.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.769.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.770.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.770.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.771.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.771.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.772.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.772.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.773.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.773.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.774.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.774.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.775.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.775.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.776.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.776.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.777.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.777.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.778.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.778.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.779.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.779.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.780.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.780.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.781.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.781.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.782.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.782.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.783.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.783.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.784.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.784.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.785.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.785.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.786.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.786.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.787.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.787.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.788.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.788.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.789.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.789.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.790.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.790.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.791.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.791.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.792.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.792.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.793.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.793.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.794.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.794.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.795.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.795.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.796.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.796.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.797.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.797.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.798.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.798.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.799.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.799.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.800.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.800.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.801.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.801.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.802.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.802.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.803.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.803.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.804.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.804.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.805.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.805.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.806.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.806.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.807.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.807.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.808.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.808.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.809.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.809.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.810.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.810.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.811.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.811.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.812.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.812.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.813.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.813.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.814.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.814.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.815.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.815.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.816.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.816.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.817.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.817.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.818.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.818.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.819.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.819.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.820.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.820.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.821.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.821.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.822.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.822.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.823.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.823.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.824.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.824.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.825.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.825.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.826.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.826.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.827.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.827.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.828.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.828.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.829.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.829.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.830.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.830.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.831.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.831.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.832.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.832.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.833.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.833.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.834.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.834.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.835.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.835.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.836.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.836.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.837.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.837.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.838.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.838.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.839.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.839.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.840.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.840.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.841.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.841.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.842.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.842.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.843.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.843.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.844.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.844.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.845.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.845.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.846.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.846.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.847.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.847.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.848.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.848.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.849.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.849.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.850.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.850.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.851.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.851.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.852.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.852.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.853.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.853.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.854.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.854.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.855.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.855.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.856.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.856.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.857.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.857.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.858.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.858.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.859.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.859.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.860.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.860.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.861.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.861.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.862.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.862.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.863.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.863.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.864.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.864.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.865.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.865.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.866.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.866.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.867.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.867.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.868.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.868.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.869.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.869.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.870.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.870.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.871.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.871.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.872.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.872.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.873.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.873.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.874.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.874.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.875.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.875.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.876.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.876.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.877.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.877.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.878.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.878.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.879.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.879.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.880.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.880.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.881.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.881.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.882.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.882.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.883.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.883.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.884.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.884.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.885.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.885.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.886.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.886.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.887.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.887.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.888.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.888.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.889.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.889.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.890.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.890.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.891.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.891.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.892.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.892.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.893.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.893.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.894.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.894.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.895.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.895.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.896.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.896.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.897.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.897.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.898.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.898.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.899.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.899.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.900.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.900.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.901.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.901.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.902.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.902.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.903.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.903.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.904.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.904.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.905.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.905.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.906.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.906.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.907.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.907.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.908.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.908.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.909.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.909.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.910.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.910.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.911.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.911.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.912.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.912.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.913.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.913.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.914.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.914.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.915.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.915.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.916.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.916.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.917.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.917.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.918.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.918.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.919.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.919.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.920.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.920.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.921.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.921.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.922.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.922.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.923.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.923.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.924.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.924.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.925.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.925.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.926.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.926.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.927.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.927.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.928.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.928.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.929.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.929.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.930.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.930.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.931.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.931.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.932.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.932.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.933.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.933.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.934.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.934.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.935.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.935.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.936.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.936.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.937.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.937.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.938.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.938.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.939.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.939.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.940.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.940.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.941.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.941.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.942.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.942.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.943.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.943.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.944.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.944.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.945.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.945.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.946.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.946.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.947.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.947.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.948.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.948.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.949.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.949.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.950.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.950.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.951.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.951.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.952.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.952.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.953.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.953.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.954.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.954.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.955.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.955.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.956.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.956.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.957.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.957.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.958.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.958.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.959.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.959.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.960.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.960.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.961.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.961.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.962.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.962.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.963.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.963.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.964.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.964.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.965.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.965.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.966.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.966.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.967.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.967.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.968.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.968.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.969.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.969.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.970.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.970.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.971.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.971.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.972.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.972.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.973.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.973.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.974.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.974.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.975.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.975.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.976.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.976.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.977.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.977.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.978.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.978.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.979.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.979.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.980.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.980.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.981.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.981.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.982.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.982.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.983.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.983.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.984.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.984.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.985.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.985.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.986.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.986.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.987.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.987.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.988.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.988.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.989.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.989.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.990.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.990.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.991.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.991.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.992.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.992.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.993.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.993.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.994.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.994.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.995.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.995.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.996.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.996.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.997.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.997.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.998.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.998.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.999.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.999.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1000.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1000.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1001.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1001.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1002.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1002.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1003.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1003.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1004.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1004.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1005.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1005.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1006.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1006.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1007.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1007.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1008.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1008.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1009.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1009.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1010.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1010.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1011.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1011.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1012.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1012.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1013.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1013.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1014.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1014.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1015.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1015.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1016.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1016.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1017.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1017.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1018.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1018.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1019.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1019.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1020.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1020.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1021.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1021.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1022.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1022.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  token_embeds.1023.proj.weight  requires_gradient  True size torch.Size([4096, 1, 4, 4])
parameter name  token_embeds.1023.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_agg.q.weight  requires_gradient  True size torch.Size([512, 4096])
parameter name  var_agg.kv.weight  requires_gradient  True size torch.Size([1024, 4096])
parameter name  var_agg.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  var_agg.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  var_linear_per_rank.weight  requires_gradient  True size torch.Size([1, 128])
parameter name  var_linear_per_rank.bias  requires_gradient  True size torch.Size([1])
parameter name  lead_time_embed.weight  requires_gradient  True size torch.Size([4096, 1])
parameter name  lead_time_embed.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.0.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.0.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.0.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.0.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.0.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.0.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.0.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.1.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.1.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.1.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.1.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.1.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.1.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.1.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.2.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.2.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.2.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.2.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.2.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.2.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.2.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.3.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.3.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.3.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.3.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.3.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.3.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.3.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.4.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.4.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.4.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.4.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.4.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.4.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.4.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.5.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.5.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.5.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.5.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.5.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.5.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.5.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.6.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.6.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.6.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.6.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.6.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.6.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.6.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.7.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.7.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.7.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.7.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.7.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.7.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.7.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.8.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.8.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.8.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.8.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.8.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.8.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.8.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.9.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.9.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.9.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.9.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.9.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.9.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.9.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.10.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.10.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.10.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.10.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.10.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.10.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.10.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.11.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.11.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.11.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.11.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.11.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.11.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.11.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.12.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.12.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.12.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.12.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.12.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.12.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.12.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.13.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.13.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.13.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.13.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.13.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.13.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.13.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.14.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.14.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.14.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.14.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.14.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.14.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.14.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.15.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.15.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.15.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.15.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.15.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.15.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.15.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.16.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.16.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.16.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.16.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.16.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.16.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.16.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.17.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.17.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.17.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.17.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.17.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.17.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.17.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.18.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.18.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.18.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.18.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.18.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.18.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.18.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.19.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.19.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.19.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.19.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.19.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.19.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.19.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.20.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.20.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.20.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.20.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.20.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.20.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.20.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.21.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.21.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.21.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.21.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.21.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.21.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.21.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.22.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.22.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.22.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.22.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.22.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.22.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.22.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.23.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.23.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.23.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.23.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.23.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.23.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.23.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.24.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.24.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.24.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.24.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.24.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.24.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.24.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.25.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.25.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.25.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.25.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.25.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.25.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.25.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.26.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.26.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.26.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.26.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.26.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.26.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.26.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.27.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.27.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.27.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.27.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.27.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.27.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.27.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.28.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.28.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.28.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.28.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.28.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.28.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.28.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.29.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.29.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.29.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.29.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.29.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.29.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.29.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.30.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.30.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.30.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.30.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.30.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.30.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.30.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm1.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.attn.qkv.weight  requires_gradient  True size torch.Size([1536, 4096])
parameter name  blocks.31.attn.qkv.bias  requires_gradient  True size torch.Size([1536])
parameter name  blocks.31.attn.proj.weight  requires_gradient  True size torch.Size([4096, 512])
parameter name  blocks.31.attn.proj.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.weight  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.norm2.bias  requires_gradient  True size torch.Size([4096])
parameter name  blocks.31.mlp.fc1.weight  requires_gradient  True size torch.Size([2048, 4096])
parameter name  blocks.31.mlp.fc1.bias  requires_gradient  True size torch.Size([2048])
parameter name  blocks.31.mlp.fc2.weight  requires_gradient  True size torch.Size([4096, 2048])
parameter name  blocks.31.mlp.fc2.bias  requires_gradient  True size torch.Size([4096])
parameter name  norm.weight  requires_gradient  True size torch.Size([4096])
parameter name  norm.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.0.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.0.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.2.weight  requires_gradient  True size torch.Size([4096, 4096])
parameter name  head.2.bias  requires_gradient  True size torch.Size([4096])
parameter name  head.5.weight  requires_gradient  True size torch.Size([16384, 4096])
parameter name  head.5.bias  requires_gradient  True size torch.Size([16384])
total_params before FSDP tensor(6697730177) params_per_gpu tensor(999198849)
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
rank  7 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
len(dict_root_dirs) 1
use_ddstore is : 0
total_params after FSDP FullyShardedDataParallel(
  (_fsdp_wrapped_module): ClimaX(
    (token_embeds): ModuleList(
      (0-1023): 1024 x PatchEmbed(
        (proj): Conv2d(1, 4096, kernel_size=(4, 4), stride=(4, 4))
        (norm): Identity()
      )
    )
    (var_agg): FullyShardedDataParallel(
      (_fsdp_wrapped_module): CheckpointWrapper(
        (_checkpoint_wrapped_module): VariableMapping_Attention(
          (q): Linear(in_features=4096, out_features=512, bias=False)
          (kv): Linear(in_features=4096, out_features=1024, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=4096, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (var_linear_per_rank): Linear(in_features=128, out_features=1, bias=True)
    (lead_time_embed): Linear(in_features=1, out_features=4096, bias=True)
    (pos_drop): Dropout(p=0.1, inplace=False)
    (blocks): ModuleList(
      (0-31): 32 x FullyShardedDataParallel(
        (_fsdp_wrapped_module): CheckpointWrapper(
          (_checkpoint_wrapped_module): Block(
            (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (attn): Attention(
              (qkv): Linear(in_features=4096, out_features=1536, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=4096, bias=True)
              (proj_drop): Dropout(p=0.1, inplace=False)
            )
            (ls1): Identity()
            (norm2): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=4096, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0.1, inplace=False)
              (fc2): Linear(in_features=2048, out_features=4096, bias=True)
            )
            (ls2): Identity()
          )
        )
      )
    )
    (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (head): Sequential(
      (0): Linear(in_features=4096, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Pred_Rearrange()
      (5): Linear(in_features=4096, out_features=16384, bias=True)
    )
  )
)
len(dict_root_dirs) 1
rank  0 lister_train reset: mpi-esm 9 9 9
use_ddstore is : 0
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
memory stats reset, ready to track
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torchvision-0.18.0a0+4c0f441-py3.8-linux-x86_64.egg/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
epoch-train:  0 batch_idx 0 world_rank 0  loss  1.359375
epoch-train:  0 batch_idx 1 world_rank 0  loss  1.328125
epoch-train:  0 batch_idx 2 world_rank 0  loss  1.3203125
[2025-03-07 22:25:01,276] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:25:01,276] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:25:01,276] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:25:01,277] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:25:01,278] [INFO] [profiler.py:80:start_profile] Flops profiler started
epoch-train:  0 batch_idx 3 world_rank 0  loss  1.2890625
[2025-03-07 22:25:01,279] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:25:01,280] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:25:01,280] [INFO] [profiler.py:80:start_profile] Flops profiler started
[2025-03-07 22:25:02,604] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:25:02,604] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:25:02,605] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:25:02,606] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:25:02,606] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:25:02,607] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:25:02,607] [INFO] [profiler.py:226:end_profile] Flops profiler finished
[2025-03-07 22:25:02,607] [INFO] [profiler.py:226:end_profile] Flops profiler finished
global rank 3: ddp rank 0 iter_start,iter_end = 0 8
global rank 3: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 7: ddp rank 0 iter_start,iter_end = 0 8
global rank 7: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 0: ddp rank 0 iter_start,iter_end = 0 8
global rank 0: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 6: ddp rank 0 iter_start,iter_end = 0 8
global rank 6: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 5: ddp rank 0 iter_start,iter_end = 0 8
global rank 5: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 2: ddp rank 0 iter_start,iter_end = 0 8
global rank 2: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 1: ddp rank 0 iter_start,iter_end = 0 8
global rank 1: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
global rank 4: ddp rank 0 iter_start,iter_end = 0 8
global rank 4: ddp rank 0 NpyReader: /lustre/orion/stf218/scratch/atsaris/code/tmp25/climaxSC24_end2end/DATA_tmp_5.0/train/2018_0.npz
MUST: Model 999.198849 M TFLOPS: 10.814785340090957

--> cuda max reserved memory = 35.0176
--> max reserved percentage = 54.73 %

--> cuda max memory allocated = 27.6584
--> max allocated percentage = 43.23 %

--> peak active memory = 29.0819
--> peak active memory 45.45 %

cudaMalloc retries = 0
cuda OOM = 0

HERE1 Namespace(arch='orbit_linear', batch_size=2, channels=1024, depth=32, embed_dim=4096, fa2=True, fsdp_size=1, imagex=128, imagey=256, max_epochs=1, num_heads=32, real=False, seq_par_size=1, simple_ddp_size=1, tensor_par_size=8, yaml_config='configs/ERA5-100million-91variables.yaml') 35.0176 10.814785340090957 tensor(6697730177)
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/backends/cuda/__init__.py:320: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/lustre/orion/world-shared/stf218/atsaris/DEEPCAM_2022/new_env/miniconda/env_rocm/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
sleeping...
Done
Done
Done
Done
Done
Done
Done
Done
0.10user 0.55system 17:44.29elapsed 0%CPU (0avgtext+0avgdata 17408maxresident)k
2806inputs+7624outputs (10major+3161minor)pagefaults 0swaps
